# 2021中国高校计算机大赛 微信大数据挑战赛


2021大数据高校赛初赛已经结束，今年的比赛规则和去年有所不同，没有对在职队伍的数量做限制。我们队伍的初赛最终排名68/6768，线上A、B榜排名分别为91、85。在此记录一下我在初赛阶段的上分过程。

<!--more-->
## 赛题描述
　　本次比赛基于脱敏和采样后的数据信息，对于给定的一定数量到访过微信视频号“热门推荐”的用户， 根据这些用户在视频号内的历史n天的行为数据，通过算法在测试集上预测出这些用户对于不同视频内容的互动行为（包括点赞、点击头像、收藏、转发等）的发生概率。 本次比赛以多个行为预测结果的加权uAUC值进行评分。  
　　比赛提供训练集用于训练模型，测试集用于评估模型效果，提交结果demo文件用于展示提交结果的格式。 所有数据文件格式都是带表头的.csv格式，不同字段列之间用英文逗号分隔。初赛与复赛的数据分布一致，数据规模不同。 初赛提供百万级训练数据，复赛提供千万级训练数据。

## Baseline
　　主办方为本次比赛提供了一份基线:[Wechat_Big_Data_Challenge_Baseline](https://github.com/WeChat-Big-Data-Challenge-2021/WeChat_Big_Data_Challenge)，该基线基于Wide & Deep模型实现，除6列原始id特征和feed时长特征外，在id特征的基础上构造了一些统计特征。Weight_uAUC线下0.657003，线上0.607908。  
　　官方提供的这份基线分为数据集生成、离线模型训练、离线模型评估、在线模型训练、生成线上提交结果几个步骤，流程比较复杂，且线上线下gap较大，达到了5个百分点（经验证是统计特征涉及时间穿越，删去此部分特征可以提高2-3个百，群里也有人在基线基础上调参也能得到线上0.65+的分数），故我并没有过多参考此份基线。  
　　我所使用的是讨论区深度匹配树大佬所开源的基于MMoE的多任务学习模型，由于MMoE的多任务训练机制，训练速度相比四个任务逐个建模大大提升，可以迅速验证一些特征的有效性。线上分数约为0.635。  
  ![MMoE](https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/wechat_algo_stage1/MMoE.jpg)
 　　TensorFlow版：[mmoe_tf](https://github.com/zanshuxun/WeChat_Big_Data_Challenge_DeepCTR_baseline)，Pytorch版：[mmoe_torch](https://github.com/dpoqb/wechat_big_data_baseline_pytorch)。


## 统计特征
　　基线中仅使用了6列id类特征，第一想法是在这六列id的基础上构建统计特征，由于数据带有时间序列的性质，提取特征时要注意时间穿越问题。我根据user、feed等多侧的历史行为，构建了点击、曝光、CTR等相关特征，这些特征在CTR类的比赛中非常常见，Kaggle、Github上也有非常多优秀的开源代码，故这部分特征的具体提取不再赘述。  
　　但将此部分统计特征喂给nn时，nn几乎不收敛，loss波动极大，归一化后线上成绩也非常低，于是开始思考什么样的特征适合喂给nn，开始下一阶段的特征构建。

## 512维多模态向量
　　这部分特征的正确使用能够获得较大幅度的提升，我尝试了两种方法，第一种是直接merge到训练集上，不过直接merge极容易OOM（除非内存足够），第二种是给feedid的嵌入赋值权重，不过后者经过实验效果不佳，也可能是我使用的方式不对。我租用的服务器配置为2\*P40 + 112G RAM，将512维多模态向量经过PCA降维到48维后并在训练集上送入nn进行训练，线上线下均有大幅度提升，仅加入多模态这部分embedding特征后，线上成绩可以直接突破0.65。

## tag、keyword：多值离散特征
　　这部分特征的处理方式有很多，例如作为序列提取通过word2vec提取embedding，将每个离散取值当成词，整个tag/keyword列表当作句子，获取每个词的词向量后做pooling操作得到该部分的embedding，此处可参考[序列问题必备特征工程——基于Word2Vec的文本向量](https://mp.weixin.qq.com/s?__biz=Mzk0NDE5Nzg1Ng==&mid=2247496721&idx=1&sn=c7fab106254f555cbea64e8464c84074&chksm=c32aed9ef45d64887f23606031d052c3fdce868b975644ca62db52bfd70185d4ddd212f0364f&mpshare=1&scene=23&srcid=0701JaeEB4Z1IDrtYDj3zaDK&sharer_sharetime=1625107770080&sharer_shareid=8c3bd21461ee94c3d6cc62dff5de10ac#rd)，或者通过embedding_lookup，此处可参考[推荐算法-4.多值离散特征的embedding解决方案](https://zhuanlan.zhihu.com/p/149014347)。  
　　该部分特征对分数的提升也能达到7-8个千，我的线上分数也达到了0.659。


## 多种子融合
　　由于tensorflow的内部机制，导致其无法完全固定随机种子，同特征同参数下训练结果有一定幅度波动，波动幅度大概有2-3个千，通过多次训练，取平均可以稳定结果，线上成绩有约2个千的小幅度提升。


## 树模型
　　我在0.664附近卡了近两周的时间，比赛中后期的时候，天才儿童在6.14的周周星分享中开源了一份线上成绩0.645的[梯度提升决策树模型基线](https://developers.weixin.qq.com/community/minihome/article/doc/0006467d05427892b94c341aa56813)，当时队伍中仅我自己一人，仅靠单模进入复赛不太稳定，而且初赛由于数据采样的原因，树模型会比nn更有优势，故决定转手再做一个树模型。  
　　树模型中主要构造了一些统计类特征，和前文提到的类似，主要包括曝光、转化、视频观看等情况的滑窗统计特征，以及包括曝光、偏好等**全局信息统计特征**（全局统计也能上分..Orz）。  
　　我在此份基线的基础上添加了nn中使用的几个embedding特征，树模型单模单折分数做到0.655。和我此前0.664的nn仅5/5平均后，就能够有3个k的提升。

## 基于embedding的衍生特征
　　这时距离比赛结束还有一周的时间，我在群里找到了一个做nn的和一个做树模型的队有，单模分数都在0.664上下，我和另一个队友的sub简单融合后分数达到了0.670，提升较大，然后继续优化nn单模。  
　　基于前面提取的多个embedding特征，我在此基础上又提取了一些衍生特征，方式包括滑窗pooling等，收益较大，简单衍生后就能提升3个千。

## 初赛B榜
　　B榜数据和A榜的user无重叠，分布一致，排行榜上普遍有3个k到6个k的下降，我们的B榜最终分数为0.67093。

## 待解决的问题
### 部分feed冷启动 
　　简单观察数据可发现，第15天仍有2607个feed冷启动（未在user_action中出现），样本量为72758。  
　　对于冷启动问题，目前的基本思路是做矩阵SVD分解，构建用户和商品的交互矩阵，对稀疏矩阵进行SVD分解，得到用户和商品的向量，将用户向量和商品向量作为特征拼接到用户和商品侧。
![每日冷启动feed数量](https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/wechat_algo_stage1/feed%E5%86%B7%E5%90%AF%E5%8A%A8)

### 模型结构
　　比赛初期GDY郭大使用Transformer输入原始的id类特征轻松上到了0.65+，从后面周周星分享的一些思路也可以看出，模型结构的修改可以带来比较大的收益，例如参考DIN对用户的长短期兴趣进行表征等。

## 参考代码
[https://github.com/meurice996/WBDC2021_Solution](https://github.com/meurice996/WBDC2021_Solution)
