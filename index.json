[{"categories":null,"content":"李宏毅2021/2022春机器学习课程——Self-Supervised Learning 自监督式学习（Self-Supervised Learning） ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:0:0","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"芝麻街与进击的巨人 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:1:0","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"芝麻街 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:1:1","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"进击的巨人：Bertolt Hoover ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:1:2","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"主流模型参数量 Model Parameters ELMO 94M BERT 340M GPT-2 1542M Megatron 8B T5 11B Turing NLG 17B GPT-3 175B Switch Transformer 1.6T ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:1:3","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"BERT ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:0","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Self-supervised Learning 对于数据$x$，监督学习需要知道数据的标签$\\hat{y}$，来让模型输出我们想要的$y$。而自监督学习没有标注，将$x$分为两部分，一部分$x’$输入到模型得到$y$，另一部分$x’’$作为标签，然后让$y$和$x’’$越接近越好。 自监督学习可以看作是一种无监督学习的方法，无监督学习的范围很大，里面有很多不同的方法，为了明确说明现在说做的工作，就称为自监督学习。 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:1","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Masked token prediction [1810.04805] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (arxiv.org) BERT的架构和Transfromer Encoder相同，输入一排向量，输出另一排向量，一般用在文字处理上。 输入一串token（token是处理一段文字的单位，在中文里一般把一个方块字当作一个token。），随机盖住一些token，盖住token有两种方法： 变为某个特殊的token 随机换为另一个token 对BERT的输出序列分别做线性变换（乘矩阵），再做Softmax就得到了一个分布。 BERT不知道被盖住的部分是什么内容，但我们知道这部分内容，BERT学习的目标是输出和盖住的部分越接近越好。 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:2","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Next Sentence Prediction 从资料库中拿出两个句子，两个句子之间加入特殊的分隔符号[SEP]，再整个序号的最前面加[CLS]符号，整个序列输入BERT，看[CLS]对应的输出，[CLS]经过BERT的输出再经过线性变换后输出为Yes/No，代表这两个句子是不是相接的。 例：[CLS] I like cat. [SEP] He likes dog Next Sentence Prediction对于BERT接下来要做的事情可能无用 [1907.11692] RoBERTa: A Robustly Optimized BERT Pretraining Approach (arxiv.org) Next Sentence Prediction这个任务可能比较简单，BERT可能学习不到太多有用的东西。 SOP：Sentence order prediction Used in ALBERT [1909.11942] ALBERT: A Lite BERT for Self-supervised Learning of Language Representations (arxiv.org) 两个句子本来就连在一起，人为拆分开，本来放在前面的句子作为Sentence 1，本来放在后面的句子作为Sentence 2，或本来放在前面的句子作为Sentence 2，本来放在后面的句子作为Sentence 1。然后让BERT去回答是哪一种顺序。 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:3","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Downstream Tasks 在训练BERT时，给了BERT两个任务： Masked token prediction Next sentence prediction 在训练BERT时，似乎仅仅在教BERT如何去做“填空题”，但BERT可以用在其他地方，BERT真正在下游任务（Downstream Tasks）中被使用，但需要少量有标注的数据。BERT经过微调（Fine-tune）可以去完成各种其他的任务。 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:4","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"GLUE 任务集GLUE（General Language Understanding Evaluation）共有9个任务， Corpus of Linguistic Acceptability（CoLA） Stanford Sentiment Treebank（SST-2） Microsoft Research Paraphrase Corpus（MRPC） Quora Question Pairs（QQP） Semantic Textual Similarity Benchmark（STS-B） Multi-Genre Natural Language Inference（MNLI） Question-answering NLI（QNLI） Recognizing Textual Entailment（RTE） Winograd NLI（WNLI） 可以在这9个任务上分别微调模型得到9个模型，通过结果数值来判断模型的好坏。 中文版本的GLUE： CLUE中文语言理解基准测评 (cluebenchmarks.com) ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:5","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"How to use BERT Case 1 Input：sequence Output：class Example：Sentiment analysis 给BERT输入一个句子，前面放[CLS] token，对[CLS]输出的向量做线性变换，Softmax后输出class。需要提供大量的已标注的训练资料。 Linear部分是随机初始化，而BERT部分将学会了做“填空题”的BERT模型的参数拿来初始化。 Case 2 Input：sequence Output：sequence Example：POS tagging（词性标注） 给BERT输入一个句子，前面放[CLS] token，对句子里面每一个token输出的向量做线性变换，Softmax后输出每一个token的类别。需要提供已标注的训练资料。 Case 3 Input：two sequences Output：a class Example：Natural Language Inference（NLI） 前提：一个人骑马越过了一架坏掉的飞机，假设：这个人在一个小餐馆里面，输出：矛盾。 输入两个句子，两个句子之间放[SEP] token，第一个句子前放[CLS] token，整串内容输入BERT，对[CLS]输出的向量做线性变换，Softmax后输出class。需要提供已标注的训练资料。 Case 4 Extraction-based Question Answering（有限制的QA，答案一定能在文章中找到。） Input： Document：$D={d_1,d_2,\\cdots,d_N}$ Query：$Q={q_1,q_2,\\cdots,q_M}$ 对于中文，$d_i$和$q_i$都是汉字。 Output：two integers$(s,e)$ Answer：$A={d_s,\\cdots,d_e}$ 输出两个正整数，代表答案的范围。 输入问题和文章，问题和文章之间放[SEP] token，问题前放[CLS] token，整串内容输入BERT。 文章的各个token输出的向量先和一个向量（橙）做内积，再对结果做Softmax，得到答案起始的位置。 文章的各个token输出的向量再和一个向量（蓝）做内积，再对结果做Softmax，得到答案结束的位置。 以上只有和BERT输出做内积的两个向量是随机初始化的，即这两个向量是重头开始学习的。 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:6","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"BERT Embryology（胚胎学） [2010.02480] Pretrained Language Model Embryology: The Birth of ALBERT (arxiv.org) BERT的训练需要耗费大量的资源，BERT的训练资料大概是30亿个词，是哈利波特全集的3000倍。有没有什么方法去节省计算资源？ 从观察BERT的训练过程开始，BERT在什么时候学会填什么样的词汇？他的填空能力是怎么增进的？ ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:7","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Pre-training a seq2seq model BERT只有预训练的Encoder。 Encoder和Decoder间通过Cross Atention连接起来，在Encoder的输入中故意加一些扰动，希望Decoder输出的句子和弄坏前的句子是一样的。 MASS / BART [1905.02450] MASS: Masked Sequence to Sequence Pre-training for Language Generation (arxiv.org) [1910.13461] BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension (arxiv.org) 对Encoder的输入加一些扰动来弄坏原本的内容： 盖住一些词 删掉一些词 打乱词顺序 词顺序旋转 混合 T5 - Comparison Transfer Text-to-Text Transformer（T5） T5在Colossal Clean Crawled Corpus（C4）进行训练，对比了多种弄坏的方法。 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:8","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Why does BERT work? 将文字输入到BERT中，得到的输出向量称为embedding，代表了各个token的意思，有相似意思的token有着非常相似的embeddng。 在语言中常常有一词多义的情况，例如“吃苹果”的“果”和“苹果手机”的“果”的含义可能相差较大。通过Cosine Similarity计算“吃苹果”和“苹果手机”的Embedding的相似度，可以发现它们之间的相似度较低。 “You shall know a word by the company it keeps.” 一个词的意思可以从上下文看出来，BERT在做“填空题”的过程中所学习的内容也许就是根据上下文来预测当前被盖住的词汇。事实上，BERT之前已经有这样的方法：word embedding，word embedding中的CBOW就是把中间挖空然后预测内容。BERT所抽取出来的向量也叫做Contextualized word embedding。 现在尝试将BERT拿来做蛋白质分类、DNA分类、音乐分类。 [2103.07162] Is BERT a Cross-Disciplinary Knowledge Learner? A Surprising Finding of Pre-trained Models’ Transferability (arxiv.org) 以DNA分类为例： 将DNA中的序列替换成文字，输入到BERT中，输出分类，当作是文章分类的任务来处理。 类似地，对于蛋白质，随意给各个氨基酸映射到词汇上，对于音乐，将各个音符映射到词汇上，得到了下面的结果： BERT的表现是比较好的，就算给BERT乱七八糟的句子，它可能也能把任务完成的比较好，这也说明BERT的表现可能并不完全来自于它“看得懂”文章这件事，关于BERT到底为什么好的问题可能还有很大的研究空间。 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:9","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"More [DLHLP 2020] BERT and its family - Introduction and Fine-tune - YouTube [DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more - YouTube ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:10","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Multi-lingual BERT 在训练的时候，会拿各种各样的语言来给BERT做“填空题”，Multi-BERT使用了104种语言来训练。拿英文的QA资料去训练，Multi-BERT就会做中文的QA问题。 Zero-shot Reading Comprehension 在英文数据集SQuAD和中文数据集DRCD上： [1909.09587] Zero-shot Reading Comprehension by Cross-lingual Transfer Learning with Multi-lingual Language Representation Model (arxiv.org) Cross-lingual Alignment 也许对Multi-lingual BERT来说，不同语言间没有什么差别。 Mean Reciprocal Rank（MRR） MRR值越高，两个不同语言align的越好（同样意思但不同语言的词汇的向量比较接近）。 在1000k资料量下，相比200k资料量下的效果显著提升： ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:11","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"一个神奇的实验 BERT可以让同样意思但不同语言的词汇的向量很接近，但在训练Multi-lingual BERT时，还是给BERT喂中文，它能够做中文填空，喂英文能够做英文填空，不会混在一起，给他喂英文他并没有填中文进去。说明来自不同语言的符号终究还是不一样，并没有完全抹掉语言的资讯。 把所有英文的embedding平均起来，再把所有中文的embedding平均起来，两者相减得到的向量就是中文和英文之间的差距。给Multi-lingual BERT一句英文，得到一串embedding，将embedding加上相减得到的向量，这些向量对于Multi-lingual BERT就变成了中文的句子，再让BERT去做“填空题”，就填出了中文的答案。 语言的资讯还是藏在Multi-lingual BERT中： ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:2:12","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"GPT ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:3:0","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Predict Next Token GPT修改了BERT中模型的任务，GPT的任务是预测接下来的句子是什么。 对于训练资料“台湾大学”，在最前面加上[BOS] token，对于[BOS] token，GPT输出一个embedding，接下来用这个embedding预测下一个应该出现的“台”这个token。 GPT与拿掉Cross attention后的Transformer Decoder结构类似。 GPT要预测下一个token，有生成的能力，GPT最知名的例子就是用GPT写了一篇关于独角兽的假新闻。 Demo – InferKit ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:3:1","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"How to use GPT? GPT有一个更“狂“的使用方式，和人类更接近。 “Few-shot” Learning 例如在进行外语考试时，首先会看题目的说明（“…从A、B、C、D四个选项中选出最佳选项…”），再会看一个例子（“…衬衫的价格是9镑15便士，所以你选择…”）。 “Few-shot” Learning中完全没有Gradient Descent，GPT文献中将这种训练称为“In-context Learning”。 类似地，还有“One-shot” Learning、甚至“Zero-shot” Learning。 “One-shot” Learning “Zero-shot” Learning 第三代GPT测试了42个任务： ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:3:2","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"More [DLHLP 2020] 來自獵人暗黑大陸的模型 GPT-3 - YouTube ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:3:3","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Beyond Text 不止NLP，在语音、图像上都可以用Self-Supervised Learning的技术。 ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:4:0","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Image - SimCLR [2002.05709] A Simple Framework for Contrastive Learning of Visual Representations (arxiv.org) google-research/simclr: SimCLRv2 - Big Self-Supervised Models are Strong Semi-Supervised Learners (github.com) ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:4:1","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Image - BYOL [2006.07733] Bootstrap your own latent: A new approach to self-supervised Learning (arxiv.org) ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:4:2","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Speech ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:4:3","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"Speech GLUE - SUPERB Speech processing Universal PERformance Benchmark，包含了十多个下游任务，包含内容、说话的人、情感、语义等。 Toolkit：s3prl/s3prl: Self-Supervised Speech Pre-training and Representation Learning Toolkit. (github.com) https://github.com/andi611/Self-Supervised-Speech-Pretraining-and-Representation-Learning ","date":"May 16, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/:4:4","tags":null,"title":"李宏毅ML课程笔记——Self-Supervised Learning","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-supervised-learning/"},{"categories":null,"content":"李宏毅2021/2022春机器学习课程——生成式对抗网络 生成式对抗网络（GAN） ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:0:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Generator ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:1:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Network as Generator 输入$x$和一个简单的分布$z$（不固定，从一个分布中采样得到，每次使用网络时都会随机生成。），经过网络输出一个复杂的分布$y$。这样的网络称为Generator。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:1:1","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Why distribution？ 当任务需要一些“创造力”时（同样的输入有多种可能的输出），需要预测分布。 eg1. Video Prediction 输入：吃豆人游戏的历史帧序列 输出：吃豆人游戏新一帧的内容（吃豆人可能向不同的方向移动） eg2. Drawing 输入：“Character with red eyes” 输出1：酷拉皮卡 输出2：辉夜 eg3. Chatbot 输入：“你知道辉夜是谁吗？” 输出1：“她是秀知院学生会…” 输出2：“她开创了忍者时代…” ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:1:2","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Generative Adversarial Network（GAN） hindupuravinash/the-gan-zoo: A list of all named GANs! (github.com) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:2:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Anime Face Generation Unconditional generation GAN学习指南：从原理入门到制作生成Demo - 知乎 (zhihu.com) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:2:1","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Discriminator Discriminator本身也是一个网络，Discriminator拿一张图片作为输入，输出一个数值。数字越大，表示图片越接近真实的图片。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:2:2","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Basic Idea of GAN 写作敌人，念做朋友。 二者关系好比Generator造假钞，Discriminator是抓造假钞的警察，Generator越来越像，Discriminator的辨别能力越来越强。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:2:3","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Algorithm 首先初始化generator $G$和discriminator $D$，在每一次训练中： Step 1：定住$G$，更新$D$ $D$学习去给真实二次元人物赋予更高的分数，而为生成的二次元人物赋予更低的分数。 $D$分辨真正的二次元人物和生成的二次元人物之间的差异，可以当作一个分类或回归任务处理。 Step 2：定住$D$，更新$G$ $G$学习去“骗过”$D$，经过调整后，使得生成的图片能在$D$中产生更高的分数。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:2:4","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Theory behind GAN ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:3:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Objective $$ G^\\ast=\\arg\\min_G Div(P_G,P_{data}) $$ 其中$Div(P_G,P_{data})$是$P_G$与$P_{data}$之间的散度（Divergence），可以看作是两个分布之间某种距离，散度越大，代表两个分布越不像，散度越小，代表两个分布越相近。c.f. $w^\\ast,b^\\ast=\\arg\\min_{w,b}L$ ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:3:1","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Sampling 虽然不清楚$P_G$和$P_{data}$的分布，但是可以从其中采样来计算散度。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:3:2","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Discriminator [1406.2661] Generative Adversarial Networks (arxiv.org) Discriminator的训练目标是看到真实数据就给出一个高的分数，看到生成数据就给出一个低的分数。 Training：$D^\\ast=\\arg\\max_DV(D,G)$ Objective Function for $D$：$V(G,D)=E_{y\\sim P_{data}}[\\log D(y)]+E_{y\\sim P_G}[\\log(1-D(y))]$ $V(D,G)$是交叉熵的相反数，Discriminator可以等同于一个分类器，最小化交叉熵。而正好$\\max_DV(D,G)$就和JS散度有关。 最开始，$P_G$和$P_{data}$混在一起，散度很小，Discriminator难以分辨哪些数据是生成数据而哪些数据是真实数据，即Discriminator难以区分小的$max_D{V(D,G)}$。 若$P_G$和$P_{data}$散度很大，$max_DV(D,G)$比较大，DIscriminator则很容易区分生成数据和真实数据。 此时，有： $$ G^\\ast=\\arg\\min_G\\max_DV(G,D) $$ ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:3:3","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Why JS Divergence？ 除了JS散度，也可以使用例如KL散度等其他散度。如何设计目标函数，得到不同的散度，在f-GAN论文中有详细的证明。 [1606.00709] f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:3:4","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Tips for GAN ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:4:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"JS散度的问题 在大多数情况下，$P_G$和$P_{data}$重复的部分非常少。 数据本身的特性：数据是高维空间中的低维流形，重叠的部分可以忽略。 流形学习的观点认为，我们所能观察到的数据实际上是由一个低维流形映射到高维空间上的。由于数据内部特征的限制，一些高维中的数据会产生维度上的冗余，实际上只需要比较低的维度就能唯一地表示。例如单位圆上有无穷多个点，无法用二唯坐标系上的点来表示圆上所有的点，而若使用极坐标，圆心在原点的圆只需一个参数——半径，就可以确定。 采样：即使$P_G$和$P_{data}$有重叠，若采样的点不够多，对Discriminator来说也是没有重叠的。 而以上的问题会导致JS散度出现问题。 在两个分布完全不重叠时，无论两个分布的中心距离有多近，其JS散度都是一个常数$\\log2$，无法判断哪个case更好，从而无法更新参数。 参考证明：JS散度(Jensen–Shannon divergence) - MorStar - 博客园 (cnblogs.com) 直观来看，如果两个分布不重叠，二分类的准确率几乎可以达到100%。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:4:1","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Wasserstein distance 考虑两个分布$P$和$Q$，想象一台推土机，$P$是一堆土，$Q$是要堆放的目的地，把$P$挪动到$Q$的平均距离就是Wasserstein distance。 考虑更复杂的情况，移动的方案可能有无穷多种。 穷举所有的移动方法，看哪一个移动方法可以让平均的距离最小，最小的值就是Wasserstein distance。但计算方法似乎比较复杂，要计算距离还需要求解这样一个最优化问题。 假设现在我们已经可以计算Wasserstein distance，就可以解决JS散度带来的问题。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:4:2","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"WGAN WGAN使用Wasserstein distance取代JS散度。 省略过程，要得到Wasserstein distance，只需解以下这个式子： $$ \\max_{D\\in 1-Lipschitz}{E_{y\\sim P_{data}}[D(y)]-E_{y\\sim P_G}[D(y)]} $$ $D\\in 1-Lipschitz$：$D$需要是一个足够平滑的函数，不能是变动很剧烈的函数，若没有这个限制，单纯让生成数据越小越好，真实数据越大越好，在生成数据和真实数据没有重叠的情况下，会给真实数据无穷大的正值而给生成数据无穷小的负值。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:4:3","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"$D\\in 1-Lipschitz$ Original WGAN：Weight 强制参数$w$在$c$和$-c$之间，参数更新后若$w\\gt c$，则$w=c$，若$w\\lt -c$，则$w=-c$。 Improved WGAN：Gradient Penalty 在真实数据和生成数据中各取一个样本，两点连线中再取一个样本，要求这个点的梯度接近1。 [1704.00028] Improved Training of Wasserstein GANs (arxiv.org) Spectral Normalization（SNGAN）：让梯度模长在任何地方都小于1 [1802.05957] Spectral Normalization for Generative Adversarial Networks (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:4:4","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"More Tips Tops from Soumith soumith/ganhacks: starter from “How to Train a GAN?” at NIPS2016 (github.com) Tips in DCGAN：Guideline for network architecture design for image generation [1511.06434] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (arxiv.org) Improved techniques for training GANs [1606.03498] Improved Techniques for Training GANs (arxiv.org) Tips from BigGAN [1809.11096] Large Scale GAN Training for High Fidelity Natural Image Synthesis (arxiv.org) GAN的训练需要Generator和Discriminator共同配合，若有其中一方不再进步，另一方也会停下来，Generator和Discriminator需要棋逢敌手。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:4:5","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"GAN for Sequence Generation Decoder参数改变后，经过max输出的文字可能不会发生改变，就无法完成参数更新。可以用RL来训练。 [1905.09922] Training language GANs from Scratch (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:5:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"More Generative Models GAN（Full version） Variational Autoencoder（VAE） FLOW-based Model ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:6:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Evaluation of Generation ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:7:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Quality of Image 评价图像质量最直接的做法是找人来看，在Generator研究初期，有人会选几张图说“看，这个结果应该比目前的结果都要好，应该是SOTA。”，这显然不够客观，如何自动地评价生成图像的质量？ 一个方法是使用图像分类器，输入一张图片$y$，输出图片属于各个类的概率分布$p(c|y)$，分布越集中，产生的图片可能就越好。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:7:1","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Diversity - Mode Collapse 仅使用以上这种方法评估图像质量时可能会遇到Mode Collapse（模式坍塌）的问题。 训练GAN的过程可能会遇到以下问题： Generator生成出来的图片可能来来去去都是那几张： 直觉上看，这样的点是Discriminator的“盲点”，Discriminator没办法看出这样的图片是假的，当Generator学会产生这种图片后，就永远都可以骗过Discriminator。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:7:2","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Diversity - Mode Dropping Mode Dropping可能比Mode Collapse更难侦测出来，产生出来的数据可能只能贴近已有真实数据的分布，但真实的数据分布的多样性其实是更大的。 一个人脸生成的例子： ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:7:3","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Diversity 过去判定多样性的做法是将一批图片输入到图片分类器中，计算所有图片的概率分布的均值，若平均的分布非常集中，则代表多样性不够。 若输入这批图片产生的分布都非常不同，平均后的结果非常平坦，则代表多样性是足够的。 Diversity和Quality的评估方式相反，Diversity看的是一批图片的平均，而Quality看的是一张图片。 Inception Score（IS）：质量越高，多样性越大，则IS越高。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:7:4","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Fréchet Inception Distance（FID） [1706.08500] GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium (arxiv.org) 取Softmax前的输出向量，假设真实图像和生成图像都是高斯分布，计算这两个高斯分布之间的Fréchet distance，这个距离越小说明真实图像与生成图像越接近，生成图像品质越高。 可能需要大量的图片样本才能做到。 [1711.10337] Are GANs Created Equal? A Large-Scale Study (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:7:5","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"We don’t want memory GAN 生成出来的图片有可能和训练集一模一样，这种情况下FID非常小，也有可能仅仅把图片翻转，这样很难侦测出来。 [1511.01844] A note on the evaluation of generative models (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:7:6","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"More about evaluation [1802.03446] Pros and Cons of GAN Evaluation Measures (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:7:7","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Conditional Generation 前面所提到的Unconditional GAN的输入都是一个随机的分布。 例如要做文本转图片，需要给模型一个文本输入$x$。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:8:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Conditional GAN 在Unconditional GAN中，Discriminator接受一个图片$y$作为输入，输出一个数值，代表图片是真实的或是生成的，但这样的方法无法解Conditional GAN的问题，Generator可以产生非常接近真实的图片，但是忽略了输入的条件。 Conditional GAN中，需要成对的训练数据。 Conditional GAN也可以用图像来生成图像，例如图像去雾，黑白转彩色，白天转黑夜，素描转实物。也叫Image translation或pix2pix。 通常可以将GAN和有监督学习结合，得到更好的结果。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:8:1","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"其他应用 Sound-to-image Talking Head Generation [1905.08233] Few-Shot Adversarial Learning of Realistic Neural Talking Head Models (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:8:2","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Learning from Unpaired Data 有一堆$x$和一堆$y$，但$x$和$y$不成对（未标注）。pseudo labeling（伪标签）和back translation（反向翻译）都需要一些成对的数据。 例如在影像风格转换，将定义域$\\mathcal{X}$真人头像转为定义域$\\mathcal{Y}$二次元头像： ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:9:0","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Cycle GAN 输入一个Domain $\\mathcal{X}$，输出Domain $\\mathcal{Y}$。但如果仍然按照之前的方法学习，GAN无法判断生成的二次元图像是否与输入的真人图像是相似的，可能会将输入当作为高斯噪声，忽略输入的内容。 Cycle GAN中会训练两个Generator，第一个Generator $G_{\\mathcal{X}\\rightarrow \\mathcal{Y}}$将$\\mathcal{X}$ domain的图变成$\\mathcal{Y}$ domain的图，第二个Generator $G_{\\mathcal{Y}\\rightarrow \\mathcal{X}}$将$\\mathcal{Y}$ domain的图还原为$\\mathcal{X}$ domain的图。 Cycle GAN能保证真实图片和生成图片有一些关系，但如何保证这种关系是我们想要的呢？例如输入一个戴眼镜的人，$G_{\\mathcal{X}\\rightarrow \\mathcal{Y}}$将眼镜转成痣，但$G_{\\mathcal{Y}\\rightarrow \\mathcal{X}}$又会把痣转成眼镜。理论上可能会出现这样的情况，不过在实际中这种情况往往不会出现。 类似地还有Disco GAN和Dual GAN，思想与Cycle GAN基本相同。 [1703.05192] Learning to Discover Cross-Domain Relations with Generative Adversarial Networks (arxiv.org) [1704.02510] DualGAN: Unsupervised Dual Learning for Image-to-Image Translation (arxiv.org) 此外还有能够在多种风格之间转换的Star GAN： [1704.02510] DualGAN: Unsupervised Dual Learning for Image-to-Image Translation (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:9:1","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"SELFIE2ANIME Selfie2Anime [1907.10830] U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:9:2","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Text Style Transfer 文字风格转换，例如将负面的句子转为正面的句子。和Cycle GAN的做法类似。 ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:9:3","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"More Unsupervised Abstractive Summarization [1810.02851] Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks (arxiv.org) Unsupervised Translation [1710.04087] Word Translation Without Parallel Data (arxiv.org) [1710.11041] Unsupervised Neural Machine Translation (arxiv.org) Unsupervised ASR [1804.00316] Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings (arxiv.org) [1812.09323] Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching (arxiv.org) [1904.04100] Completely Unsupervised Speech Recognition By A Generative Adversarial Network Harmonized With Iteratively Refined Hidden Markov Models (arxiv.org) ","date":"May 13, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/:9:4","tags":null,"title":"李宏毅ML课程笔记——生成式对抗网络（GAN）","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"李航《统计学习方法》第2章 第2章 感知机 感知机是二类分类的线性分类模型。 感知机学习旨在求出将训练数据进行线性划分的分离超平面，为此，导入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。 ","date":"May 12, 2022","objectID":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/:0:0","tags":null,"title":"统计学习——感知机","uri":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":null,"content":"感知机模型 定义：假设输入空间是$\\mathcal{X}\\subseteq \\mathbf{R}^n$，输出空间是$\\mathcal{Y}={+1,-1}$。输入$x\\in \\mathcal{X}$表示实例的特征向量，对应于输入空间的点；输出$y\\in\\mathcal{Y}$表示实例的类别。感知机是由输入空间到输出空间的如下函数： $$ f(x)=\\text{sign}(w\\cdot x+b) $$ 其中$w$和$b$是参数，$w\\in \\mathbf{R}^n$叫做权值（weight），$b\\in \\mathbf{R}$叫做偏置（bias）。$\\text{sign}$是符号函数。 线性方程$w\\cdot x+b=0$对应于特征空间$\\mathbf{R}^n$中的一个超平面$S$，这个超平面将特征空间划分为正、负两类。 ","date":"May 12, 2022","objectID":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/:1:0","tags":null,"title":"统计学习——感知机","uri":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":null,"content":"感知机学习策略 假设训练数据集是线性可分的，感知机的学习目标是求得一个能够将训练集正、负实例点完全正确分开的分离超平面。 为了便于优化，损失函数的选择是误分类点到超平面$S$的总距离： $$ \\frac{1}{|{w}|}|w\\cdot x_0+b| $$ 其中，$|w|$是$w$的$L_2$范数。 对于误分类点有$-y_i(w\\cdot x_i+b)\\gt 0$，则所有误分类点到超平面$S$的总距离为 $$ -\\frac{1}{|w|}\\sum_{x_i\\in M}y_i(w\\cdot x_i+b) $$ 其中$M$为误分类点的集合，不考虑$\\frac{1}{|w|}$即得到感知机学习的损失函数 $$ L(w,b)=-\\sum_{x_i\\in M}y_i(w\\cdot x_i+b) $$ ","date":"May 12, 2022","objectID":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/:2:0","tags":null,"title":"统计学习——感知机","uri":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":null,"content":"感知机学习算法 ","date":"May 12, 2022","objectID":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/:3:0","tags":null,"title":"统计学习——感知机","uri":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":null,"content":"感知机学习算法的原始形式 求参数$w,b$，使其为损失函数极小化问题的解 $$ \\min_{w,b}L(w,b)=-\\sum_{x_i\\in M}y_i(w\\cdot x_i+b) $$ 感知机学习算法采用随机梯度下降法（Stochastic GD），每次随机选取一个误分类点使其梯度下降。 损失函数的梯度由下式给出： $$ \\begin{aligned} \\nabla_wL(w,b)\u0026=-\\sum_{x_i\\in M}y_ix_i \\ \\nabla_bL(w,b)\u0026=-\\sum_{x_i\\in M}y_i \\end{aligned} $$ 随机选取一个误分类点$(x_i,y_i)$对$w,b$进行更新（沿着梯度的反方向）： $$ \\begin{aligned} w\u0026\\leftarrow w+\\eta y_ix_i \\ b\u0026\\leftarrow b+\\eta y_i \\end{aligned} $$ 算法（感知机学习算法的原始形式）: 输入：训练数据集$T={(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)}$，其中$x_i\\in \\mathcal{X}=\\mathbf{R}^n$，$y_i\\in \\mathcal{Y}={-1,+1}$，$i=1,2,\\cdots,N$；学习率$\\eta(0\\lt \\eta\\leqslant 1)$； 输出：$w,b$；感知机模型$f(x)=\\text{sign}(w\\cdot x+b)$。 （1）选取初值$w_0,b_0$； （2）在训练集中选取数据$(x_i,y_i)$； （3）如果$y_i(w\\cdot x_i+b)\\leqslant 0$， $$ \\begin{aligned} w\u0026\\leftarrow w+\\eta y_ix_i \\ b\u0026\\leftarrow b+\\eta y_i \\end{aligned} $$ （4）转至（2），直至训练集中没有误分类点。 ","date":"May 12, 2022","objectID":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/:3:1","tags":null,"title":"统计学习——感知机","uri":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":null,"content":"算法的收敛性 现在证明，对于线性可分数据集，感知机学习算法原始形式收敛，即经过有限次迭代可以得到一个将训练数据集完全正确划分的分离超平面及感知机模型。 将偏置$b$并入权重向量$w$，记作$\\hat{w}=(w^T,b)^T$，同样也将输入向量$x$加以扩充，记作$\\hat{x}=(x^T,1)^T$，这样$\\hat{x}\\in \\mathbf{R}^{n+1}$，$\\hat{w}\\in \\mathbf{R}^{n+1}$，且$\\hat{w}\\cdot\\hat{x}=w\\cdot x+b$。 定理（Novikoff）：设训练数据集$T={(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)}$是线性可分的，其中$x_i\\in \\mathcal{X}=\\mathbf{R}^n$，$y_i\\in \\mathcal{Y}={-1,+1}$，$i=1,2,\\cdots,N$，则： （1）存在满足条件$|\\hat{w}{opt}|=1$的超平面$\\hat{w}{opt}\\cdot\\hat{x}=w_{opt}\\cdot x+b_{opt}=0$将训练数据集完全正确分开；且存在$\\gamma\\gt 0$，对所有的$i=1,2,\\cdots,N$ $$ y_i(\\hat{w}_{opt}\\cdot\\hat{x}i)\\geqslant\\gamma $$ （2）令$R=\\max{1\\le i\\le N}|\\hat{x}_i|$，则感知机学习算法的原始形式在训练数据集上的误分类次数$k$满足不等式 $$ k=\\left(\\frac{R}{\\gamma}\\right)^2 $$ 证明： （1）由于训练数据集线性可分，故存在超平面可将训练数据集完全正确分开，取此超平面为$\\hat{w}{opt}\\cdot\\hat{x}=0$，使$|\\hat{w}{opt}|=1$。由于对于有限的$i=1,2,\\cdots,N$，均有 $$ y_i(\\hat{w}{opt}\\cdot\\hat{x}i)\\gt 0 $$ 所以存在 $$ \\gamma=\\min_i{y_i(\\hat{w}{opt}\\cdot\\hat{x}i)} $$ 使 $$ y_i(\\hat{w}{opt}\\cdot\\hat{x}i)\\geqslant\\gamma $$ （2）感知机算法从$\\hat{w}0$开始，如果实例被误分类，则更新权重。令$\\hat{w}{k-1}$是第$k$个误分类实例之前的扩充向量权重，即 $$ \\hat{w}{k-1}=(w{k-1}^T,b_{k-1})^T $$ 则第$k$个误分类实例的条件是 $$ y_i(\\hat{w}{k-1}\\cdot\\hat{x}i)\\leqslant 0 $$ 若$(x_i,y_i)$是被$\\hat{w}{k-1}=(w{k-1}^T,b_{k-1})^T$误分类的数据，则$w$和$b$的更新是 $$ \\begin{aligned} w_k\u0026\\leftarrow w_{k-1}+\\eta y_ix_i \\ b_k\u0026\\leftarrow b_{k-1}+\\eta y_i \\end{aligned} $$ 即 $$ \\hat{w}k=\\hat{w}{k-1}+\\eta y_i\\hat{x}i $$ 下面推导两个不等式（1）和（2）： $$ \\hat{w}k\\cdot\\hat{w}{opt}\\geqslant k\\eta\\gamma \\tag{1} $$ 由式$\\hat{w}k=\\hat{w}{k-1}+\\eta y_i\\hat{x}i$及式$y_i(\\hat{w}{opt}\\cdot\\hat{x}i)\\geqslant\\gamma$得 $$ \\begin{aligned} \\hat{w}k\\cdot\\hat{w}{opt} \u0026= \\hat{w}{k-1}\\cdot\\hat{w}{opt}+\\eta y_i\\hat{w}{opt}\\cdot\\hat{x}i \\ \u0026\\geqslant \\hat{w}{k-1}\\cdot\\hat{w}{opt}+\\eta\\gamma \\end{aligned} $$ 递推即得不等式（2） $$ \\hat{w}k\\cdot\\hat{w}{opt}\\geqslant \\hat{w}{k-1}\\cdot\\hat{w}{opt}+\\eta\\gamma \\geqslant \\hat{w}{k-2}\\cdot\\hat{w}{opt}+2\\eta\\gamma\\geqslant \\cdots\\geqslant k\\eta\\gamma $$ $$ |\\hat{w}_k|^2\\leqslant k\\eta^2R^2\\tag{2} $$ 由式$\\hat{w}k=\\hat{w}{k-1}+\\eta y_i\\hat{x}i$及式$y_i(\\hat{w}{k-1}\\cdot\\hat{x}i)\\leqslant0 $得 $$ \\begin{aligned} |\\hat{w}k|^2\u0026=|\\hat{w}{k-1}|^2+2\\eta y_i\\hat{w}{k-1}\\cdot\\hat{x}i+\\eta^2|\\hat{x}i|^2 \\ \u0026\\leqslant |\\hat{w}{k-1}|^2+\\eta^2|\\hat{x}i|^2 \\ \u0026\\leqslant |\\hat{w}{k-1}|^2+\\eta^2R^2 \\ \u0026\\leqslant |\\hat{w}{k-2}|^2+2\\eta^2R^2 \\leqslant \\cdots \\ \u0026\\leqslant k\\eta^2R^2 \\end{aligned} $$ 结合式$\\hat{w}k\\cdot\\hat{w}{opt}\\geqslant k\\eta\\gamma$及式$|\\hat{w}_k|^2\\leqslant k\\eta^2R^2$即得 $$ k\\eta\\gamma \\leqslant\\hat{w}k\\cdot\\hat{w}{opt}\\leqslant|\\hat{w}k||\\hat{w}{opt}|\\leqslant \\sqrt{k}\\eta R $$ 则有 $$ k^2\\gamma^2\\leqslant kR^2 $$ 于是 $$ k\\leqslant \\left(\\frac{R}{\\gamma}\\right)^2 $$ ","date":"May 12, 2022","objectID":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/:3:2","tags":null,"title":"统计学习——感知机","uri":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":null,"content":"感知机学习算法的对偶形式 对偶形式的基本想法是，将$w$和$b$表示为实例$x_i$和标记$y_i$的线性组合的形式，通过求解其系数而求得$w$和$b$。 在感知机学习算法的原始形式中，假设初始值$w_0,b_0$均为0。假设样本点$(x_i,y_i)$在更新过程中被使用了$n_i$次，最后学习到的$w,b$可以分别表示为 $$ \\begin{aligned} w\u0026=\\sum_{i=1}^Nn_i\\eta y_ix_i \\ b\u0026=\\sum_{i=1}^Nn_i\\eta y_i \\end{aligned} $$ 考虑$n_i$，如果$n_i$的值很大，说明这个样本点经常被误分类，这意味着它离超平面距离很近，超平面稍微移动，这个点就可能被误分类，并且这样的点很可能就是支持向量。 将$w,b$代入感知机学习算法的原始形式： $$ f(x)=\\text{sign}(w\\cdot x+b)=\\text{sign}\\left(\\sum_{j=1}^Nn_j\\eta y_jx_j\\cdot x+\\sum_{j=1}^Nn_j\\eta y_i\\right) $$ 此时的学习目标从$w,b$变为$n_i$。 算法（感知机学习算法的对偶形式）： 输入：训练数据集$T={(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)}$，其中$x_i\\in \\mathcal{X}=\\mathbf{R}^n$，$y_i\\in \\mathcal{Y}={-1,+1}$，$i=1,2,\\cdots,N$；学习率$\\eta(0\\lt \\eta\\leqslant 1)$； 输出：$n$；感知机模型$f(x)=\\text{sign}\\left(\\sum_{j=1}^Nn_j\\eta y_jx_j\\cdot x+\\sum_{j=1}^Nn_j\\eta y_i\\right)$，其中$n=(n_1,n_2,\\cdots,n_N)^T$。 （1）$n\\leftarrow 0$； （2）在训练集中选取数据$(x_i,y_i)$； （3）如果$y_i\\left(\\sum_{j=1}^Nn_j\\eta y_jx_j\\cdot x_i+\\sum_{j=1}^Nn_j\\eta y_i\\right)\\leqslant0$，更新参数，将误分类次数加一： $$ n_i\\leftarrow n_i+1 $$ （4）转至（2）直至没有误分类数据。 对偶形式中训练实例仅以内积的形式出现，可以预先将训练集中实例间的内积计算出来存在矩阵中，此矩阵为Gram矩阵 $$ \\symbfit{G}=[x_i\\cdot x_j]_{N\\times N} $$ ","date":"May 12, 2022","objectID":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/:3:3","tags":null,"title":"统计学习——感知机","uri":"/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":null,"content":"李宏毅2021/2022春机器学习课程——各式各样的神奇的自注意力 Self-attention变型 Sequence length=$N$，产生的$N$个key向量和$N$个query向量两两之间做Dot-product，共$N^2$平方次计算，得到一个$N\\times N$的矩阵Attention Matrix，根据该矩阵对value向量加权求和。Self-attention往往是模型里面的一个小模块，当$N$很大时，模型的主要计算量都集中在Self-attention上，对于计算速度的优化往往都是用在影像上。 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:0:0","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Human knowledge ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:1:0","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Local Attention / Truncated Attention 某些问题不用看完整的序列，只用看左右邻居的信息即可，将其他位置的信息设为0。 可以加快运算速度，但每次做Attention只能看到某个小范围的信息，和CNN的差别就不大了。 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:1:1","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Stride Attention 与Local Attention类似，看更远的邻居，例如看三个位置之前和三个位置之后的信息。 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:1:2","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Global Attention 在原始序列中加入一些特殊的token，代表该位置要做Global Attention，Global Attention会从序列中的每一个token去收集信息。 Attend to every token -\u003e 收集所有的信息 Attended by every token -\u003e 能获取全局的信息 Global Attention有两种做法，可以从原始序列中选择一些已有的字符（例如BERT中的[CLS]标志、句号等）作为token，或外加额外的token。 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:1:3","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Papers [2004.05150] Longformer: The Long-Document Transformer (arxiv.org) [2007.14062] Big Bird: Transformers for Longer Sequences (arxiv.org) ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:1:4","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Clustering 在Attention矩阵，可能有些值很大，有些值特别小，可以直接把较小的权值置0，问题在于如何快速估计哪些地方的Attention值较高，而哪些地方的Attention值较低。 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:2:0","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Reformer Reformer: The Efficient Transformer | OpenReview [2003.05997] Efficient Content-Based Sparse Attention with Routing Transformers (arxiv.org) 步骤 Step 1：对query和key做聚类 聚类有很多可以加速的方法，对query和key做聚类时，会采取精度相对较低但速度很快的方法。 Step 2 对同一Cluster的query和key计算Attention分数 不属于同一类的直接将Attention值设为0。 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:2:1","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Learnable Patterns ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:3:0","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Sinkhorn Sorting Network [2002.11296] Sparse Sinkhorn Attention (arxiv.org) 让机器去学习两个位置的向量要不要做Attention。 Sinkhorn Sorting Network里面有一个额外需要学习的矩阵，来决定哪些地方需要计算Attention。 多个向量会共享一个矩阵以加快计算速度。（例如对于长度为100的输入，会分成10组，每组都是同一个矩阵。） ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:3:1","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Representative key Attention矩阵中有很多冗余列，往往无需$N\\times N$的Attention矩阵。 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:4:0","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Linformer [2006.04768] Linformer: Self-Attention with Linear Complexity (arxiv.org) 从$N$个key中选出最有代表性的$K$个key，只需算$N\\times K$的Attention矩阵。 Reduce Number of Keys Linformer中，对$N$的向量做线性组合： $$ M_{d\\times N}\\times M_{N\\times K}=M_{d\\times K} $$ 在Compressed Attention中的处理方式是对输入的较长序列用CNN去处理，得到一个较长的序列。 [1801.10198] Generating Wikipedia by Summarizing Long Sequences (arxiv.org) ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:4:1","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"$k,q$ first $\\rightarrow$ $v,k$ first ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:5:0","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"忽略Softmax的情况 首先不考虑Softmax的计算，Attention的计算式为： $$ O\\approx VK^TQ $$ 调整计算顺序，有： $$ O\\approx V[K^TQ]\\rightarrow O\\approx [VK^T]Q $$ 对于计算方法$O\\approx V[K^TQ]$： $A=K^TQ$：$N\\times d\\times N$ $O=VA$：$d’\\times N\\times N$ 求和：$(d+d’)N^2$ 而对于计算方法$O\\approx [VK^T]Q$： $M_1=VK^T$：$d’\\times N\\times d$ $M_2=M_1Q$：$d’\\times d\\times N$ 求和：$2d’dN$ ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:5:1","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"加回Softmax 已知存在一个$\\phi$，使得有以下式子成立： $$ \\exp(q\\cdot k)\\approx \\phi(q)\\cdot\\phi(k) $$ 则对于原始的Self-attention计算，有： $$ \\begin{aligned} b^1=\\sum_{i=1}^Na’{1,i}v^i\u0026=\\sum{i=1}^N\\frac{\\exp{(q^1\\cdot k^i)}}{\\sum_{j=1}^{N}\\exp{(q^1\\cdot k^j)}}v^i \\ \u0026=\\sum_{i=1}^N\\frac{\\phi(q^1)\\cdot\\phi(k^i)}{\\sum_{j=1}^{N}\\phi(q^1)\\cdot\\phi(k^j)}v^i \\ \u0026=\\frac{\\sum_{i=1}^{N}[\\phi(q^1)\\cdot\\phi(k^i)]v^i}{\\sum_{j=1}^{N}\\phi(q^1)\\cdot\\phi(k^j)} \\end{aligned} $$ 其中，对于分母部分： $$ \\sum_{j=1}^{N}\\phi(q^1)\\cdot\\phi(k^j)=\\phi(q^1)\\cdot\\sum_{j=1}^{N}\\phi(k^j) $$ 对于分子部分，由于： $$ \\phi(q^1)= \\begin{bmatrix} q_1^1 \\ q_2^1 \\ \\vdots \\end{bmatrix} \\quad \\phi(k^1)= \\begin{bmatrix} k_1^1 \\ k_2^1 \\ \\vdots \\end{bmatrix} $$ 则有： $$ \\begin{aligned} \u0026\\quad\\sum_{i=1}^N[\\phi(q^1)\\cdot \\phi(k^i)]v^i \\ \u0026=[\\phi(q^1)\\cdot\\phi(k^1)]v^1+[\\phi(q^1)\\cdot\\phi(k^2)]v^2+\\cdots \\ \u0026=(q_1^1k_1^1+q_2^1k_2^1+\\cdots)v^1+(q_1^1k_1^2+q_2^1k_2^2+\\cdots)v^2+\\cdots \\ \u0026=(q_1^1k_1^1v^1+q_2^1k_2^1v^1+\\cdots)+(q_1^1k_1^2v^2+q_2^1k_2^2v^2+\\cdots)+\\cdots \\ \u0026=q_1^1(k_1^1v^1+k_1^2v^2+\\cdots)+q_2^1(k_2^1v^1+k_2^2v^2+\\cdots)+\\cdots \\ \\end{aligned} $$ 设$\\phi(q^1)$的维度为$M$，则： 即在分子中的$M$个向量中，每一个向量都是通过，拿出$\\phi(k^1)$、$\\phi(k^2)$、…、$\\phi(k^N)$中的第$i$个分量，对$v^1$、$v^2$、…、$v^N$做加权和。 可以看出，每次计算$b^i$时，除了$\\phi(q^i)$以外，其他部分没有发生变化，这部分内容无需再重复计算。 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:5:2","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Self-attention中的$q$、$k$、$v$ 计算$b^1$： 产生的$M$个向量以及$\\sum_{j=1}^{N}\\phi(k^j)$在后面$b^2$、$b^3$、$b^4$的计算中无需再进行计算。 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:5:3","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"实现 关于$\\phi$的实现： [1812.01243] Efficient Attention: Attention with Linear Complexities (arxiv.org) Linear Transformers (linear-transformers.com) [2103.02143] Random Feature Attention (arxiv.org) [2009.14794] Rethinking Attention with Performers (arxiv.org) ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:5:4","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"New framework ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:6:0","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"无需$q,k$产生Attention——Synthesizer 将Attention矩阵作为网络的参数。 $$ \\begin{bmatrix} \\alpha_{1,1} \u0026 \\alpha_{1,2} \u0026 \\alpha_{1,3} \u0026 \\alpha_{1,4} \\ \\alpha_{1,2} \u0026 \\alpha_{2,2} \u0026 \\alpha_{2,3} \u0026 \\alpha_{2,4} \\ \\alpha_{1,3} \u0026 \\alpha_{2,3} \u0026 \\alpha_{3,3} \u0026 \\alpha_{3,4} \\ \\alpha_{1,4} \u0026 \\alpha_{2,4} \u0026 \\alpha_{3,4} \u0026 \\alpha_{4,4} \\ \\end{bmatrix} $$ ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:6:1","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"Attention-free [2105.03824] FNet: Mixing Tokens with Fourier Transforms (arxiv.org) [2105.08050] Pay Attention to MLPs (arxiv.org) [2105.01601] MLP-Mixer: An all-MLP Architecture for Vision (arxiv.org) ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:7:0","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"总结 ","date":"April 30, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/:8:0","tags":null,"title":"李宏毅ML课程笔记——各式各样的Attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/"},{"categories":null,"content":"一个简单的方案，lgb五折，无特征工程，仅简单处理了缺失值，CV 0.9504 LB 0.9535。 import pandas as pd import lightgbm as lgb import numpy as np from sklearn.model_selection import StratifiedKFold from sklearn.metrics import roc_auc_score flag = False if flag: train = pd.read_excel(f'data/data142927/train.xlsx') test = pd.read_excel(f'data/data142927/test_A榜.xlsx') train = train.replace('?', np.nan) test = test.replace('?', np.nan) train.to_csv(f'train.csv', index=False) test.to_csv(f'test.csv', index=False) train = pd.read_csv(f'train.csv') test = pd.read_csv(f'test.csv') train = train.fillna(-1) test = test.fillna(-1) def gen_features(df): df['MON_12_CUST_CNT_PTY_ID'] = df['MON_12_CUST_CNT_PTY_ID'].map({-1: -1, 'Y': 1}).astype(np.int8) df['WTHR_OPN_ONL_ICO'] = df['WTHR_OPN_ONL_ICO'].map({-1: -1, 'A': 1, 'B': 2}).astype(np.int8) df['LGP_HLD_CARD_LVL'] = df['LGP_HLD_CARD_LVL'].map({-1: -1, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6}).astype(np.int8) df['NB_CTC_HLD_IDV_AIO_CARD_SITU'] = df['NB_CTC_HLD_IDV_AIO_CARD_SITU'].map({-1: -1, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6}).astype(np.int8) return df def reduce_mem_usage(df): \"\"\" iterate through all the columns of a dataframe and modify the data type to reduce memory usage. \"\"\" start_mem = df.memory_usage().sum() / 1024**2 print('Memory usage of dataframe is {:.2f}MB'.format(start_mem)) for col in df.columns: col_type = df[col].dtype if col_type != object: c_min = df[col].min() c_max = df[col].max() if str(col_type)[:3] == 'int': if c_min \u003e np.iinfo(np.int8).min and c_max \u003c np.iinfo(np.int8).max: df[col] = df[col].astype(np.int8) elif c_min \u003e np.iinfo(np.int16).min and c_max \u003c np.iinfo(np.int16).max: df[col] = df[col].astype(np.int16) elif c_min \u003e np.iinfo(np.int32).min and c_max \u003c np.iinfo(np.int32).max: df[col] = df[col].astype(np.int32) elif c_min \u003e np.iinfo(np.int64).min and c_max \u003c np.iinfo(np.int64).max: df[col] = df[col].astype(np.int64) else: if c_min \u003e np.finfo(np.float16).min and c_max \u003c np.finfo(np.float16).max: df[col] = df[col].astype(np.float16) elif c_min \u003e np.finfo(np.float32).min and c_max \u003c np.finfo(np.float32).max: df[col] = df[col].astype(np.float32) else: df[col] = df[col].astype(np.float64) else: df[col] = df[col].astype('category') end_mem = df.memory_usage().sum() / 1024**2 print('Memory usage after optimization is: {:.2f}MB'.format(end_mem)) print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem)) return df train_data = reduce_mem_usage(gen_features(train)) test_data = reduce_mem_usage(gen_features(test)) drop_features = ['CUST_UID', 'LABEL'] features = [c for c in train_data.columns if c not in drop_features] target = train_data['LABEL'] nfold = 5 oof_preds = np.zeros((train_data.shape[0])) oof_label = np.zeros(train_data.shape[0]) test_preds = pd.DataFrame({'CUST_UID': test_data['CUST_UID'], 'LABEL': np.zeros(len(test_data))}, columns=['CUST_UID', 'LABEL']) feature_importance_df = pd.DataFrame() folds = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=42) for i, (trn_idx, val_idx) in enumerate(folds.split(train_data, target)): print('---------- fold', i + 1, '----------') trn_X, val_X = train_data[features].iloc[trn_idx, :], train_data[features].iloc[val_idx, :] trn_y, val_y = target[trn_idx], target[val_idx] dtrn = lgb.Dataset(trn_X, label=trn_y) dval = lgb.Dataset(val_X, label=val_y) parameters = { 'learning_rate': 0.01, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'num_leaves': 63, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'min_data_in_leaf': 32, 'verbose': -1, 'nthread': 12 } lgb_model = lgb.train( parameters, dtrn, num_boost_round=2000, valid_sets=[dval], early_stopping_rounds=100, verbose_eval=100, ) oof_preds[val_idx] = lgb_model.predict(val_X[features], num_iteration=lgb_model.best_iteration) oof_label[val_idx] = val_y test_preds['LABEL'] += lgb_model.predict(test_data[features], num_iteration=lgb_model.best_iteration) / nfold fold_importance_df = pd.DataFrame() fold_importance_df[\"feature\"] = features fol","date":"April 29, 2022","objectID":"/2022%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93%E9%A6%96%E6%97%A5%E5%9F%BA%E7%BA%BF/:0:0","tags":null,"title":"2022招商银行FinTech精英训练营 数据赛道首日基线","uri":"/2022%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93%E9%A6%96%E6%97%A5%E5%9F%BA%E7%BA%BF/"},{"categories":null,"content":"李宏毅2021/2022春机器学习课程——Transformer Transformer Transformer是一个Sequence-to-sequence（Seq2seq）的模型，输出的长度由模型自己来决定。 ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:0:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Sequence-to-sequence ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:1:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"应用 Maching Translation Speech Translation Text-to-Speech（TTS） Questions Answering（QA） 大部分自然语言处理问题可以看作是QA（Question：这个句子的翻译是什么？；Context：一个句子；Answer：翻译结果）。 $$ \\text{question}, \\text{context} \\stackrel{Seq2seq}{\\longrightarrow} \\text{answer} $$ Multi-label Classification $$ \\text{data} \\stackrel{Seq2seq}{\\longrightarrow} \\text{class 7, class 9, class 13} $$ [1909.03434] Order-free Learning Alleviating Exposure Bias in Multi-label Classification (arxiv.org) [1707.05495] Order-Free RNN with Visual Attention for Multi-Label Classification (arxiv.org) Object Detection [2005.12872] End-to-End Object Detection with Transformers (arxiv.org) ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:1:1","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"结构 $$ \\text{Encoder}\\longrightarrow \\text{Decoder} $$ [1409.3215] Sequence to Sequence Learning with Neural Networks (arxiv.org) [1706.03762] Attention Is All You Need (arxiv.org) ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:1:2","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Encoder 输入一排向量：${x^1,x^2,x^3,x^4}$ 输出一排向量：${h^1,h^2,h^3,h^4}$ Self-attention、RNN、CNN…均可用来作为Encoder。 ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:2:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Transformer Encoder 在Transformer Encoder中，加入了Residual Connection，经过Self-attention输出的向量加上原输入的向量后当作新的输出向量。 得到Residual的结果以后，进行Normalization，但此处使用的是Layer Normalization而非Batch Normalization。对于输入的向量，Layer Norm会计算它的均值$m$和标准差$\\sigma$，与Batch Norm不同点在于，Batch Norm是对不同特征、样本的同一个维度计算均值和标准差，而Layer Norm是对同一个特征、样本的不同维度去计算均值和标准差。 Layer Norm的结果将作为FC的输入，经过FC Network得到新的向量，在FC层也同样地加入了Residual Connection，得到的结果再做一次Layer Norm，则得到了此Block的输出。 即一个Block的结构如下： 此Block会重复N次，组成Transformer的Encoder，BERT与Transformer Encoder采用了相同的结构。 ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:2:1","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"More [2002.04745] On Layer Normalization in the Transformer Architecture (arxiv.org) [2003.07845] PowerNorm: Rethinking Batch Normalization in Transformers (arxiv.org) ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:2:2","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Decoder——Autoregressive（AT） ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:3:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Decoder的运作方式 除了Encoder产生的输出以外，Decoder中还会加入一个BOS（Begin of Sequence）符号（token），用来表示开始，BOS token是一个One-hot表示的向量。 输出一个向量，向量的长度应该和Vocabulary Size相等来表示所有的汉字（对于中文，Vocabulary Size就是所有汉字的数量），每一个中文对应向量中的一个数值，这个向量是经过Soft-max得到的，取最大的作为输出的文字，Decoder会将这个输出的文字的One-hot向量作为新的输入。 但是按照这样的运作方式，后面会产生无穷尽的文字，像文字接龙一样一直不能停下来，所以，还应该加一个EOS（End of Sequence） token来表示文字的结束，一般情况下，EOS token和BOS token都用一个相同的向量来表示，故向量的长度应该为Vocabulary Size + 1。 在这种运作方式下，某步的错误预测可能影响后面的预测（“一步错，步步错。”），具体参考最后一节Scheduled Sampling。 ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:3:1","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Transformer Decoder Transformer中的Decoder和Encoder结构类似，除中间的Multi-Head Attention和Add \u0026 Norm结构外，在第一次Multi-Head Attention计算中加入了Mask。 Masked Self-attention 在产生$b^1$的时候，只能考虑$a^1$的信息，而不能考虑$a^2$、$a^3$、$a^4$的信息；在产生$b^2$的时候，只能考虑$a^1$、$a^2$的信息，而不能考虑$a^3$、$a^4$的信息。 具体来说，在产生$b^2$时，只会拿第二个位置的query去跟第一个位置的key和第二个位置的key来计算Attention，而不管第三、四个位置的key。 对于Decoder而言，先有$a^1$才有$a^2$，才有接下来的$a^3$、$a^4$，计算$b^2$的时候无法考虑$a^3$、$a^4$。 ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:3:2","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Decoder——Non-autoregressive（NAT） ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:4:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"AT v.s. NAT AT分别输入BOS token、$w_1$、$w_2$、$w_3$、EOS token，而NAT一次输入一整排BOS token。 优点： 并行 输出长度可控 问题：模型如何知道输出的长度，从而确定输入的BOS token的数量？ 用一个模型来预测输出长度； 输出一个很长的句子，忽略EOS token以后的内容。 NAT的表现往往比AT要差（Multi-modality）。 ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:4:1","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Encoder-Decoder Transformer中由Cross Attention模块来连接Encoder和Decoder。该模块接收Encoder的两个输出和Decoder的一个输出作为输入。 将BOS token输入到Decoder的Masked Self-attention模块后，将输出的向量进行线性变换得到query $q$，再将$q$与Encoder中的key $k^1$、$k^2$、$k^3$计算Attention分数，与value $v^1$、$v^2$、$v^3$相乘加权求和得到$v$。 Cross Attention比Self-Attention出现要更早。 Listen, attend and spell: A neural network for large vocabulary conversational speech recognition | IEEE Conference Publication | IEEE Xplore Transformer中，Decoder中每一层都与Encoder的最后一层做Cross Attention，也有论文的工作中尝试了与其他层的不同的连接方式。 [2005.08081] Layer-Wise Multi-View Decoding for Improved Natural Language Generation (arxiv.org) ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:5:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Training 以下以一段标签为“机器学习”的语音数据为例。 在Decoder中输入BOS token后，输出的向量应该和“机”对应的向量越接近越好，即通过计算两个向量的交叉熵，交叉熵越小越好，这个过程和分类非常相似。 包括最后一个EOS token，模型希望最后一个字所输出的内容与EOS token的One-hot向量是接近的。 在训练过程中，Decoder的输入是真实标签，训练过程中会给Decoder看正确答案，即给Decoder输入BOS token和“机”以后，希望模型的输出是“器”，给Decoder输入BOS token、“机”和“器”之后，希望模型输出的是“学”。这种方法叫做Teacher Forcing，将正确答案作为输入。 训练时Decoder可以看到完全正确的信息，而测试的时候Decoder可能会看到一些错误的信息，可能会导致“一步错，步步错。”，训练与测试不一致的现象叫做exposure bias，方法是在学习时，给Decoder的输入加入一些错误的信息，具体参考最后一节Scheduled Sampling。 ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:6:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Tips ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:7:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Copy Mechanism 某些信息并不需要机器来学习，可能是从输入信息中复制出来，例如聊天机器人中： eg1 User：你好，我是库洛洛。 Machine：库洛洛你好，很高兴认识你。 eg2 User：小杰不能使用念能力了！ Machine：你所谓的*「不能使用念能力」*是什么意思？ 又例如从文章中提取摘要这一任务，从文章中复制一些信息是很模型很关键的能力。 [1704.04368] Get To The Point: Summarization with Pointer-Generator Networks (arxiv.org) [1603.06393] Incorporating Copying Mechanism in Sequence-to-Sequence Learning (arxiv.org) ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:7:1","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Guided Attention 在一些任务中（例如语音辨识、TTS等），对于输入的每一个内容都要看到，不能漏掉某些信息。 Guided Attention要求机器以特定的方式完成Attention的计算，应该由左向右分别产生输出。例如在TTS中，应该先看最左边的文字产生输出，最后看最右的文字产生输出。 Monotonic Attention Location-aware attention ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:7:2","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Beam Search 要找到最优解，暴力搜索难以计算。通过Beam Search找一个不是完全精准的解。 [1904.09751] The Curious Case of Neural Text Degeneration (arxiv.org) 假设一个任务的答案非常明确，Beam Search会比较有帮助，但对于一些答案不唯一的任务（例如文本补全），分数最高的路径可能结果并不是很好，往往需要在Decoder中加入随机性（noise）。 ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:7:3","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Optimizing Evaluation Metrics 训练时使用交叉熵，在评估时使用BLEU。BLEU不可微分，无法作为Loss。不过对于无法优化的Loss，可以将其当作Reinforcement Learning（RL）的reward，Decoder作为Agent，将其看作是RL问题来解决。 ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:8:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"Scheduled Sampling Schedule可能会影响计算的并行化，对于Transformer的Scheduled Sampling另有方法。 [1506.03099] Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks (arxiv.org) [1906.07651] Scheduled Sampling for Transformers (arxiv.org) [1906.04331] Parallel Scheduled Sampling (arxiv.org) ","date":"April 25, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/:9:0","tags":null,"title":"李宏毅ML课程笔记——Transformer","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0transformer/"},{"categories":null,"content":"李宏毅2021/2022春机器学习课程——自注意力机制（Self-attention） 自注意力机制（Self-Attention） 考虑两种不同的输入： 输入是一个向量 输入是一排向量（输入的向量个数可能会改变） ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:0:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"将一排向量作为输入 ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:1:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"方法 One-hot Encoding Word Embedding ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:1:1","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"输入 一段语音窗口 一张图 分子结构 … ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:1:2","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"输出 N个向量对应N个标签 句子中每个词的词性：I saw a saw -\u003e N V DET N 社交网络中每个人的购买意向：甲 -\u003e buy;乙 -\u003e not N个向量对应一个标签 情感分析：this is good -\u003e positive 分子属性分析：一个分子图 -\u003e 亲水性 N个向量对应多个标签（seq2seq） 机器翻译 ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:1:3","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"Fully-connected Network 使用全连接网络，设置窗口大小，每次输入邻近的多个词。但限制于窗口大小，无法考虑整个句子的影响，且窗口覆盖整个句子比较困难。 ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:2:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"Self-attention 例： 输入：一排向量${a^1,a^2,a^3,a^4}$ 输出：一排向量${b^1,b^2,b^3,b^4}$ $b^1$、$b^2$、$b^3$、$b^4$分别都是考虑了$a^1$、$a^2$、$a^3$、$a^4$而产生的。 ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:3:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"如何生成$b^1$？ $a^1$与其他向量的相关性$\\alpha$的计算方法 Dot-product 输入两个向量，分别与矩阵$W^q$和$W^k$相乘，再将得到的向量$q$和$k$做点乘。 $$ \\begin{aligned} q\u0026=a^1\\times W^q \\\\ k\u0026=a^2\\times W^k \\\\ \\alpha \u0026= q\\cdot k \\end{aligned} $$ Additive 输入两个向量，分别与矩阵$W^q$和$W^k$相乘，将得到的向量$q$和$k$串起来并通过激活函数，最后通过一个变换得到$alpha$。 $b^1$的计算 本节中的例子中，对于$b^1$，计算步骤如下： step1.计算$q^1$ $$ q^1=W^qa^1 $$ step2.计算$k^1$、$k^2$、$k^3$、$k^4$ $$ k^i=W^ka^i $$ step3.计算$\\alpha_{1,1}$、$\\alpha_{1,2}$、$\\alpha_{1,3}$、$\\alpha_{1,4}$ $$ \\alpha_{1,i}=q^1\\cdot k^i \\ $$ step4.通过Soft-max（也可使用ReLU等）计算$\\alpha_{1,1}’$、$\\alpha_{1,2}’$、$\\alpha_{1,3}’$、$\\alpha_{1,4}'$ $$ \\alpha_{1,i}’=\\frac{\\exp(\\alpha_{1,i})}{\\sum_j\\exp(\\alpha_{1,j})} $$ step5.计算$v^1$、$v^2$、$v^3$、$v^4$ $$ v^i=W^va^i $$ step6.计算$b^1$（根据Attenion分数抽取重要信息） $$ b^1=\\sum_j\\alpha_{1,j}‘v^j $$ ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:3:1","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"输出向量组${b^1,b^2,b^3,b^4}$的完整计算过程 整理以上过程，$Q$、$K$、$V$和Attention分数的计算过程如下： $Q$、$K$、$V$的计算 由： $$ \\begin{aligned} q^i \u0026=W^qa^i \\ k^i \u0026=W^ka^i \\ v^i \u0026=W^va^i \\end{aligned} $$ 有： $$ \\begin{aligned} \\begin{bmatrix} q^1 \u0026 q^2 \u0026 q^3 \u0026 q^4 \\end{bmatrix} \u0026=W^q \\begin{bmatrix} a^1 \u0026 a^2 \u0026 a^3 \u0026 a^4 \\end{bmatrix} \\ \\begin{bmatrix} k^1 \u0026 k^2 \u0026 k^3 \u0026 k^4 \\end{bmatrix} \u0026=W^k \\begin{bmatrix} a^1 \u0026 a^2 \u0026 a^3 \u0026 a^4 \\end{bmatrix} \\ \\begin{bmatrix} v^1 \u0026 v^2 \u0026 v^3 \u0026 v^4 \\end{bmatrix} \u0026=W^v \\begin{bmatrix} a^1 \u0026 a^2 \u0026 a^3 \u0026 a^4 \\end{bmatrix} \\end{aligned} $$ 即： $$ \\begin{aligned} Q\u0026=W^qI \\ K\u0026=W^kI \\ V\u0026=W^vI \\end{aligned} $$ Attention分数的计算 由： $$ \\alpha_{1,i}=k^i\\cdot q^1 \\ $$ 有： $$ \\begin{bmatrix} \\alpha_{1,1} \\ \\alpha_{1,2} \\ \\alpha_{1,3} \\ \\alpha_{1,4} \\end{bmatrix} \\begin{bmatrix} k^1 \\ k^2 \\ k^3 \\ k^4 \\end{bmatrix} \\cdot q^1 $$ 进一步有： $$ \\begin{bmatrix} \\alpha_{1,1} \u0026 \\alpha_{2,1} \u0026 \\alpha_{3,1} \u0026\\alpha_{4,1} \\ \\alpha_{1,2} \u0026 \\alpha_{2,2} \u0026 \\alpha_{3,2} \u0026\\alpha_{4,2} \\ \\alpha_{1,3} \u0026 \\alpha_{2,3} \u0026 \\alpha_{3,3} \u0026\\alpha_{4,3} \\ \\alpha_{1,4} \u0026 \\alpha_{2,4} \u0026 \\alpha_{3,4} \u0026\\alpha_{4,4} \\ \\end{bmatrix} \\begin{bmatrix} k^1 \\ k^2 \\ k^3 \\ k^4 \\end{bmatrix} \\cdot \\begin{bmatrix} q^1 \u0026 q^2 \u0026 q^3 \u0026q^4 \\end{bmatrix} $$ 即： $$ A=K^TQ $$ 对$A$进行Soft-max得到$A’$： $$ A’= \\begin{bmatrix} \\alpha_{1,1}’ \u0026 \\alpha_{2,1}’ \u0026 \\alpha_{3,1}’ \u0026\\alpha_{4,1}’ \\ \\alpha_{1,2}’ \u0026 \\alpha_{2,2}’ \u0026 \\alpha_{3,2}’ \u0026\\alpha_{4,2}’ \\ \\alpha_{1,3}’ \u0026 \\alpha_{2,3}’ \u0026 \\alpha_{3,3}’ \u0026\\alpha_{4,3}’ \\ \\alpha_{1,4}’ \u0026 \\alpha_{2,4}’ \u0026 \\alpha_{3,4}’ \u0026\\alpha_{4,4}’ \\ \\end{bmatrix} $$ 最后将$V$与$A’$相乘，得到$b^1$、$b^2$、$b^3$、$b^4$： $$ \\begin{bmatrix} b^1 \u0026 b^2 \u0026 b^3 \u0026 b^4 \\end{bmatrix} \\begin{bmatrix} v^1 \u0026 v^2 \u0026 v^3 \u0026 v^4 \\end{bmatrix} \\cdot \\begin{bmatrix} \\alpha_{1,1}’ \u0026 \\alpha_{2,1}’ \u0026 \\alpha_{3,1}’ \u0026\\alpha_{4,1}’ \\ \\alpha_{1,2}’ \u0026 \\alpha_{2,2}’ \u0026 \\alpha_{3,2}’ \u0026\\alpha_{4,2}’ \\ \\alpha_{1,3}’ \u0026 \\alpha_{2,3}’ \u0026 \\alpha_{3,3}’ \u0026\\alpha_{4,3}’ \\ \\alpha_{1,4}’ \u0026 \\alpha_{2,4}’ \u0026 \\alpha_{3,4}’ \u0026\\alpha_{4,4}’ \\ \\end{bmatrix} $$ 即得到Self-attention的输出： $$ O=VA’ $$ 总结 $$ \\begin{aligned} \u0026Q=W^qI \\ \u0026K=W^kI \\ \u0026V=W^vI \\ \u0026A=K^TQ \\ \u0026A \\rightarrow A’ \\ \u0026O=VA' \\end{aligned} $$ $W^q$、$W^k$、$W^v$是需要学习的参数。 ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:3:2","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"Multi-head Self-attention 多个$q$，对应不同种类的相关性。 例如对于2 head的情况，$a^i$对应的$q^i$、$k^i$、$v^i$具体有$q^{i,1}$、$k^{i,1}$、$v^{i,1}$： $$ \\begin{aligned} \u0026q^{i,1}=W^{q,1}q^i \\ \u0026q^{i,2}=W^{q,2}q^i \\end{aligned} $$ 类似的，$a^j$对应的$q^j$、$k^j$、$v^j$具体有$q^{j,1}$、$k^{j,1}$、$v^{j,1}$： 在使用Dot-product计算Attention分数时，使用对应的$q$和$k$进行计算，$q^{i,1}$分别和$k^{i,1}$、$k^{j,1}$进行计算，在将Attention分数分别和$v^{i,1}$、$v^{j,1}$计算，得到$b^{i,1}$，类似可得到$b^{i,2}$。 $$ b^i=W^O \\begin{bmatrix} b^{i,1} \\ b^{i,2} \\end{bmatrix} $$ ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:4:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"位置编码 Self-attention中，对输入的几个向量所进行的操作是相同的，与位置无关，可能丢失了位置信息。 为每一个位置都设定一个向量$e^i$，将该向量加到$a^i$上。 $$ e^i+a^i\\rightarrow q^i,k^i,v^i $$ 向量$e^i$可以通过一个规则设定（人工）或从训练数据中学习出来。 有各种不同的方法产生位置编码： Sinusoidal Position embedding FLOATER RNN … ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:5:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"Self-attention用于语音 把声音讯号表示为一排向量，一般一个向量只有10ms的长度，会导致向量个数过多，$A’$计算的复杂度是$O(L^2)$，一般使用Truncated Self-attention，不看一整句话，只看一小部分。 ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:6:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"Self-attention用于图像 一张图片可以看成是一排向量。 Self-Attention GAN Detection Transformer(DETR) ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:7:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"Self-attention v.s. CNN Self-attention可以看作复杂化的CNN，Self-attention考虑全局。CNN是Self-attention的特例，Self-attention可以通过设定合适的参数，达到和CNN同样的效果。 [1911.03584] On the Relationship between Self-Attention and Convolutional Layers (arxiv.org) ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:8:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"Self-attention v.s. RNN RNN（Recurrent Neural Network）： RNN的缺点很明显，很难去考虑到输入位置较远的向量，并且无法并行计算。 [2006.16236] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention (arxiv.org) ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:9:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"Self-attention用于图 图中每个结点可以表示为一个向量，边可以用来考虑结点之间的关联性，计算Attention分数时，只需计算相连的结点。 Self-attention用在图上面，是某一种类型的GNN（Graph Neural Network）。 ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:10:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"More Self-Attention的计算量较大，优化效率是一个研究方向。 [2011.04006] Long Range Arena: A Benchmark for Efficient Transformers (arxiv.org) [2009.06732] Efficient Transformers: A Survey (arxiv.org) ","date":"April 23, 2022","objectID":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/:11:0","tags":null,"title":"李宏毅ML课程笔记——Self-attention","uri":"/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/"},{"categories":null,"content":"最近想给博客写一个相册界面，在网络找了一些实现方式但都不太满意，然而自己的前端基础几乎为零，只能拿此前生成的博客页面里的HTML源代码来参考，正好Fancybox也非常合适。找学过前端的室友请教了一下之后，魔改了一番此前博文的HTML代码，效果还不错，故在此分享一下我的实现方式。 本文所提出的方案中，图片的存储基于阿里云OSS对象存储实现。 效果图 缩略图生成 考虑到原图像的占用空间较大，直接在页面引入原图可能会严重拖慢内容加载速度，故对于原图像可以先进行适当的缩小以减少占用空间，而在点击图像后查看大图的情况下再加载原图。 这里提供一个我个人实现的图片裁切程序，基于Python+OpenCV实现，也可以点击此处直接下载。 import os import cv2 def resize(img, t): h, w = img.shape[0], img.shape[1] if(h \u003e w): img = cv2.copyMakeBorder(img, 0, 0, int((h - w) / 2), int((h - w) / 2), cv2.BORDER_CONSTANT, value=[255, 255, 255]) img = cv2.resize(img, (t, t)) else: img = cv2.copyMakeBorder(img, int((w - h) / 2), int((w - h) / 2), 0, 0, cv2.BORDER_CONSTANT, value=[255, 255, 255]) img = cv2.resize(img, (t, t)) return img imgList = os.listdir(f\"./raw\") for i in imgList: img = cv2.imread(f\"./raw/{i}\") cv2.imwrite(f\"./images/{i}\", img) img = resize(img, 512) cv2.imwrite(f\"./images-s/{i}\", img) 此段程序的实现逻辑是对于raw文件夹下的每一张图片，先在images文件夹下保存图片（可以抹除图片中的地理位置等信息），再对图片进行如下处理： 获取图像的宽度、高度，并比较大小； 根据比较的结果将较小的一边进行填充以成为一张正方形的图片； 将图片缩放到目标宽度，并保存在images-s文件夹下。 文件树如下： ./ ├─images ├─images-s ├─raw └─run.py 将需要处理的图片放在raw文件夹后执行run.py即可，会在images文件夹和images-s文件夹中分别生成同名的原图和缩略图。 图片存储 由于相关文档已经非常详细，故关于阿里云OSS对象存储的基本使用本文不再赘述。 对于原图和缩略图的存储，我在Bucket中建立了两个文件夹：gallery和gallery-s，分别存储原图和缩略图。 建立完成后，将上一步骤中的处理结果分别放在两个文件夹中即可。 页面生成 首先： 在Hexo中生成新的Page hexo new page gallery 在Next的主题配置文件中的menu项加入相关链接 menu: + gallery: /gallery/ || fa fa-camera （可选）languages下zh-CN.yml文件中加入对应中英文对照。 页面样式 在root/source/_data/styles.styl中加入如下代码： /*gallery*/ .gallery-page { margin-top: -50px; } .img-list, .gallery-list { display: flex; flex-direction: row; flex-wrap: nowrap; align-items: flex-start; } .img-column { display: flex; flex-direction: column-reverse; } .img-column a, .gallery-column a { border-bottom: 0px; } .gallery-item { margin-bottom: -50px } .gallery-item p { margin: -25px auto -10px; max-width: 50%; text-align: center; font-size: 15px; color: $black-deep; background: rgba(255,255,255,.3); border-radius: 7px; border: 1px solid $black-deep; box-shadow: 0 8px 20px -8px rgba(0,0,0,.3); } .posts-expand .post-body .gallery-column a img { height: 250px; width: 300px; object-fit: cover; } @media (max-width: 767px){ .gallery-item p { min-width: 75px; font-size: 13px; } } ","date":"March 5, 2022","objectID":"/hexo%E4%B8%ADnext%E4%B8%BB%E9%A2%98%E4%B8%8B%E5%9F%BA%E4%BA%8Efancybox%E7%9A%84%E7%9B%B8%E5%86%8C%E9%A1%B5%E9%9D%A2%E5%AE%9E%E7%8E%B0/:0:0","tags":null,"title":"Hexo中NexT主题下基于Fancybox的相册页面实现","uri":"/hexo%E4%B8%ADnext%E4%B8%BB%E9%A2%98%E4%B8%8B%E5%9F%BA%E4%BA%8Efancybox%E7%9A%84%E7%9B%B8%E5%86%8C%E9%A1%B5%E9%9D%A2%E5%AE%9E%E7%8E%B0/"},{"categories":null,"content":"为图片四周加上阴影 可在源代码中加入如下样式： .img { -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); } 注：自从 NexT-7.3.0 开始，官方推荐采用数据文件将配置与主题分离，以在不修改主题源码的同时完成选项配置、自定义布局、自定义样式，便于后续 NexT 版本更新。 页面内容 Fancybox文档中给出了一段基础代码示例： \u003ca href=\"image.jpg\" data-fancybox data-caption=\"My caption\"\u003e \u003cimg src=\"thumbnail.jpg\" alt=\"\" /\u003e \u003c/a\u003e 其中image.jpg为原图，thumbnail.jpg为缩略图。 下面给出我所修改的代码示例（可直接在对应的md文件中编写）： \u003clink rel=\"stylesheet\" href=\"//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css\"\u003e \u003cscript src=\"//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js\"\u003e\u003c/script\u003e \u003cdiv class=\"gallery-page\"\u003e \u003c!--2--\u003e \u003cdiv class=\"img-list\"\u003e \u003ca class=\"img\" data-fancybox=\"gallery\" href=\"6.jpg\" data-caption=\"caption 6\"\u003e \u003cimg src=\"6-s.jpg\"\u003e \u003cp class=\"image-caption\"\u003e6\u003c/p\u003e \u003c/a\u003e \u0026nbsp; \u003ca class=\"img\" data-fancybox=\"gallery\" href=\"5.jpg\" data-caption=\"caption 5\"\u003e \u003cimg src=\"5-s.jpg\"\u003e \u003cp class=\"image-caption\"\u003e5\u003c/p\u003e \u003c/a\u003e \u0026nbsp; \u003ca class=\"img\" data-fancybox=\"gallery\" href=\"4.jpg\" data-caption=\"caption 4\"\u003e \u003cimg src=\"4-s.jpg\"\u003e \u003cp class=\"image-caption\"\u003e4\u003c/p\u003e \u003c/a\u003e \u003c/div\u003e \u003cbr\u003e \u003c!--1--\u003e \u003cdiv class=\"img-list\"\u003e \u003ca class=\"img\" data-fancybox=\"gallery\" href=\"3.jpg\" data-caption=\"caption 3\"\u003e \u003cimg src=\"3-s.jpg\"\u003e\u003c/a\u003e \u003cp class=\"image-caption\"\u003e3\u003c/p\u003e \u0026nbsp; \u003ca class=\"img\" data-fancybox=\"gallery\" href=\"2.jpg\" data-caption=\"caption 2\"\u003e \u003cimg src=\"2-s.jpg\"\u003e\u003c/a\u003e \u003cp class=\"image-caption\"\u003e2\u003c/p\u003e \u0026nbsp; \u003ca class=\"img\" data-fancybox=\"gallery\" href=\"1.jpg\" data-caption=\"caption 1\"\u003e \u003cimg src=\"1-s.jpg\"\u003e\u003c/a\u003e \u003cp class=\"image-caption\"\u003e1\u003c/p\u003e \u003c/div\u003e \u003c/div\u003e 不足之处 图片的生成、上传及页面HTML代码的编辑较为繁琐； 图片无法根据页面宽度等自适应换行，在小屏幕设备上缩略图可能比较拥挤。 参考链接 Hexo-NexT 实现相册 | 小丁的个人博客 ","date":"March 5, 2022","objectID":"/hexo%E4%B8%ADnext%E4%B8%BB%E9%A2%98%E4%B8%8B%E5%9F%BA%E4%BA%8Efancybox%E7%9A%84%E7%9B%B8%E5%86%8C%E9%A1%B5%E9%9D%A2%E5%AE%9E%E7%8E%B0/:1:0","tags":null,"title":"Hexo中NexT主题下基于Fancybox的相册页面实现","uri":"/hexo%E4%B8%ADnext%E4%B8%BB%E9%A2%98%E4%B8%8B%E5%9F%BA%E4%BA%8Efancybox%E7%9A%84%E7%9B%B8%E5%86%8C%E9%A1%B5%E9%9D%A2%E5%AE%9E%E7%8E%B0/"},{"categories":null,"content":"在此对阮秋琦著的《数字图像处理学》（第三版）中的部分基础概念及习题进行总结。 第一章 绪论 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:0:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"本章内容 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:1:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"图像处理技术的分类 模拟图像处理：包括光学处理（利用透镜）和电子处理，如照相、遥感图像处理、电视信号处理等。速度快，但精度、灵活性较差。 数字图像处理：一般都用计算机处理或实时的硬件处理。精度高，但处理速度还有待提高。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:1:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"数字图像处理的特点 图像信息量大 一幅图像每个像素的灰度级至少要用$6\\ bit$表示，一般采用$8\\ bit$（彩色图像），高精度的可用$12\\ bit$或$16\\ bit$。一般分辨率的图像像素数为$256\\times 256$像素、$512\\times 512$像素，高分辨率图像可达$1024\\times 1024$像素或$2048\\times 2048$像素。 图像处理技术综合性强 数字图像处理中涉及的基础知识和专业技术相当广泛。一般来说涉及通信技术、计算机技术、电子技术、电视技术，至于涉及的数学、物理等方面的基础知识就更多。 图像信息理论与通信理论密切相关 图像理论是把通信中的一维时间问题推广到二维空间上来研究的。通信研究的是一维时间信息，是时间域和频率域的问题；图像研究的是二维空间信息，是空间域和空间频率域（或变换域）之间的关系。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:1:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"数字图像处理方法 见思考题1 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:1:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"数字图像处理的主要内容 见思考题3 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:1:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"数字图像处理的硬件设备 一般的数字图像处理系统如下所示： $$ \\begin{aligned} 输入设备\\rightarrow A/D（模拟数字转换器） \\rightarrow \u0026计算机 \\rightarrow D/A（数字模拟转换器） \\rightarrow 图像显示器 \\ \u0026 \\uparrow\\downarrow\\ \u0026键盘监视器 \\end{aligned} $$ 早期的数字图像处理系统为提高处理速度，增加容量，都采用大型机，后来较普遍发展小型机为主的系统。 现在的图像处理系统向微型图像处理系统和大型机两个方向发展。 要从根本上解决处理能力、速度与数据量巨大的问题，还应该发展阵列机和并行处理技术。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:1:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"数字图像处理的应用 见思考题7 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:1:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"数字图像处理领域的发展动向 见思考题8 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:1:7","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"思考题 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:2:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"1. 图像处理的主要方法分几大类？ 数字图像处理方法大致可分为两大类，即空域法和变换域法。 空域法 把图像视为平面中各个像素组成的集合，然后直接对这个二维函数进行相应的处理。 空域处理法主要有两大类： 邻域处理法 梯度运算、拉普拉斯算子运算、平滑算子运算和卷积运算等。 点处理法 灰度处理，面积、周长、体积和重心运算等。 变换域法 首先对图像进行正交变换，得到变换域系数阵列，然后再施各种处理，处理后再将其反变换到空间域，得到处理结果。 包括滤波、数据压缩、特征提取等处理。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:2:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"2. 图像处理工程包括哪几项内容？ 完整的数字图像处理工程大体上可分为： 图像信息的获取 图像信息的存储 图像信息的传送 图像信息的处理 图像信息的输出与显示 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:2:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"3. 数字图像处理的主要内容是什么？试说明它们的基本用途。 数字图像处理概括地说，主要包括： 几何处理 坐标变换，图像的放大、缩小、旋转、移动，多个图像配准，全景畸变校正，扭曲校正，周长、面积、体积计算等。 其中图像配准涉及众多的数学变换问题，在医学图像处理中具有重要的应用价值。 算术处理 对图像施以加、减、乘、除等运算。 如医学图像的减影处理有显著的效果。 图像增强 突出图像中感兴趣的信息，而减弱或去除不需要的信息，从而使有用信息得到加强，便于区分或解释。 主要方法包括直方图修改技术、伪彩色增强法、灰度窗口、图像平滑、图像尖锐化处理、同态处理等技术。 图像复原 去掉干扰和模糊，恢复图像的本来面目。 典型的例子如去噪就属于复原处理。 图像重建 以上四项都是从图像到图像的处理，而重建是从数据到图像的处理，即输入的是某种数据，而处理结果得到的是图像。 该处理的典型应用就是CT技术，早期为X光CT，后来发展有ECT、超声CT、核磁共振（NMR）等。 图像编码 主要宗旨是利用图像信号的统计特性及人类视觉的生理学及心理学特性对图像信号进行高效编码，即研究数据压缩技术，以解决数据量大的矛盾。一般来说，图像编码的目的有三个： 减少数据存储量 降低数据率以减少传输带宽 压缩信息量，便于特征抽取，为识别做准备 图像识别 图像模式识别方法大致有三种： 统计识别法：侧重于特征 统计决策理论的基本思想就是在不同的模式类中建立一个决策边界，利用决策函数把一个给定的模式归入相应的模式类中。 句法结构模式识别法：侧重于结构和基元 如英文句子由一些短语，短语又由单词，单词又由字母构成一样。用一组模式基元和它们的组成来描述模式的结构的语言，称为模式描述语言。支配基元组成模式的规则称为文法。当每个基元被识别后，利用句法分析就可以作出整个的模式识别。即以这个句子是否符合某特定文法，以判别它是否属于某一类别。这就是句法模式识别的基本思想。 模糊识别法：把模糊数学的一些概念和理论用于识别处理。 图像理解 由模式识别发展起来的方法，输入图像，输出一种描述。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:2:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"4. 什么是图像显示中的硬拷贝和软拷贝？它们主要用什么设备？ 硬拷贝是二维地保持被压缩信息的板状物体实体，当资料经由印表机输出至纸上称为硬拷贝。而软拷贝则表示另有存储（记忆） 的不可见信息，若资料显示在萤幕上则称为软拷贝。 通常的硬拷贝方法有照相、激光拷贝、彩色喷墨打印机等几种方法。 软拷贝方法有以下几种： CRT显示 液晶显示器LCD 彩色等离子显示技术PDP 场致发光显示器FED ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:2:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"5. 图像信息获取设备有哪几种？其优缺点是什么？ 图像信息获取这一过程主要包括摄取图像、光电转换及数字化等几个步骤。通常图像获取的方法有如下几种： 电视摄像机 优点：设备小巧、速度快、成本低、灵敏度高； 缺点：灰度层次较差、非线性失真较大、有黑板效应、在使用中需校正。 飞点扫描器 优点：可获得与电视摄像机相仿的扫描速度，但位置进度和分辨率都比电视摄像机高，图像清晰，可透射成像也可反射成像； 缺点：稳定性和再现性比较差，体积略显庞大，设备价格也较高。 扫描鼓 优点：扫描精度高、信噪比高、可靠性，速度比平台式位密度计要快得多，既可以输入也可以输出； 缺点：只能采用逐行扫描方式，不能用于随机扫描，同时价格昂贵，维护要求高。 扫描仪 优点：成本很低； 缺点：速度较慢，精度一般。 微光密度计 优点：精度很高； 缺点：速度很慢、价格昂贵。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:2:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"6. 图像显示的主要方法有几种？其特点什么？ 硬拷贝：照相、激光拷贝、彩色喷墨打印等。 软拷贝： CRT显示：显示质量好、亮度高、电子束寻址方式简单，成本低。 液晶显示器LCD 彩色等离子显示技术PDP：大面积显示、全色显示、对比度高、色纯度好、寿命长、工作电压低、易于批量生产。 场致发光显示器 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:2:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"7. 数字图像处理有哪些应用？试举出几种你见过的应用。 其典型的应用领域如下： 遥感 土地测绘、资源调查、气象监测、环境污染监测、农作物估产、军事侦察等。 医学 X光CT、电阻抗断层图像技术（或阻抗成像）等。 通信 电视广播、可视电话和会议电话、传真、图文电视和可视图文等。 工业生产的质量控制 产品及部件的无损检测（食品包装、玻璃质量、工件尺寸测量和铁谱分析等）。 安全保障、公安等方面的应用 采用模式识别等方法实现监控、指纹档案、案件侦破、交通管理等。 教学、科研领域 科学计算可视化技术、远程培训等。 电子商务 身份认证、产品防伪、水印技术等。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:2:7","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"8. 数字图像处理的发展方向是什么？ 图像处理技术未来发展大致归纳如下4点： 高速、高分辨率和立体化 三维成像和多维成像 硬件芯片研究 新理论与算法研究 第二章 图像、图像系统与视觉结构 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:2:8","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"本章内容 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"光学预备知识 见思考题1 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"图像信息的分类 符号信息 一般是用文字、符号、图形等表示的具体的或抽象的事物。 景物信息 能给人以主观感觉但不取决于人本身的客观场景信息。 情绪信息 是一种依赖于受信者的图像信息，不仅能给人以直观感觉，而且能以其特殊的艺术内容刺激人的感官。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"图像的统计特性 见思考题2 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"图像信息的信息量 离散的图像信息的熵 一幅图像如果有$s1,s2,s3,\\cdots,s_q$共$q$种幅度值，并且出现的概率分别为$P_1,P_2,P_3,\\cdots,P_q$，那么每一种幅度值所具有的信息量分别为$\\log_2(\\frac{1}{P_1}).\\log_2(\\frac{1}{P_2}),\\log_2(\\frac{1}{P_3}),\\cdots,\\log_2(\\frac{1}{P_q})$。由此，其平均信息量（熵）可由下式表示： $$ H=\\sum_{i=1}^{q}P_i\\log_2\\frac{1}{P_i}=-\\sum_{i=1}^{q}P_i\\log_2{P_i} $$ 连续的图像信息的熵 $$ H=\\int_{-\\infty}^{\\infty}p(s)\\log_2{\\frac{1}{p(s)}}ds+\\infty $$ 一般忽略第二项： $$ H=-\\int_{-\\infty}^{\\infty}p(s)\\log_2{p(s)}ds $$ 其中$p(s)$是概率密度。 连续图像的熵并不是绝对熵，而是绝对熵减去一个无限大项，可以说这是一个相对熵。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"常用图像格式 BMP：点阵图像格式之一。 PCX：MS-DOS下常用的格式。 GIF：为数据流而设计的一种传输格式，不是作为文件存储的格式。 JPEG：有损压缩格式，能够将图像压缩在很小的储存空间。 TIF(F)：主要在应用程序和计算机平台之间交换文件。 GEM：通常用.IMG为扩展名，由文件头和后面的图像数据组成。 PBM：包括了读写许多其他位图文件格式的程序，以及对图像完成变换的实用程序。 PSD：Adobe Photoshop的专用图像格式，可以以RGB或CMYK彩色模式储存。 PCD：Photo CD专用存储格式，文件特别大，需要存在CD-ROM上。 WMF：微软公司开发的矢量图形格式 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"常用输入设备 电视摄像机 飞点扫描设备 鼓形扫描器 微密度计 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"常用输出设备 监视器 激光扫描器 液晶显示器 等离子体PDP显示技术 数码纸显示技术 其他图像显示装置 彩色打印机 投影显示器 其他平板显示 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:7","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"视觉系统的基本构造 人的视觉系统由眼球、神经系统及大脑的视觉中枢构成。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:8","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"颜色的表示方法及观察条件 颜色的表示方法大体上有两种方法。 设置一套作为标准的颜色样本，被试的颜色与样本进行比较，然后用特殊的记号来表示。 取决于刺激光的物理性质和色的感觉的对应关系。（心理物理色） ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:9","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"三基色混色及色度表示原理 见思考题18、19 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:10","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"CIE的R、G、B颜色表示系统 国际照明委员会（CIE）选择红色（波长$\\lambda=700.00\\ nm$），绿色（波长$\\lambda=546.1\\ nm$），蓝色（波长$\\lambda=438.8\\ nm$）三种单色光作为表色系统的三基色。 产生$1\\ lm$白光需要的三基色的近似值可用下面的亮度方程来表示： $$ 1\\ lm(White)=0.30\\ lm(Red)+0.59\\ lm(Green)+0.11\\ lm(Blue) $$ 产生白光时三基色比例关系不等，可以使用$T$单位制： $$ 1\\ lm(W)=1\\ T(R)+1\\ T(G)+1\\ T(B) $$ 可见$1\\ T$单位红光$=0.30\\ lm$，$1\\ T$单位绿光$=0.59\\ lm$，$1\\ T$单位蓝光$=0.11\\ lm$。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:11","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"刺激强度与感觉的关系 关于刺激光的强度和颜色的感觉，由于较暗的情况下只有杆状体起作用，所以此时并没有颜色感觉。亮度达到$10^{-3}\\ cd/m^2$时锥状体才起作用，也就是亮度达到所谓微明视觉的水平时才有色觉。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:12","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"亮度适应和颜色适应 从较亮的场所到较暗的场所时，很难马上看到东西，相反，从较暗的场所到较亮的场所，也看不见东西。一般把眼睛的状态适应明暗条件的变化叫做亮度适应。从亮到暗的变化叫做暗适应；从暗到亮的变化叫做亮适应。 与亮度适应相区别，随着光的分布而变化，眼睛对颜色刺激灵敏度变化的性质。例如，用强红光刺激眼睛后看本来是黄色的物体确实绿色的。这种依赖光分布的视觉灵敏度叫做色适应。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:13","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"亮度对比和颜色对比 一般情况，在相同亮度的刺激下，背景亮度的不同所感觉到的明暗程度也不同。 刺激的亮度和色度受周围背景的影响而使其产生不同感觉的现象叫做同时对比现象。这里包括亮度对比和颜色对比。 关于对比效果的基尔希曼法则： 目标比背景小，颜色对比大； 颜色对比在空间分离的两个领域内也发生，间隔大时则效果较小； 背景大，对比量也大； 明暗对比最小时，颜色对比最大； 明暗相同时，背景色度高对比量大； 亮度及颜色的恒定性（白天的煤山亮度比夜间的雪山亮度高，但仍感觉煤山黑，雪山白）。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:14","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"颜色感觉与刺激面积的关系 见思考题21（第三色盲） ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:15","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"主观颜色 一个一半黑一半白的圆板，当它旋转时，将看到色度较低的颜色。这个现象不能用刺激光的分光特性来预测。圆板缓慢旋转时，从圆心到最外圈将看到不同的颜色。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:16","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"记忆色 我们经常接触的物体，对它的特有的颜色会有记忆，这就是记忆色的概念。例如人的皮肤颜色、草木的颜色等很容易从颜色样本中选出来，这是人人都有的视觉倾向。 但是一般来说，记忆色与实际颜色并不一样，记忆色的色度和亮度都比实际颜色要高。记忆色与理想颜色的再现关系密切，无论是在彩色电视技术上还是绘画上都受到广泛的关注。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:17","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"进入色、后退色、膨胀色、收缩色 观察物体时，根据其颜色有的感觉较近，有的感觉较远。使人有拉近距离感觉的颜色称为进入色，它有较长的波长。看着有推远距离感觉的颜色称为后退色，它有较短的波长。 另外，有的颜色使我们有物体变大的感觉，称为膨胀色。有的会有缩小的感觉，称为收缩色。这些特性又与亮度有关。亮度高的黄色有增大的感觉，亮度低的蓝色有缩小的感觉。除此外，还有暖色、冷色等。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:18","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"错视的原因 视觉系统对形状的感受受到物体自身形状及周围背景的影响。这类影响有神经系统引起的错视现象也有心理学因素的作用。 当出示几个图形时，互相接近的人之间对图形的感觉比较容易取得一致的看法，这里就包括有心理上的诱导作用（群化法则）。另一个关系到心理因素的重要问题是图形和背景的关系问题，对图形和背景的感觉与观察者的经验、态度、明暗差别以及面积的比例等各种因素都有关系。 视觉对大小形状的感觉也有时间因素的影响。 当视网膜受到刺激时，并不是只有与刺激部位相对应的神经系统产生反应，而是对其周围也有影响，这种影响可以看成是由某种场引起的，所以把它叫做诱导场。利用诱导场的概念可以解释一些错视现象。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:3:19","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"思考题 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"1. 光学中的主要计量单位有哪几个？它们的含义是什么？ 发光强度（$I$） 光源发光的功率，其单位主要有如下两种： 烛光功率（Candle Power，$CP$）：1$CP$是指标准蜡烛发出的光 新烛光（Candle，$cd$）：1$cd$是“全辐射体”加热到铂的熔点（$2024K$）时从一平方厘米表面面积上发出的光的$1/60$ 光通量（$\\Phi$） 每秒钟内光流量的度量，其单位是流明（lumen，$lm$）。 照度（$E$） 入射到某表面的光通量密度称为该表面的照度，用每单位面积的流明数来表示，主要单位有如下几种： 公制单位： 勒克斯（lx） 辐透（phot） 毫辐透（mphot） 英制单位： 英尺一烛光 反射系数（$\\rho$） $$ \\rho=\\frac{某表面反射的流明数}{入射到该表面的流明数} $$ 透射系数（$\\tau$） $$ \\tau=\\frac{某物质透射的流明数}{入射到该物质的流明数} $$ 亮度（$L$） 用来说明物体表面发光的量度。 亮度的衡量主要有A、B两组单位。 A组：使用新烛光（坎德拉）为单位 尼特：1 尼特=1 新烛光/平方米 熙提：1 熙提=1 新烛光/平方厘米 B组：使用流明数为单位 亚熙提：1 亚熙提=1 流明/平方米 郎伯：1 郎伯=1 流明/平方厘米 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"2. 图像的统计特性包括哪些内容？ 图像的振幅分布特性 差值信号的振幅分布特性 图像的自相关函数和空域功率谱 电视信号的数学表示及自相关函数 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"17. 什么是光觉？什么是色觉？ 眼睛对光的感觉称为光觉，对颜色的感觉称为色觉，这是眼睛的基本特性。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"18. 什么是三基色？相加混色与相减混色的基色是否相同？ 几乎所有的彩色都能由三种基本彩色混配出来，这三种彩色就叫做三基色。 由三基色混配各种颜色的方法通常有两种——相加混色和相减混色，二者主要的区别表现在以下： 相加混色是由发光体发出的光相加而产生各种颜色，而相减混色是先有白色光，然后从中减去某些成分（吸收）得到各种彩光； 相加混色的三基色是红、绿、蓝，而相减混色的三基色是黄、青、紫（一般不确切的说成是黄、蓝、红），即相加混色的补色就是相减混色的基色。 相加混色和相减混色有不同规律（颜料相混）。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"19. 格拉斯曼定律包含哪些内容？ 所有颜色都可以用互相独立的三基色混合得到； 假如三基色的混合比相等，则色调和色饱和度也相等； 任意两种颜色相混合产生的新颜色与采用三基色分别合成这两种颜色的各自成分混合起来得到的结果相等； 混合色的光亮度是原来各分量光亮度的总和。 色调、色饱和度及亮度是表示色觉程度的，色调表示各种颜色的种类，色饱和度表示颜色深浅。 $$ F\\equiv R(R)+G(G)+B(B) $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"21. 什么是第三色盲？它对图像处理有何意义？ 对于一个色觉正常的人来说，颜色刺激面积非常小时就不能识别颜色了，这种色觉异常状态叫做第三色盲。有学者的研究结果表明，当面积较小时，橙、蓝、绿直线的感觉很接近，当更小时，就只有灰色的感觉了。这个原理被用到彩色电视机原理中，对减少传送频带做出了贡献。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"22. 什么是视力？视力与哪些因素有关？ 视力是指人眼分辨物体细微部分的能力，视力与以下因素有关： 环境 不同的测试条件测得的视力值也不同。 视网膜的不同部分 视力最好的部分在视线附近，即视网膜中央凹上，中央凹周围视力急剧下降。 眼睛的光学系统 瞳孔较大时，因为成像的光行差时视力变低。但在极端情况下，瞳孔很小时视力也要下降。 水晶体的调节状态 一般情况下，视距在$1\\ m$以下时视距越小则视力降低越显著。此外照明亮度高或者测试卡与背景的对比度大则视力会提高。特别是测试标在运动的情况下，运动速度越快则视力越低。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:7","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"23. 什么是马赫现象？它指什么而言？ 马赫效应是一种轮廓增强现象。一幅明暗图像，一边亮一边暗，中间过渡是缓慢斜变的，当观看这样的图象时，视觉的感觉是亮的一边更亮，暗的一边更暗，同时靠近暗的一边的亮度比远离暗的一边要亮，而靠近亮的一边比远离亮的一边显得更暗。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:8","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"24. 什么是光觉门限？ 产生光的感觉必须有一定量的光进入眼睛，把产生光觉的最小亮度叫做光觉门限或光觉阈。 光觉门限的适应状态受生理条件、光的波长、光刺激的持续时间、刺激面积以及在视网膜上的位置等因素的影响。光觉门限的值大约为$1\\times 10^{-6}\\ cd/m^2$（尼特）。 第三章 图像处理中的正交变换 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:4:9","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"本章内容 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"傅里叶变换 定义及基本概念 $$ \\begin{aligned} F(u)\u0026=\\int_{-\\infty}^{\\infty}f(x)e^{-j2\\pi ux}dx \\ f(x)\u0026=\\int_{-\\infty}^{\\infty}F(u)e^{j2\\pi ux}du \\end{aligned} $$ $x$为时域变量，$u$为频率变量，令$\\omega=2\\pi u$： $$ \\begin{aligned} F(u)\u0026=\\int_{-\\infty}^{\\infty}f(x)e^{-j\\omega x}dx \\ f(x)\u0026=\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}F(u)e^{j\\omega x}d\\omega \\end{aligned} $$ $f(x)$的傅里叶变换一般是一个复量： $$ F(\\omega)=R(\\omega)+jI(\\omega) $$ 指数形式： $$ F(\\omega)=|F(\\omega)|e^{j\\phi(\\omega)} $$ 其中，傅里叶幅度谱： $$ |F(\\omega)|=\\sqrt{R^2(\\omega)+I^2(\\omega)} $$ 相位谱： $$ \\phi(w)=\\arctan{\\frac{I(\\omega)}{R(\\omega)}} $$ 性质 可分性 一个二维傅里叶变换可用两次一维傅里叶变换实现。 线性 傅里叶变换是线性算子。 共轭对称性 对于$f(-x,-y)$傅里叶变换的共轭函数$F^(-u,-v)$，有： $$ F(u,v)=F^(-u,-v) $$ 旋转性 若空间域函数旋转角度$\\theta_0$，则在变换域中此函数的傅里叶变换也旋转同样的角度。 比例变换特性 $$ \\begin{aligned} af(x,y)\u0026\\Leftrightarrow aF(u,v) \\ f(ax,by)\u0026\\Leftrightarrow\\frac{1}{|ab|}F(\\frac{u}{a},\\frac{v}{b}) \\end{aligned} $$ 帕斯维尔定理（能量保持定理） $$ \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}|f(x,y)|^2dxdy=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}|F(u,v)|^2dudv $$ 相关定理 卷积定理 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"离散傅里叶变换（DFT） 定义 $$ \\begin{aligned} X(m)\u0026=\\sum_{n=-\\infty}^{\\infty}x(n)e^{-j2\\pi mn} \\ x(n)\u0026=\\sum_{n=-\\infty}^{\\infty}X(m)e^{j2\\pi mn} \\end{aligned} $$ 性质 线性 $$ ax(n)+by(n)\\Leftrightarrow aX(m)+bY(m) $$ 对称性 $$ \\frac{1}{N}X(n)\\Leftrightarrow x(-m) $$ 时间移位 频率移位 周期性 偶函数 奇函数 卷积定理 相关定理 帕斯维尔定理 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"快速傅里叶变换（FFT） 在分析离散傅里叶变换中的多余运算之上，进而消除这些重复工作的思想指导下得到的。 把原始的$N$点序列依次分解为一系列短序列，然后求出这些短序列的离散傅里叶变换，以此减少乘法运算。 $$ X(m)=X_1(m)+W_N^mX_2(m)\\quad m=0,1,\\cdots,N-1 $$ 一个$N$点的离散傅里叶变换可由两个$N/2$点的傅里叶变换得到，离散傅里叶变换的计算时间主要由乘法决定，当$N$是$2$的整数幂时，上式中$X_1(m)$和$X_2(m)$还可以再分成两个更短的序列。利用系数矩阵$W_N^m$的周期性和分解运算，从而减少乘法运算次数是实现快速运算的关键。 FFT算法根据分解的特点一般有两类，一类是按时间分解，一类是按频率分解。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"离散余弦变换（DCT） 定义 一维离散余弦变换的定义： $$ \\begin{aligned} F(0)\u0026=\\frac{1}{\\sqrt{N}}\\sum_{x=0}^{N-1}f(x) \\ F(u)\u0026=\\sqrt{\\frac{2}{N}}\\sum_{x=0}^{N-1}f(x)cos\\frac{(2x+1)u\\pi}{2N} \\end{aligned} $$ 其中，$F(u)$是第$u$个余弦变换系数，$u$是广义频率变量，$u=1,2,3,\\cdots,N-1$；$f(x)$是时域$N$点序列，$x=0,1,\\cdots,N-1$。 $$ \\begin{bmatrix} F(0) \\ F(1) \\ F(2) \\ F(3) \\end{bmatrix} \\begin{bmatrix} \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \\ \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \\ \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \\ \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \\ \\end{bmatrix} \\cdot \\begin{bmatrix} f(0) \\ f(1) \\ f(2) \\ f(3) \\end{bmatrix} $$ 即： $$ \\begin{aligned} F(u)\u0026=Af(x) \\ f(x)\u0026=A^TF(u) \\end{aligned} $$ 二维离散余弦变换矩阵式： $$ \\begin{aligned} F(u,v)\u0026=Af(x,y)A^T \\ f(x,y)\u0026=A^TF(u,v)A \\end{aligned} $$ 离散余弦变换的正交性 $$ AA^T=I $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"沃尔什变换 离散傅里叶变换和余弦变换在快速算法中都要用到复数乘法，占用的时间仍然比较多，在某些领域需要更为便利更为有效的变换方法。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"离散沃尔什变换 TODO.. ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"哈尔函数及哈尔变换 TODO.. ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:7","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"斜矩阵与斜变换 TODO.. ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:8","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"小波变换 TODO.. 第四章 图像增强 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:5:9","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"本章内容 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:6:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"直方图 见思考题2 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:6:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"直方图修改技术的基础 见思考题3 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:6:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"用直方图修改技术进行图像增强 直方图均衡化处理 以累计分布函数变换法为基础的直方图修正法，变换函数： $$ s=T(r)=\\int_0^rp_r(w)dw $$ 则： $$ \\begin{aligned} p_r(s)\u0026=[p_r(r)\\cdot\\frac{dr}{ds}]{r=T^{-1}(s)} \\ \u0026= [p_r(r)\\cdot\\frac{1}{\\frac{ds}{dr}}]{r=T^{-1}(s)}\\ \u0026=[p_r(r)\\cdot\\frac{1}{p_r(r)}] = 1 \\end{aligned} $$ 变换后的图像灰度级服从均匀分布，即得到一幅灰度层次较为适中的图像。 直方图规定化处理 在不同的情况下，并非总需要具有均匀直方图的图像，有时需要具有特定的直方图的图像，以便能够对图像中的某些灰度级加以增强。 对于原始图像和所希望得到的图像（假设已经得到）都做直方图均衡化处理： $$ \\begin{aligned} s\u0026=T(r)=\\int_0^rp_r(w)dw \\ u\u0026=G(z)=\\int_0^zp_z(w)dw \\end{aligned} $$ 同样做了均衡化处理，$p_s(s)$和$p_u(u)$具有同样的均匀密度。根据上式的逆过程，用$s$来代替$u$有： $$ z=G^{-1}(u)\\approx G^{-1}(s) $$ 则： $$ z\\approx G^{-1}[T(r)] $$ 图像对比度处理 图像的亮度范围不足或非线性会使图像的对比度不理想，可用像素幅值重新分配的方法来改善图像对比度。扩大图像亮度范围可以用线性映射的方法。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:6:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"图像平滑化处理 邻域平均法 $$ g(x,y)=\\frac{1}{M}\\sum_{(m,n)\\in S}f(m,n) $$ 采用阈值法可以减少由于邻域平均所产生的模糊效应： $$ g(x,y)= \\begin{cases} \\frac{1}{M}\\sum_{(m,n)\\in S}f(m,n),\\quad \u0026若|f(x,y)-|\\frac{1}{M}\\sum_{(m,n)\\in S}f(m,n)|\\gt T \\ f(x,y),\u0026其他 \\end{cases} $$ 即当一些点和它的邻域内点的灰度的平均值的差不超过规定的阈值时，保留原灰度值不变。 低通滤波法 $$ G(u,v)=H(u,v)\\cdot F(u,v) $$ 见思考题15 多图像平均法 加性噪声，与坐标不相关，且平均值为零。 $$ \\bar{g}(x,y)=\\frac{1}{M}\\sum_{j=1}^Mg_j(x,y) $$ 见思考题16 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:6:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"图像尖锐化处理 见思考题17 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:6:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"利用同态系统进行增强处理 见思考题19 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:6:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"伪彩色图像处理 等密度分层伪彩色技术 可以用专用硬件实现，照相技术中一幅照片的浓淡层次由底片上银粒的沉积度决定，照片的反差直接与密度有关。 灰度分割 若一幅图像可被看作为二维亮度函数（$x,y,f(x,y)$），用一些平行于图像坐标平面的平面，每一平面在与函数相交处分割函数。一次分割将产生一个两色图像，多分层过程类似。 例如$16$级分层，通过编码器得到四位码，加到红、绿、蓝、亮度四个通道中即可得到不同的色调，颜色与码的关系可以人为改变，例如： 0000：黑色 0001：紫色 0010：粉红色 … 1110：深蓝色 1111白色 灰度级转换为彩色 对输入像素的灰度级进行三个相互独立的转换，然后将三个结果分别送到彩色监视器的红、绿、蓝的电子发射枪上。这是对图像的灰度级值的转换，而不是位置的函数。 $$ \\begin{aligned} \u0026\\nearrow 红转换 \\rightarrow I_R(x,y) \\ f(x,y)\u0026\\rightarrow 绿转换 \\rightarrow I_G(x,y)\\ \u0026\\searrow 蓝转换 \\rightarrow I_B(x,y) \\end{aligned} $$ 一种滤波处理 前面几种为灰度 - 彩色变换方法，实际应用中也可以针对图像中不同频率成分加以彩色增强，以便更有利于抽取频率信息。 $$ \\begin{aligned} \u0026\\nearrow 滤波器 \\rightarrow 傅里叶反变换 \\rightarrow 附加处理 \\searrow \\ \\rightarrow 傅里叶变换 \u0026\\rightarrow 滤波器 \\rightarrow 傅里叶反变换\\rightarrow 附加处理 \\rightarrow 彩色监视器\\ \u0026\\searrow 滤波器 \\rightarrow 傅里叶反变换\\rightarrow 附加处理 \\nearrow \\end{aligned} $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:6:7","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"思考题 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"1. 图像增强的目的是什么？ 图像增强是按特定的需要突出一幅图像中的某些信息，同时削弱或去除某些不重要的信息的处理方法。其主要目的是使处理后的图像对某种特定的应用来说，比原始图像更适用。因此这类处理是为了某种应用而去改善图像质量的。处理的结果使图像更适合于人的视觉特性或机器的识别系统。 增强处理并不能增强原始图像的信息，其结果只能增强对某种信息的辨别能力，而这种处理有可能损失一些其他信息。 图像增强技术主要包括直方图修改处理、图像平滑化处理、图像尖锐化处理以及彩色处理技术等。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"2. 什么是直方图？ 灰度级的直方图是反映一幅图像中的灰度级与出现这种灰度的概率之间关系的图形。 图像中，像素的灰度级可作归一化处理：$0\\le r\\le 1$。 $r$是一个随机变量，假定对每一瞬间它们是连续的随机变量，用概率密度函数$p_r(r)$来表示原始图像的灰度分布。横轴代表灰度级$r$，纵轴代表灰度级的概率密度$p_r(r)$。从图像的灰度级分布可以看出一幅图像的灰度分布特性。 引入离散形式，$r_k$代表灰度级，$P_r(r_k)$代替$p_r(r)$，则有： $$ \\begin{aligned} P_r(r_k)=\u0026\\frac{n_k(出现r_k这种灰度的像素数)}{n(图像中的像素总数)}(频数) \\ \u0026\\quad \\quad0\\le r_k \\le 1 \\quad k=0,1,2,\\cdots,l-1 \\end{aligned} $$ $r_k$与$P_r(r_k)$的关系图形称为灰度级的直方图。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"3. 直方图修改的技术基础是什么？/ 4. 在直方图修改技术中采用的变换函数的基本要求是什么？/ 5. 直方图均衡化采用何种变换函数？/ 6. 直方图均衡化处理的结果是什么？ 一幅图像，$0\\le r \\le 1$，对$[0,1]$区间内的任一个$r$做如下变换： $$ s=T(r) $$ $T(r)$应满足： $0\\le r \\le 1$内，$T(r)$单值单增（保证灰度级从白到黑的次序不变）； 对于$0\\le r \\le 1$，$0\\le T(r) \\le 1$（灰度值在允许范围内）。 反变换为： $$ r=T^{-1}(s) $$ 已知随机变量$\\xi$的概率密度$p_r(r)$，而随机变量$\\eta$是$\\xi$的函数，即$\\eta=T(\\xi)$，$\\eta$的概率密度为$p_s(s)$，则可由$p_r(r)$求出$p_s(s)$。 $s=T(r)$单增可得$r=T^{-1}(s)$单增，则$\\eta\\lt s$仅当$\\xi \\lt r$时发生，则： $$ F_\\eta(s)=P(\\eta\\lt s)=P(\\xi\\lt r)=\\int_{-\\infty}^rP_r(x)dx $$ 两端求导即可得到$\\eta$的密度函数$p_s(s)$。 $$ p_s(s)=\\cdots=[p_r(r)\\cdot\\frac{dr}{ds}]_{r=T^{-1}(s)} $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"11. 什么是“简并”现象？如何克服“简并”现象？ 直方图均衡化变换后的灰度级会减少，叫做“简并”现象，这是像素灰度有限的必然结果。 减少简并现象的简单方法是增加像素的比特数，从而减少灰度层次的损失。另外采用灰度间隔放大理论的直方图修正法也可以减少简并现象，这种灰度间隔放大可以按照眼睛的对比度灵敏度特性和成像系统的动态范围进行放大。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"12. 直方图规定化处理的技术难点是什么？如何解决？ 利用直方图规定化方法进行图像增强的主要困难在于如何构成有意义的直方图。一般有两种方法，一种是给定一个规定的概率密度函数，若高斯、瑞利等函数。另一种方法是规定一个任意可控制的直方图，其形状可由一些直线所组成，得到希望的形状后，将这个函数数字化。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"14. 在邻域平均法处理中如何选取邻域？ 半径=$\\Delta{x}$ $$ \\begin{bmatrix} \\circ \u0026 \\bullet \u0026 \\circ \\ \\bullet \u0026 \\cdot \u0026 \\bullet \\ \\circ \u0026 \\bullet \u0026 \\circ \\end{bmatrix} $$ 半径=$\\sqrt{2}\\Delta{x}$ $$ \\begin{bmatrix} \\bullet \u0026 \\bullet \u0026 \\bullet \\ \\bullet \u0026 \\cdot \u0026 \\bullet \\ \\bullet \u0026 \\bullet \u0026 \\bullet \\end{bmatrix} $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"15. 低通滤波法图像增强处理中通常有几种滤波器？它们的特点是什么？ 理想低通滤波器 处理过程会产生较严重的模糊和振铃现象，这种现象是傅里叶变换的性质决定的。 布特沃斯低通滤波器 由于它的$H(u,v)$不是陡峭的截止特性，它的尾部会包含有大量的高频成分。且由于在滤波器的通带和阻带之间有一平滑过渡的缘故，经布特沃斯低通滤波器处理的图像将不会有振铃现象。 指数低通滤波器 经指数低通滤波器处理的图像比布特沃斯低通滤波器处理的图像稍模糊一些，由于指数低通滤波器的传递函数也有较平滑的过渡带，所以图像中也没有振铃现象。 梯形低通滤波器 梯形低通滤波器的传递函数特性介于理想低通滤波器和具有平滑过渡带的低通滤波器之间，其处理效果也介于这两者中间。结果有一定的振铃现象。 详细参考：数字图像处理#频率域高通（锐化）滤波器 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:7","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"16. 多图像平均法为何能去掉噪声？它的主要难点是什么？ 取$M$辐内容相同但含不同噪声（加性噪声，平均值零）的图像叠加，不难得出： $$ \\begin{aligned} E{\\bar{g}(x,y)}\u0026=f(x,y) \\ \\sigma^2_{\\bar{g}(x,y)}\u0026=\\frac{1}{M}\\sigma^2_{n(x,y)} \\ \\sigma_{\\bar{g}(x,y)}\u0026=\\frac{1}{\\sqrt{M}}\\sigma_{n(x,y)} \\end{aligned} $$ 做平均处理的含噪声图像数目增加时，其统计平均值越接近原始无噪声图像。 这种方法在实际应用中的最大困难在于把多幅图像配准起来，以便使相应的像素能正确地对应排列。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:8","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"17. 图像尖锐化处理有几种方法？ 微分尖锐化处理 零交叉边缘检测 Canny算子 经典的Kirsch算子 高通滤波法 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:9","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"18. 零交叉边缘检测的优点是什么？ 对图像的二维卷积可简化为两个一维卷积，是最佳边缘检测器之一。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:10","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"19. 何为同态处理？试述其基本原理。 是把频率过滤和灰度变换结合起来的一种处理方法。它是把图像的照射、反射模型作为频域处理的基础，利用压缩高亮范围和增强对比度来改善图像的一种处理技术。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:11","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"21. 在图像处理中有哪几种模型？它们的应用对象是什么？ RGB彩色模型：彩色监视器和彩色摄像机等领域 CMY彩色模型：彩色打印机 蓝绿（青，Cyan）、红紫（紫，Magenta）、黄（Yellow） $$ \\begin{bmatrix} C \\ M \\ Y \\end{bmatrix} ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:7:12","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"\\begin{bmatrix} 1 \\ 1 \\ 1 \\end{bmatrix} \\begin{bmatrix} R \\ G \\ B \\end{bmatrix} $$ YIQ彩色模型：彩色电视广播 是一个RGB的编码 $$ \\begin{bmatrix} Y \\ I \\ Q \\end{bmatrix} \\begin{bmatrix} 0.299 \u0026 0.587 \u0026 0.114 \\ 0.596 \u0026 -0.275 \u0026 -0.321 \\ 0.212 \u0026 -0.523 \u0026 0.311 \\end{bmatrix} \\begin{bmatrix} R \\ G \\ B \\end{bmatrix} $$ HSI彩色模型：实用系统（自动判断水果成熟度的图像处理系统） 色调（Hue）、饱和度（Saturation）、亮度（Intensity） 第五章 图像编码 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:8:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"本章内容 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:9:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"行程编码 是一种无损编码。 一维行程编码 $$ \\begin{bmatrix} 3\u00263\u00263\u00265\u00265\u00265\u00265\u00265\u00264\u00264\u00268\u00268\u00268\u00268 \\end{bmatrix} $$ 得出序列对： $i$ $g_i$ $l_i$ $1$ $3$ $3$ $2$ $5$ $5$ $3$ $4$ $2$ $4$ $8$ $4$ 行程终点编码：行程终点的位置由扫描行的开始点算起，由到达行程终点的像素计数来确定 行程长度编码：行程终点位置由这一终点与前一终点的相对距离确定。 二维行程编码（预测微分量化器，PDQ） TODO.. ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:9:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"哈夫曼编码 与哈夫曼树类似。是一种无损编码。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:9:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"算术编码 是一种无损编码。基本步骤如下： 对需要编码的数据，统计所有字符和出现次数； 将区间$[0,1)$划分为多个子区间，每个子区间代表一个字符，区间的大小正比于该字符在文中出现的概率$p$； 编码从初始区间开始： $$ low=0\\quad high=1 $$ 不断读入原始数据字符，找到该字符的区间： $$ \\begin{aligned} low\u0026=low+(high-low)*L \\ high\u0026=low+(high-low)*H \\end{aligned} $$ 例1：原始数据ARBER Symbol Times $P$ A $1$ $0.2$ B $1$ $0.2$ E $1$ $0.2$ R $2$ $0.4$ 划分为： $$ \\begin{bmatrix} 0 \u0026 \u0026 0.2 \u0026 \u0026 0.4 \u0026 \u0026 0.6 \u0026 \u0026 \u0026 \u0026 1\\ \\cdot\u0026\\cdot\u0026\\cdot\u0026\\cdot\u0026\\cdot\u0026\\cdot\u0026\\cdot\u0026\\cdot\u0026\\cdot\u0026\\cdot\u0026\\cdot \\ |\u0026 A \u0026 | \u0026 B \u0026 | \u0026 E \u0026 | \u0026 \u0026 R \u0026 \u0026| \\end{bmatrix} $$ 具体步骤： 初始化编码区间$[0,1)$： $$ low=0\\quad high=1 $$ 字符A的概率区间为$[0,0.2)$，则$L=0$，$H=0.2$，更新区间： $$ \\begin{aligned} low\u0026=low+(high-low)*L =0\\ high\u0026=low+(high-low)*H=0.2 \\end{aligned} $$ 字符R的概率区间为$[0.6,1)$，则$L=0.6$，$H=1$，更新区间： $$ \\begin{aligned} low\u0026=low+(high-low)*L =0.12\\ high\u0026=low+(high-low)*H=0.2 \\end{aligned} $$ 字符R的概率区间为$[0.2,0.4)$，则$L=0.2$，$H=0.4$，更新区间： $$ \\begin{aligned} low\u0026=low+(high-low)*L =0.136\\ high\u0026=low+(high-low)*H=0.152 \\end{aligned} $$ … 即每次都按A、B、E、R的比例在新区间上划分子区间。 可以再参考下面这个例子。 例2：原始数据AABABCABAB $$ P(A)=0.5\\quad P(B)=0.4\\quad P(C)=0.1 $$ 则： $$ A:[0,0.5)\\quad B:[0.5,0.9)\\quad C:[0.9,1) $$ 第二个字符为A，则选中A的区间$[0,0.5)$作为划分的目标区间： $$ A:[0,0.25)\\quad B:[0.25,0.45)\\quad C:[0.45,0.5) $$ 第一个字符为A，则选中A的区间$[0,0.25)$作为划分的目标区间： $$ A:[0,0.125)\\quad B:[0.125,0.225)\\quad C:[0.225,0.25) $$ 第一个字符为B，则选中B的区间$[0.125,0.225)$作为划分的目标区间： $$ A:[0.125,0.175)\\quad B:[0.175,0.215)\\quad C:[0.215,0.225) $$ … 重复以上操作，得到编码结果： 字符 目标区间 A $[0,0.5)$ A $[0,0.25)$ B $[0.125,0.225)$ A $[0.125,0.175)$ B $[0.15,0.17)$ C $[0.168,0.17)$ A $[0.168,0.169)$ B $[0.1685,0.1689)$ A $[0.1685,0.1687)$ B $[0.1686,0.16868)$ 最短压缩，从$[0.1686,0.16868)$选一个二进制数表示，选定$0.16864013671975$，即$0.00101011001011$，故最终的二进制编码为$00101011001011$。 参考链接： 什么是算术编码 - 知乎 (zhihu.com) 算数编码原理解析 - SegmentFault 思否 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:9:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"JPEG编码 是一种有损压缩。 编码过程： graph LR A[原始图像数据分成8*8小块] --\u003eB[DCT]--\u003eC[量化器]--\u003eD[熵编码器]--\u003eE[压缩数据] F[量化表]--\u003eC G[码表]--\u003eD 解码过程： graph LR A[压缩数据] --\u003eB[熵编码器]--\u003eC[反量化器]--\u003eD[IDCT]--\u003eE[恢复的图像数据] F[码表]--\u003eB G[量化表]--\u003eC A -.-\u003eF A -.-\u003eG 具体步骤： 将原始图像分为$8\\times 8$的数据块，每个block里有64个像素点。 将图像中的每个$8\\times 8$的block进行DCT变换，经过DCT变换后，低频部分集中在每个block的左上角，高频部分在右下角。所谓JPEG的有损压缩，损的是量化过程中的高频部分。因为有这样一个前提：低频部分比高频部分要重要得多，去除50%的高频信息可能对于编码信息只损失了5%。 量化：像素值$\\div$量化表对应的值得到的结果。由于量化表左上角的值较小，右上角的值较大，这样就起到了保持低频分量，抑制高频分量的目的。JPEG使用的颜色是YUV格式，Y分量代表了亮度信息，UV分量代表了色差信息。相比而言，Y分量更重要一些。我们可以对Y采用细量化，对UV采用粗量化，可进一步提高压缩比。故量化表通常有两张，一张是针对Y的；一张是针对UV的。 编码：编码信息分两类，一类是每个$8\\times 8$的block中$[0,0]$位置的元素，这是DC（直流分量），代表这个block的平均值，JPEG中对该位置的点单独编码。由于两个相邻的$8\\times 8$子块的DC系数相差很小，所以对它们采用差分编码DPCM，可以提高压缩比，即对相邻的子块DC系数的差值进行编码。 另一类是其他63个元素，即AC（交流系数），采用行程编码（Run-length encode,RLE）。为保证低频分量先出现，高频分量后出现，这63个采用了“之”字型（Zig-Zag）的排列方法。 得到了DC码字和AC行程码字后，为进一步提高压缩比，需要对RLE编码结果再进行熵编码，选用Huffman编码。 第六章 图像复原 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:9:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"本章内容 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:10:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"退化模型 见思考题1 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:10:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"复原的代数方法 寻找一个估计$\\hat{f}$，它使事先确定的某种优度准则为最小。 非约束复原方法 约束复原法 见思考题5 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:10:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"逆滤波 见数字图像处理#图像复原方法——逆滤波 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:10:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"最小二乘方滤波 见数字图像处理#图像复原方法——维纳滤波 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:10:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"约束去卷积 见思考题8 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:10:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"中值滤波 见思考题9 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:10:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"其他空间复原技术 几何畸变校正 盲目图像复原 递归图像复原技术 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:10:7","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"思考题 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:11:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"1. 试述图像退化的基本模型。 $$ \\begin{aligned} \u0026n(x,y)\\ \u0026\\downarrow \\ f(x,y)\\rightarrow H \\rightarrow \u0026\\oplus \\rightarrow g(x,y) \\end{aligned} $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:11:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"2. 什么是线性、空间不变的系统，试写出其表达式。 线性：两个输入之和的响应等于两个响应之和。 $$ \\begin{aligned} H[f_1(x,y)+f_2(x,y)]\u0026=H[f_1(x,y)]+H[f_2(x,y)] \\ \u0026=g_1(x,y)+g_2(x,y) \\end{aligned} $$ 空间不变：图像中任一点通过该系统的响应只取决于该点的输入值，而与该点的位置无关。 $$ H[f(x-\\alpha,y-\\beta)]=g(x-\\alpha,y-\\beta) $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:11:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"5. 什么是非约束复原？什么是约束复原？ 非约束复原： 噪声项为 $$ n=g-Hf $$ 不了解$n$情况下，希望找到一个$\\hat{f}$，使$H\\hat{f}$在最小二乘方意义上来说近似于$g$，即： $$ \\begin{aligned} \\parallel n \\parallel^2\u0026=\\parallel g-H\\hat{f}\\parallel ^2 \\ J(\\hat{f})\u0026=\\parallel g-H\\hat{f}\\parallel^2 \\end{aligned} $$ 选择$\\hat{f}$除了要求$J(\\hat{f})$最小外，不受任何其他条件约束。一般用求极值的方法，使： $$ \\frac{\\partial J(\\hat{f})}{\\partial \\hat{f}}=-2H^T(g-H\\hat{f})=0 $$ 约束复原： 最小二乘方复原处理中，为使在数学上更加容易处理，常附加某种约束条件。例如可以令$Q$为$f$的线性算子，则原问题可以看成是使形式为$\\parallel Q\\hat{f}\\parallel$的函数，服从约束条件$\\parallel n \\parallel^2=\\parallel g-H\\hat{f}\\parallel ^2$的最小化问题。 使用拉格朗日乘数法： $$ J(\\hat{f})=\\parallel Q\\hat{f} \\parallel ^2 + \\lambda(\\parallel g-H\\hat{f}\\parallel ^2 - \\parallel n \\parallel ^2) $$ 使： $$ \\frac{\\partial J(\\hat{f})}{\\partial \\hat{f}}=2Q^TQ\\hat{f}-2\\lambda H^T(g-H\\hat{f})=0 $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:11:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"8. 如果不知道原始图像的功率谱，而只知道噪声的方差，采用何种方法复原图像为好？ 最小二乘法是在原始图像和噪声都是平稳随机相场并且功率谱已知的假设下推导的，在没有这方面先验知识而只知道噪声的方差的情况下，则可采用约束去卷积的方法来复原。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:11:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"9. 试描述一维和二维中值滤波的基本原理。 中值滤波的基本原理是把数字图像或数字序列中一点的值用该点的一个邻域中各点值的中值代替。 若邻域内数值个数$n$为偶数则为$\\frac{1}{2}[x_{\\frac{n}{2}}+x_{\\frac{n}{2}+1}]$。 $$ \\begin{bmatrix} x_i\u00260\u00260\u00260\u00268\u00260\u00260\u00262\u00263\u00262\u00260\u00263\u00265\u00263\u00260\u00260\u00262\u00263\u00264\u00265\u00265\u00265\u00265\u00265\u00260\u00260\u00260 \\ y_i\u00260\u00260\u00260\u00260\u00260\u00260\u00262\u00262\u00262\u00262\u00263\u00263\u00263\u00260\u00260\u00262\u00263\u00264\u00265\u00265\u00265\u00265\u00265\u00260\u00260\u00260 \\end{bmatrix} $$ 可见经过中值滤波后脉冲噪声被滤除，振荡被平滑掉了，斜坡和阶跃部分被保存了下来。 一维中值滤波不难推广到二维。 对于加权的中值滤波，其基本原理是改变窗口中变量的个数，可以使一个以上的变量等于同一点的值。 $$ \\begin{aligned} y_i \u0026=Weighted_med(x_{i-1},x_i,x_{i+1}) \\ \u0026=Med(x_{i-1},x_{i-1},x_i,x_i,x_i,x_{i+1},x_{i+1}) \\end{aligned} $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:11:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"11. 试述均值滤波的基本原理。 {% raw %} $$ \\begin{aligned} y_i\u0026=Mean{x_{ij}} \\ \u0026=\\frac{1}{9}\\sum_{m=-1}^1\\sum_{n=-1}^1{x_{{i+m},{j+n}}} \\end{aligned} $$ {% endraw%} 第七章 图像重建 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:11:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"本章内容 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:12:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"图像重建概述及常用方法 图像重建被广泛应用于检测和观察中，这种重建方法一边是根据物体的一些横截面部分的投影而进行的。在一些应用中，某个物体的内部结构图像的检测只能通过这种重建才不会有任何物理上的损伤。由于这种无损检测技术的显著优点，它的适用面非常广泛，例如医疗放射学、核医学、电子显微、无线和雷达天文学。 常用方法有： 傅里叶变换重建 卷积法重建 代数重建方法 见思考题2、3、4 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:12:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"思考题 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:13:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"1. 图像重建中数据的获取模型有哪几种？ 透射模型 透射模型建立于能量通过物体后有一部分能量会被吸收的基础之上，透射模型经常用在X射线、电子射线及光线和热辐射的情况下。 发射模型 发射可以用来确定物体的位置，它是通过在相反的方向分解散射的两束伽马射线来实现的，这两束射线的度越时间可用来确定物体的位置。 反射模型 能量反射也可以用来测定物体的表面特性，例如光线、电子束、激光或作为能量源的超声波等都可以用来进行这种测定。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:13:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"2. 试述傅里叶重建法的基本原理。 一个三维（或二维）物体，它的二维（或一维）投影的傅里叶变换恰与此物体的傅里叶变换的主体部分相等。通过将投影进行旋转和部分傅里叶变换可以首先构造整个傅里叶变换的平面，然后只需再通过傅里叶反变换就可以得到重建后的物体。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:13:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"3. 试述卷积法图像重建的基本原理。 TODO.. ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:13:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"4. 试述代数法重建的基本原理。 TODO.. 第八章 图像分析 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:13:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"本章内容 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:14:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"灰度阈值法分割 把图像灰度分成不同的等级，然后用设置灰度门限的方法确定有意义的区域或与分割的物体之边界。 可以设一个阈值$T$，把直方图分成两个部分，$T$的选择要遵循如下原则： $B_1$应尽可能包含与背景相关联的灰度级 $B_2$应包含物体的所有灰度级 为了找出水平方向和垂直方向上的边界，要进行两次扫描，首先确定一个门限$T$，然后执行以下步骤： 对$f(x,y)$的每一行进行检测，产生的图像的灰度将遵循如下规则： $$ f_1(x,y) \\begin{cases} L_E\\quad f(x,y)和f(x,y-1)处在不同的灰度级上\\ L_B\\quad 其他 \\end{cases} $$ 对$f(x,y)$的每一列进行检测，产生的图像的灰度将遵循如下规则： $$ f_2(x,y) \\begin{cases} L_E\\quad f(x,y)和f(x-1,y)处在不同的灰度级上\\ L_B\\quad 其他 \\end{cases} $$ 为了得到边缘图像，可用下述方法处理： $$ f(x,y)= \\begin{cases} L_E\\quad f_1(x,y)或f_2(x,y)中的任何一个等于L_E\\ L_B\\quad 其他 \\end{cases} $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:14:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"样板匹配 样板是为了检测某些不变区域特性而设计的阵列。样板可根据检测目的不同分为点样板、线样板、梯度样板、正交样板。 一个点样板例子如下： $$ \\begin{bmatrix} -1 \u0026 -1 \u0026 -1 \\ -1 \u0026 8 \u0026 -1 \\ -1 \u0026 -1 \u0026 -1 \\end{bmatrix} $$ 用点样板的检测步骤如下： 样板中心（标号为$8$）沿着图像从一个像素移到另一个像素，在每一个位置上，把处在样板内的图像的每一点的值乘以样板的相应方格中指示的数字，然后把结果相加。 可以采用阈值法清除一些较弱的响应。 一些线检测样板如下： $$ \\begin{bmatrix} -1 \u0026 -1 \u0026 -1\\ 2 \u0026 2 \u0026 2 \\ -1 \u0026 -1 \u0026 -1 \\end{bmatrix} \\quad \\begin{bmatrix} -1 \u0026 -1 \u0026 2\\ -1 \u0026 2 \u0026 -1 \\ 2 \u0026 -1 \u0026 -1 \\end{bmatrix} $$ 一些梯度检测样板如下： $$ \\begin{bmatrix} 1 \u0026 2 \u0026 1\\ 0 \u0026 0 \u0026 0 \\ -1 \u0026 -2 \u0026 -1 \\end{bmatrix} \\quad \\begin{bmatrix} 1 \u0026 0 \u0026 -1\\ 2 \u0026 0 \u0026 -2 \\ 1 \u0026 0 \u0026 -1 \\end{bmatrix} $$ 一些梯度检测样板如下： $$ \\begin{bmatrix} 1 \u0026 \\sqrt{2} \u0026 1\\ 0 \u0026 0 \u0026 0 \\ -1 \u0026 -\\sqrt{2} \u0026 -1 \\end{bmatrix} \\quad \\begin{bmatrix} \\sqrt{2} \u0026 0 \u0026 0\\ -1 \u0026 0 \u0026 1 \\ 0 \u0026 1 \u0026 -\\sqrt{2} \\end{bmatrix} $$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:14:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"区域生长 分割图像的目的是要把一幅图像划分成一些区域，对于该问题最直接的方法是把一幅图像分成满足某种判据的区域，即把点组成区域。 分割区域的一种方法称为区域生长或区域生成，假设区域的数目以及在每个区域中单个点的位置已知，则可推导一种算法，从一个已知点开始，加上与已知点相似的邻近点形成一个区域，这个相似性准则可以是灰度级、彩色、组织、梯度或其他特性。相似性的测度可以由所确定的阈值来判定。 它的方法是从满足检测准则的点开始，在各个方向上生长区域。当邻近点满足检测准则就并入小块区域中，当新的点被合并后再用新的区域重复这一过程，直到没有可接受的邻近点时，生成过程终止。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:14:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"区域聚合 区域聚合可直接用于图像分割，它要求集合中的各个点必须在平面上相邻接而且特性相似。区域聚合的步骤是首先检查图像的测度集，以确定在测度空间中聚合的位置和数目，然后把这些聚合的定义用于图像，以得到区域聚合。 首先在图片上定义某个等价关系，最简单的等价关系可定义为$p(i,j)=p(k,l)$。任何在点的格子上的等价关系又可划分为等价类，例如$p(i,j)$的取值范围为$0\\sim 63$，就可以产生64个等价类的模板。这些等价的类又可以进一步分为最大连接的子集，称为连接分量，连接性可以用点$(i,j)$的邻点来定义，如4连接邻点、8连接邻点。 如$R$是属于格子的子集，在$R$中存在一个点序列，第一个点和最后一个点分别为$p_1$、$p_2$，这两个点是被连接起来的，这样相继的各点是4连接相邻的。通过这样的连接关系可以定义一个属于$R$的子集，这个子集形成一个区域。在这个区域中，任何点都与$R$有关。利用等价模板可分成最大的连接区域，然后，这些最大的连接区域又可以形成有意义的分割。 第九章 数学形态学处理 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:14:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"本章内容 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:0","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"边缘提取算法 图像$A$的边界$b(A)$定义为： $$ b(A)=A-(A\\ominus B) $$ 其中，$B$是适当的结构元素。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:1","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"区域填充算法 孔洞：被前景像素连成的边框所包围的背景区域。 令$A$表示一个集合：其元素是$8$连通的边界，且每个边界包围一个孔洞； 令$X_0$表示一个与包含$A$的相同大小的阵列，其初始状态为： 包含每个孔洞中的一个指定位置处的前景像素点； 除上述的前景像素点外，其余元素均为背景像素点。 在给定$A$和$X_0$的前提下，采用前景像素填充$A$的所有空洞的过程如下： $$ X_k=(X_{k-1}\\oplus B)\\cap A^c\\quad k=1,2,3,\\cdots $$ 其中，$B$是对称结构元素，$B=\\begin{bmatrix}0 \u0026 1 \u0026 0 \\ 1 \u0026 1 \u0026 1 \\ 0 \u0026 1 \u0026 0\\end{bmatrix}$； 若$X_k=X_{k-1}$，则算法在迭代的第$k$步结束； 集合$X_k$包含所有被填充的孔洞，$X_k$和$A$的并集则包含被填充的孔洞及其边界。 每一步运算中，膨胀结果与$A^c$的交集操作实现了将膨胀结果限制在感兴趣区域内，即条件膨胀。 B对图像X的膨胀是B对X的前景元素的膨胀。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:2","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"连接部分提取算法 $Y$表示一个包含与集合$A$相连接的部分，假设$Y$内的一个点$P$已知。那么下述迭代表达式可得到$Y$中的所有元素： $$ X_k=(X_{k-1}\\oplus B)\\cap A \\quad k=1,2,3,\\cdots $$ 其中$X_0=P$，$B$为一合适的结构元，若$X_k=X_{k-1}$则算法收敛。 该表达式与区域填充算法的表达式$X_k=(X_{k-1}\\oplus B)\\cap A^c$类似。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:3","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"凸壳算法 设$B^i,i=1,2,3,4$，代表4个结构元，获得集合$A$凸壳$C(A)$的简单形态学算法由下述公式实现： $$ X_k^i=(X_{k-1}^i\\circledast B^i)\\cup A\\quad i=1,2,3,4 \\quad k=1,2,3,\\cdots $$ 式中，$X_0^i=A$，现在令$D^i=X_{conv}^i$，下标“conv”表示当$X_k^i=X_{k-1}^i$时收敛，那么$A$的凸壳为： $$ C(A)=\\bigcup_{i=1}^4D^i $$ 即，这个过程包括对$A$和$B^i$重复使用击中（Hit）或击不中（Miss）变换；当没有进一步的变化发生时，求$A$和所谓的结果$D^1$并集。对$B^2$重复此过程直到没有进一步的变化为止。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:4","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"细化 集合$A$被结构元的细化用$A\\otimes B$表示，根据击中（Hit）或击不中（Miss）变换定义： $$ \\begin{aligned} A\\otimes B\u0026=A-(A\\circledast B) \\ \u0026=A\\cap (A\\circledast B)^c \\end{aligned} $$ TODO.. ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:5","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"粗化 TODO.. ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:6","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"骨骼化算法 TODO.. ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:7","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"裁剪 TODO.. ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:8","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"膨胀 效果：扩大图像中的物体。 设$A$：原始二值图像，$B$：结构元素，则$A$被$B$膨胀定义为： $$ A\\oplus B={z|(\\hat{B})_z\\cap A \\ne \\emptyset} $$ 或： $$ A\\oplus B = {z|[(\\hat{B})_z\\cap A]\\subseteq A } $$ 即$A$被$B$膨胀的结果是满足上式的所有位移$z$的点（前景像素点）的集合。 膨胀应用实例：桥接裂缝 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:9","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"腐蚀 效果：缩小图像中的物体。 设$A$：原始二值图像，$B$：结构元素，则$A$被$B$腐蚀定义为： $$ A \\ominus B = {z|(B)_z \\subseteq A} $$ 即，将结构元素$B$相对于集合$A$进行平移，只要平移后的结构元素都包含在集合$A$中，则这些位移$z$的点的集合（前景像素点）为腐蚀结果。 如果结构元素取$\\begin{bmatrix} 1 \u0026 1 \u0026 1 \\ 1 \u0026 1 \u0026 1 \\ 1 \u0026 1 \u0026 1 \\end{bmatrix}$，腐蚀将使物体的边界沿周边减少一个像素。 腐蚀可以去除小于结构元素的物体。 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:10","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"开运算和闭运算 开启 效果：平滑物体的轮廓、断开较窄的狭颈、消除细的突出物。 $$ A \\circ B=(A\\ominus B)\\oplus B $$ 即先用$B$对$A$腐蚀，然后用$B$对腐蚀结果进行膨胀。 性质： $A\\circ B$是$A$的子集 若$C \\subseteq D$，则$C\\circ B\\subseteq D\\circ B$ $(A\\circ B)\\circ B=A \\circ B$ 闭合 效果：同样平滑物体的轮廓，但弥合狭窄的断裂和细长的沟壑，消除小孔，并填补轮廓中的缝隙。 $$ A\\bullet B=(A\\oplus B)\\ominus B $$ 即先用$B$对$A$膨胀，然后用$B$对腐蚀结果进行腐蚀。 性质： $A\\bullet B$是$A$的子集 若$C \\subseteq D$，则$C\\bullet B\\subseteq D\\bullet B$ $(A\\bullet B)\\bullet B=A \\bullet B$ ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:11","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"灰度形态学的应用 形态学图像平滑：对图像先进行闭运算处理再进行开运算处理，处理结果将去除或消亮斑或暗斑。 形态学图像梯度：服饰和膨胀处理常用于计算图像的形态梯度： $$ g=(f\\oplus b)-(f \\ominus b) $$ Top-hat变换 $$ h=f-(f\\circ b) $$ 其中$f$为输入图像，$b$为结构元函数。这一变换的最初命名是由于用平顶圆柱和平行六面体作为结构元函数，它常被用于阴影的细节增强处理。 纹理分割 粒状处理 ","date":"March 3, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/:15:12","tags":null,"title":"《数字图像处理学》中的基础概念与课后习题总结","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/"},{"categories":null,"content":" 注：由于近期jsdelivr受到DNS污染，目前在中国无法通过jsdelivr使用CDN服务，本站已采用备用方式渲染页面，部分页面和功能暂时无法查看和使用。 ","date":"March 1, 2022","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"关于我 这个人很懒，什么都没有留下… ","date":"March 1, 2022","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"关于本站 本站始建于 2020 年 7 月 15 日。 ","date":"March 1, 2022","objectID":"/about/:2:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Powered by： Hugo：静态站点生成框架 FixIt：优雅、简洁且高效的 Hugo 主题 Alibaba Cloud：提供云服务器、域名解析与对象存储等多项服务 GitHub：提供代码托管与对象存储等多项服务 LeanCloud：数据云存储与后端支持 Valine：文章评论组件 Hexo：静态站点生成框架 NexT：基于Hexo的博客主题 本站遵循 CC BY-NC-SA 4.0国际许可协议。您可以在署名原著的情况下自由使用、改编、分发本站内容，但不能用于商业用途。 ","date":"March 1, 2022","objectID":"/about/:2:1","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"友情链接 -Thanx-：大学室友的CSDN博客 ","date":"March 1, 2022","objectID":"/about/:3:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"参考视频是广东海洋大学的课程录像，参考书目为冈萨雷斯等著，阮秋琦等译的《数字图像处理》（第四版）。 图像的空域增强技术 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:0:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"概述 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:1:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"空域的概念 空域：像素组成的空间。 空域增强技术：直接作用于图像像素的增强技术。 $$ 像素的空间坐标(x,y) \\rightarrow 像素的灰度值f(x,y) $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:1:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"空域增强的模型 $$ g(x,y)=E_H[f(x,y)] $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:1:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"分类 基于像素的空域增强 $E_H$定义在每个像素$(x,y)$上。 像素点操作：$g(x,y)=P_{xy}[f(x,y)]$ 几何操作：$(x’,y’)=M(x,y)$ 基于模板的空域增强 $E_H$定义在像素$(x,y)$的某个邻域上。 $$ t=E_H[s,n(s)] $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:1:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像间运算 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:2:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"算数运算 两幅图像对应位置像素$p、q$：$p+q、p-q、p\\times q、p\\div q$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:2:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"应用 图像去噪 对原始图像$f(x,y)$和随机噪声$e(x,y)$： $$ \\begin{aligned} g(x,y)\u0026=f(x,y)+e(x,y) \\ \\overline{g}(x,y)\u0026=\\frac{1}{M} \\sum_{i=1}^{M}g_i(x,y) \\end{aligned} $$ 医学图像的数字减影 图像局部显示 二值模板图像与原图像做乘法，进行图像的局部显示。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:2:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"直接灰度映射 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:3:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"原理 $$ 灰度值\\xrightarrow{f}另一灰度值 $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:3:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"典型灰度映射 图像求反 斜率为-1的线性灰度变换： $$ t=(L-1)-s $$ 对比度增强 基于像素的图像增强，即增强原图的各部分反差。 分段线性增强 拉伸感兴趣的图像细节的灰度级。 eg.对于$0\\sim 255$的灰度取值范围，划分为$0\\sim 100、101\\sim 200、201\\sim 255$三个取值区间，只改变其中某段进行灰度变换。 分段线性增强的典型变换函数是三段线性变换函数： $$ \\large t = \\begin{cases} \\frac{t_1}{s_1}s, \u0026 0\\le s \\le s_1\\ \\frac{t_2-t_1}{s_2-s_1}[s-s_1]+t_1, \u0026s_1 \\lt s \\le s_2 \\ \\frac{L-1-t_2}{L-1-s_2}[s-s_2]+t_2, \u0026s2 \\lt s \\le L-1 \\end{cases} $$ 经过斜率小于1的线性变换函数后： 压缩了灰度的动态范围 对比度下降 经过斜率大于1的线性变换函数后，反之。 对数变换 原图动态范围太大，超出某些设备所允许的动态范围，需要压缩其动态范围，即$0 \\sim L’(\\gt L-1) \\longrightarrow 0 \\sim L-1$。 常采用对数变换实现动态范围的压缩： $$ t=C\\log(1+|s|) $$ 其中$C$为尺度比例常数。 可以使用对数变换来扩展图像中暗像素的值，同时压缩高灰度级的值。 幂律（伽马）变换 $$ t=c\\times s^\\gamma $$ 其中$c$和$\\gamma$为正常数。 对于$\\gamma (\\gamma \\lt 1)$的幂律曲线，将较窄范围的暗色输入值映射为较宽范围的亮色输入值（与对数变换类似）；同时，将较宽范围的亮色输入值映射为较窄范围的输出值，$\\gamma \\gt$ 1的幂律变换与之效果完全相反。 可以采用幂律变换提升图像细节的质量。 灰度切割（灰度级分层） 增强特定范围的对比度，用来突出图像中特定灰度范围的亮度。 方法一 $$ t = \\begin{cases} t_2, \u0026 s_1\\le s \\le s_2\\ t_1, \u0026 \\text{其他} \\end{cases} $$ 方法二 $$ t = \\begin{cases} t_2, \u0026 s_1\\le s \\le s_2\\ s, \u0026 \\text{其他} \\end{cases} $$ 阈值化处理（二值化处理，灰度切割的特例） $$ t = \\begin{cases} 0, \u0026 s\\lt s_1\\ L-1, \u0026 s\\ge s_1 \\end{cases} $$ 最终产生一个黑白图像。 位图切割 $8$比特表示的图像看作$8$个单独的$1$比特平面（位图）组成，位面0表示最低位面，位面7表示最高位面。 每个位面均为二值图像，位面图像中像素的灰度值等于相应有效位的取值。 可实现以下应用： 操作特定位面增强图像 确定用于量化该图像的比特数的充分性 图像压缩 实现方法 图像各像素的灰度值除以各有效位的权值$2^i$（$i$为有效位的序数，从$0$计数），商的整数部分为奇数，则该灰度值在相应位面中映射为1，若为偶数，则映射为$0$。（可类比十进制转二进制的手算方法） 例如8位灰度图，某一像素点灰度值121，则： $$ \\begin{aligned} floor(121/2^7)=0 \u0026\\quad\\Rightarrow\\quad 位面\\ 7\\ 中取值为\\ 0 \\ floor(121/2^6)=1 \u0026\\quad\\Rightarrow\\quad 位面\\ 6\\ 中取值为\\ 1 \\ floor(121/2^5)=3 \u0026\\quad\\Rightarrow\\quad 位面\\ 5\\ 中取值为\\ 1 \\ floor(121/2^4)=7 \u0026\\quad\\Rightarrow\\quad 位面\\ 4\\ 中取值为\\ 1 \\ floor(121/2^3)=15 \u0026\\quad\\Rightarrow\\quad 位面\\ 3\\ 中取值为\\ 1 \\ floor(121/2^2)=30 \u0026\\quad\\Rightarrow\\quad 位面\\ 2\\ 中取值为\\ 0 \\ floor(121/2^1)=60 \u0026\\quad\\Rightarrow\\quad 位面\\ 1\\ 中取值为\\ 0 \\ floor(121/2^0)=121 \u0026\\quad\\Rightarrow\\quad 位面\\ 0\\ 中取值为\\ 1 \\end{aligned} $$ MATLAB实现代码 im=imread('fractal_iris.bmp'); rowcnt=size(im,1); columncnt=size(im,2); subplot(3,3,1);imshow(im);title('源图像'); for i=7:-1:0 for x=1:rowcnt for y=1:columncnt if mod(floor(double(im(x,y))/(2^i)),2)==0 bitmap(x,y)=0; else bitmap(x,y)=1; end end end subplot(3,3,7-i+2);imshow(bitmap);title(strcat('位平面',num2str(i))); end ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:3:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"直方图修正——直方图均衡化 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:4:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"直方图和累计直方图 直方图 $$ \\begin{aligned} h(k)=n_k \\quad k=0,1,\\cdots,L-1 \\end{aligned} $$ 其中，$n_k$是图像$f(x,y)$中具有灰度值$k$的像素的个数。 是图像的一种统计表达，反映了图像中像素的灰度值的分布情况。 若某图像的灰度直方图具有二峰性，则表明这个图像较亮区域和较暗区域可以较好的分离。 归一化直方图 $$ \\begin{aligned} p(s_k)\u0026=\\frac{n_k}{n} \\quad s_k=\\frac{k}{L-1},0\\le s_k\\le1 \\end{aligned} $$ 其中，$n$为图像所有像素的数量。 累计直方图 $$ H(k)=\\sum_{i=0}^{k}n_i $$ 其中，$n_i$表示图像中灰度级等于$i$的像素点数量。 归一化累计直方图 $$ \\begin{aligned} P(s_k)=\\sum_{i=0}^kp(s_i) \\end{aligned} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:4:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"直方图均衡化原理 把图像的直方图变换为均匀分布的形式，以此增强动态范围偏小的图像的反差，从而实现对比度增强。 实质是选用合适的变换函数来修正图像灰度级的归一化直方图$p(s_k)$，为了能从图像中获得尽量多的信息量（图像熵尽可能大），要求$p(s_k)$为常数。 增强函数$E_H(s)$需要满足： $E_H(s)$为单值单增函数（保持原有排列次序） $0\\le E_H(s) \\le L-1$（灰度级动态范围一致） 反变换也应该满足上述条件。 累积分布函数（CDF）满足以上条件： $$ t_k=E_H(s_k)=\\sum_{i=0}^{k}\\frac{n_i}{n}=\\sum_{i=0}^{k}p(s_i) $$ 例如一幅图像$64\\times 64(n=4096)$，每个像素点用3比特表示（8个灰度级），像素点的灰度值分布如下： $$ \\begin{array}{c|cccccccc} \\text{灰度级}\u0026 0 \u0026 1 \u0026 2 \u0026 3 \u0026 4 \u0026 5 \u0026 6 \u0026 7 \\ \\hline \\text{像素数量} \u0026 790 \u0026 1023 \u0026 850 \u0026 656 \u0026 329 \u0026 245 \u0026 122 \u0026 81 \\end{array} $$ 实现直方图均衡化步骤如下： 计算源图像的归一化直方图； $$ \\begin{array}{c|cccccccc} 灰度级k \u0026 0 \u0026 1 \u0026 2 \u0026 3 \u0026 4 \u0026 5 \u0026 6 \u0026 7 \\ \\hline 归一化灰度级s_k \u0026 \\frac{0}{7} \u0026 \\frac{1}{7} \u0026 \\frac{2}{7} \u0026 \\frac{3}{7} \u0026 \\frac{4}{7} \u0026 \\frac{5}{7} \u0026 \\frac{6}{7} \u0026 \\frac{7}{7} \\ \\hline 像素数量n_k \u0026 790 \u0026 1023 \u0026 850 \u0026 656 \u0026 329 \u0026 245 \u0026 122 \u0026 81 \\ \\hline \\textbf{归一化直方图}p(s_k) \u0026 0.19 \u0026 0.25 \u0026 0.21 \u0026 0.16 \u0026 0.08 \u0026 0.06 \u0026 0.03 \u0026 0.02 \\end{array} $$ 计算源图像的归一化累积直方图； $$ \\begin{array}{c|cccccccc} 灰度级k \u0026 0 \u0026 1 \u0026 2 \u0026 3 \u0026 4 \u0026 5 \u0026 6 \u0026 7 \\ \\hline 归一化灰度级s_k \u0026 \\frac{0}{7} \u0026 \\frac{1}{7} \u0026 \\frac{2}{7} \u0026 \\frac{3}{7} \u0026 \\frac{4}{7} \u0026 \\frac{5}{7} \u0026 \\frac{6}{7} \u0026 \\frac{7}{7} \\ \\hline 像素数量n_k \u0026 790 \u0026 1023 \u0026 850 \u0026 656 \u0026 329 \u0026 245 \u0026 122 \u0026 81 \\ \\hline 归一化直方图p(s_k) \u0026 0.19 \u0026 0.25 \u0026 0.21 \u0026 0.16 \u0026 0.08 \u0026 0.06 \u0026 0.03 \u0026 0.02 \\ \\hline \\textbf{归一化累积直方图}t_k \u0026 0.19 \u0026 0.44 \u0026 0.65 \u0026 0.81 \u0026 0.89 \u0026 0.95 \u0026 0.98 \u0026 1.00 \\end{array} $$ $t_k’=int[(L-1)t_k+0.5]$（小数部分四舍五入），将$t_k$扩展到$[0, L-1]$范围内，得到直方图均衡化后的灰度值。 $$ \\begin{array}{c|cccccccc} 灰度级k \u0026 0 \u0026 1 \u0026 2 \u0026 3 \u0026 4 \u0026 5 \u0026 6 \u0026 7 \\ \\hline 归一化灰度级s_k \u0026 \\frac{0}{7} \u0026 \\frac{1}{7} \u0026 \\frac{2}{7} \u0026 \\frac{3}{7} \u0026 \\frac{4}{7} \u0026 \\frac{5}{7} \u0026 \\frac{6}{7} \u0026 \\frac{7}{7} \\ \\hline 像素数量n_k \u0026 790 \u0026 1023 \u0026 850 \u0026 656 \u0026 329 \u0026 245 \u0026 122 \u0026 81 \\ \\hline 归一化直方图p(s_k) \u0026 0.19 \u0026 0.25 \u0026 0.21 \u0026 0.16 \u0026 0.08 \u0026 0.06 \u0026 0.03 \u0026 0.02 \\ \\hline 归一化累积直方图t_k \u0026 0.19 \u0026 0.44 \u0026 0.65 \u0026 0.81 \u0026 0.89 \u0026 0.95 \u0026 0.98 \u0026 1.00 \\ \\hline \\textbf{扩展}t_k’ \u0026 1 \u0026 3 \u0026 5 \u0026 6 \u0026 6 \u0026 7 \u0026 7 \u0026 7 \\end{array} $$ 其中$t’_k$的选取：选择最靠近的一个灰度级的值，例如$0.19$离$\\frac{1}{7}$最近，则修正的灰度级为$1$，以此类推。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:4:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"空间滤波机理 组成： 一个邻域 对领域内像素执行的预定义操作 滤波在邻域中心坐标产生一个新的像素，其值是滤波操作的结果。滤波器的中心访问图像中的每个像素后生成滤波后的图像。 可根据执行的操作分为线性空间滤波器和非线性空间滤波器。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:5:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"线性滤波 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:6:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"技术分类和实现原理 技术分类 平滑滤波 平滑线性空间滤波器使用滤波器模板确定的领域像素的平均灰度值代替邻域中心像素的值。降低了图像灰度的“尖锐”变化。 应用：降低噪声、模糊处理… 影响：边缘模糊的负面效应 锐化滤波 削弱图像中灰度缓慢变化的区域，同时使图像中灰度值发生突变的区域得到增强（或不变）。（即消除图像中的低频分量，同时增强（或不影响）高频分量。） 效果：增强被模糊的细节或目标的边缘 与平滑滤波互逆。凸显细节，弱化背景。 实现原理（模板卷积） 大小为$m\\times n$的滤波器对大小为$M\\times N$的图像$f(x,y)$进行线性空间滤波，对于图像中的任意一点$(x,y)$，滤波器的响应$g(x,y)$是滤波器的系数与该滤波器所覆盖像素点的像素值的乘积之和，即： $$ \\begin{aligned} g(x,y)=\\sum_{s=-a}^{a}\\sum_{t=-b}^bw(s,t)f(x+s,y+t) \\end{aligned} $$ 其中： $w(s,t)$为滤波器系数，滤波器中心系数$w(0,0)$对准位置为$(x,y)$的像素； $m=2a+1$，$n=2b+1$，且$a$、$b$为正整数。 使用奇数尺寸的滤波器可更简化索引且更为直观，因为其滤波器的中心落在整数值上。 算法步骤： 将滤波器在图像中漫游，并将滤波器中心与图像中某个像素位置重合； 将滤波器中的各个系数与滤波器所覆盖的各对应像素的灰度值相乘； 将2中的所有成绩结果进行相加，并将加法运算的结果赋给图像中对应滤波器中心位置的像素（滤波器的输出响应）。 大小为$3\\times 3$滤波器的线性空间滤波为例，滤波下方的的图像部分像素和滤波器系数入以下所示： $$ \\begin{bmatrix} { } \u0026 {\\vdots} \u0026 {\\vdots} \u0026 {\\vdots} \u0026 { } \\ {\\cdots} \u0026 {f(x-1,y-1)} \u0026 {f(x-1,y)} \u0026 {f(x-1,y+1)} \u0026 {\\cdots} \\ {\\cdots} \u0026 {f(x,y-1)} \u0026 {f(x,y)} \u0026 {f(x,y+1)} \u0026 {\\cdots}\\ {\\cdots} \u0026 {f(x+1,y-1)} \u0026 {f(x+1,y)} \u0026 {f(x+1,y+1)} \u0026 {\\cdots}\\ { } \u0026 {\\vdots} \u0026 {\\vdots} \u0026 {\\vdots} \u0026 { } \\end{bmatrix} $$ $$ \\begin{bmatrix} {w(-1,-1)} \u0026 {w(-1,0)} \u0026 {w(-1,1)} \\ {w(0,-1)} \u0026 {w(0,0)} \u0026 {w(0,1)} \\ {w(1,-1)} \u0026 {w(1,0)} \u0026 {w(1,1)}\\ \\end{bmatrix} $$ $$ \\begin{aligned} g(x,y) \u0026= w(-1,-1)f(x-1,y-1) \u0026\u0026+ w(-1,0)f(x-1,y) \u0026\u0026+ w(-1,1)f(x-1,y+1) \\ \u0026+ w(0,-1)f(x,y-1) \u0026\u0026+ w(0,0)f(x,y) \u0026\u0026+ w(0,1)f(x,y+1) \\ \u0026+ w(1,-1)f(x+1,y-1) \u0026\u0026+ w(1,0)f(x+1,y) \u0026\u0026+ w(1,1)f(x+1,y+1) \\end{aligned} $$ 对于每一个滤波的结果，其参与运算的邻域灰度值均为原始图像对应邻域的灰度值，相当于在把结果存放在一个新的空白矩阵上，而非在原始图像上就地修改。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:6:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"线性平滑滤波器 邻域平均 $$ g(x,y)=\\frac{1}{mn}\\sum_{(x,y)\\in S}f(x,y) $$ 其中： $S$为滤波器模板覆盖的像素邻域 $mn$为邻域$S$中像素点数 算法简单，但会使图像产生模糊，且邻域越大，模糊越厉害。 加权平均 滤波器模板中各个位置的系数采用不同的数值： 离模板中心近的像素权值大 离模板中心远的像素权值小 权值之和等于1 $$ \\begin{aligned} g(x,y)=\\sum_{s=-a}^{a}\\sum_{t=-b}^bw(s,t)f(x+s,y+t) \\end{aligned} $$ $$ H_1 = \\frac{1}{9} \\begin{bmatrix} {1} \u0026 {1} \u0026 {1} \\ {1} \u0026 {1} \u0026 {1} \\ {1} \u0026 {1} \u0026 {1} \\ \\end{bmatrix} \\quad H_2 = \\frac{1}{10} \\begin{bmatrix} {1} \u0026 {1} \u0026 {1} \\ {1} \u0026 {2} \u0026 {1} \\ {1} \u0026 {1} \u0026 {1} \\ \\end{bmatrix} \\quad H_3 = \\frac{1}{16} \\begin{bmatrix} {1} \u0026 {2} \u0026 {1} \\ {2} \u0026 {4} \u0026 {2} \\ {1} \u0026 {2} \u0026 {1} \\ \\end{bmatrix} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:6:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"非线性滤波 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:7:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"非线性平滑滤波器 统计排序滤波器的响应以滤波器所覆盖的图像区域中的所有像素的排序为基础，然后使用统计排序的结果值代替中心像素的值。其具备优秀的去噪能力，且比同尺寸的线性平滑滤波器的模糊程度明显要低。 中值滤波器 使用像素邻域内灰度的中值代替中心像素的值。其主要功能是拥有不同灰度的像素点看起来更接近于它的相邻点（去除孤立像素）。 中值滤波器对处理椒盐噪声（椒噪声：灰度值较低，偏暗；盐噪声：灰度值较高，偏亮。极端情况是黑色和白色噪声）非常有效，因为这种噪声以黑白点的形式叠加在图像上。 实现步骤 将滤波器模板（无系数）在图像中漫游，并将模板中心与图像中某个像素位置重合； 读取模板下各对应像素的灰度值； 将灰度值按从小到大（或从大到小）的次序进行排序； 确定排序结果的中值，将此中值赋予对应模板中心位置的像素。 $$ \\begin{bmatrix} { } \u0026 {\\vdots} \u0026 {\\vdots} \u0026 {\\vdots} \u0026 { } \\ {\\cdots} \u0026 {10} \u0026 {20} \u0026 {20} \u0026 {\\cdots} \\ {\\cdots} \u0026 {20} \u0026 {15} \u0026 {20} \u0026 {\\cdots}\\ {\\cdots} \u0026 {20} \u0026 {25} \u0026 {100} \u0026 {\\cdots}\\ { } \u0026 {\\vdots} \u0026 {\\vdots} \u0026 {\\vdots} \u0026 { } \\end{bmatrix} \\Rightarrow \\begin{bmatrix} {10} \u0026 {15} \u0026 {20} \u0026 {20} \u0026 \\textbf{20} \u0026 {20} \u0026 {20} \u0026 {25} \u0026 {100} \\end{bmatrix} $$ 模板选择 去噪效果与以下两个因素有关： 模板形状 参与运算的像素数量 常用模板形状：方形、圆形、十字形等。 $$ \\begin{bmatrix} {\\cdot} \u0026 {\\cdot} \u0026 {\\cdot} \u0026 {\\cdot} \u0026 {\\cdot} \\ {\\cdot} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\cdot} \\ {\\cdot} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\cdot} \\ {\\cdot} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\cdot} \\ {\\cdot} \u0026 {\\cdot} \u0026 {\\cdot} \u0026 {\\cdot} \u0026 {\\cdot} \\end{bmatrix} \\quad \\begin{bmatrix} {\\cdot} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\cdot} \\ {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \\ {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \\ {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \\ {\\cdot} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\cdot} \\end{bmatrix} \\quad \\begin{bmatrix} {\\cdot} \u0026 {\\cdot} \u0026 {\\bullet} \u0026 {\\cdot} \u0026 {\\cdot} \\ {\\cdot} \u0026 {\\cdot} \u0026 {\\bullet} \u0026 {\\cdot} \u0026 {\\cdot} \\ {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet} \u0026 {\\bullet}\\ {\\cdot} \u0026 {\\cdot} \u0026 {\\bullet} \u0026 {\\cdot} \u0026 {\\cdot} \\ {\\cdot} \u0026 {\\cdot} \u0026 {\\bullet} \u0026 {\\cdot} \u0026 {\\cdot} \\end{bmatrix} $$ 对于有缓变的较长轮廓线的图像，采用方形或圆形模板为宜； 对于包含有尖顶角物体的图像，采用十字形模板为宜，且模板大小则以不超过图像中最小有效物体的尺寸为宜； 对于包含点、线、尖细节较多的图像，则不适宜采用中值滤波。 百分比滤波器 最大值（$max$）滤波器： $$ g_{max}(x,y)=\\mathop{max}\\limits_{(s,t)\\in N(x,y)}[f(s,t)] $$ 最小值（$min$）滤波器： $$ g_{min}(x,y)=\\mathop{min}\\limits_{(s,t)\\in N(x,y)}[f(s,t)] $$ 椒噪声有较低的灰度值，用最大值滤波器有较好的效果，而盐噪声反之。 最大值滤波会细化黑色目标，最小值滤波会粗化黑色目标。 中点滤波器 $$ g_{mid}(x,y)=\\frac{1}{2}[g_{max}(x,y)+g_{min}(x,y)] $$ 结合了排序统计和求平均，对于高斯和均匀分布随机噪声有较好效果。 中点滤波器得到的结果图像会产生模糊。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:7:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"非线性锐化滤波器 锐化处理目的是突出图像中灰度的过渡部分。 锐化处理可以用空间微分来完成（微分算子的响应强度与像素的突变程度成正比）。即图像微分增强边缘与其他突变（噪声、线），并削弱灰度变化缓慢的区域。 常用滤波器： 基于一阶微分的锐化滤波器 基于二阶微分的锐化滤波器 数字图像微分 一阶微分 在恒定灰度区域的一阶微分值为零； 在灰度台阶、灰度斜坡的起点处一阶微分值非零； 沿着灰度斜坡的一阶微分值非零。 二阶微分 在恒定灰度区域的二阶微分值为零； 在灰度台阶、灰度斜坡的起点处二阶微分值非零； 沿着灰度斜坡的二阶微分值为零。 对于一维离散函数$f(x)$，采用差分计算其微分如下： 一阶微分 $$ \\frac{\\partial f}{\\partial x}=f(x+1)-f(x) $$ 二阶微分 $$ \\begin{aligned} \\frac{\\partial^2 f}{\\partial x^2}\u0026=[f(x+1)-f(x)]-[f(x)-f(x-1)] \\ \u0026= f(x+1)+f(x-1)-2f(x) \\end{aligned} $$ 对于二维的数字图$f(x,y)$，可以沿着两个空间轴处理偏微分。 例如灰度扫描值及一阶微分、二阶微分： $$ \\begin{bmatrix} 6 \u0026 6 \u0026 6 \u0026 5 \u0026 4 \u0026 3 \u0026 2 \u0026 1 \u0026 1 \u0026 1 \u0026 6 \u0026 6 \u0026 6 \\ 恒定灰度 \u0026 \u0026 斜坡起点 \u0026 \u0026 \u0026 斜坡 \u0026 \u0026 \u0026 \u0026 台 \u0026 阶 \u0026 \u0026 \\ 0 \u0026 0 \u0026 -1 \u0026 -1 \u0026 -1 \u0026 -1 \u0026 0 \u0026 0 \u0026 0 \u0026 5 \u0026 0 \u0026 0 \u0026 0 \\ 0 \u0026 0 \u0026 -1 \u0026 0 \u0026 0 \u0026 0 \u0026 1 \u0026 0 \u0026 0 \u0026 0 \u0026 -5 \u0026 0 \u0026 0 \\end{bmatrix} $$ 基于一阶微分的锐化滤波器——梯度算子 基于一阶微分的锐化滤波常用梯度幅值来实现。 对于图像$f$，在任意坐标$(x.y)$上的梯度$\\nabla f$定义为二维列向量： $$ \\nabla f= \\begin{bmatrix} Gx \u0026 Gy \\end{bmatrix}^T \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \u0026 \\frac{\\partial f}{\\partial y} \\end{bmatrix}^T $$ 梯度的幅值$|\\nabla f|$： $$ |\\nabla f|=\\sqrt{G_x^2+G_y^2}=\\sqrt{(\\frac{\\partial f}{\\partial x})^2 + (\\frac{\\partial f}{\\partial y})^2} $$ 实际应用中，一般把梯度的幅值称为梯度，并采用绝对值近似求梯度幅值： $$ |\\nabla f|=|G_x|+|G_y|=|\\frac{\\partial f}{\\partial x}| + |\\frac{\\partial f}{\\partial y}| $$ 梯度（一阶微分）的近似计算方法（滤波模板）: 直接差分 $$ \\begin{aligned} G_x=f(x+1,y)-f(x,y) \\ G_y=f(x,y+1)-f(x,y) \\end{aligned} $$ 直接差分算子： $$ 垂直方向 \\begin{bmatrix} \\underline{-1} \u0026 0 \\ 1 \u0026 0 \\end{bmatrix} \\quad 水平方向 \\begin{bmatrix} \\underline{-1}\u0026 1 \\ 0 \u0026 0 \\end{bmatrix} $$ 交叉差分 $$ \\begin{aligned} G_x=f(x+1,y+1)-f(x,y) \\ G_y=f(x+1,y)-f(x,y+1) \\end{aligned} $$ 交叉差分（Roberts）算子： $$ 垂直方向 \\begin{bmatrix} \\underline{-1} \u0026 0 \\ 0 \u0026 1 \\end{bmatrix} \\quad 水平方向 \\begin{bmatrix} \\underline{0} \u0026 -1 \\ 1 \u0026 0 \\end{bmatrix} $$ Sobel算子 $$ \\begin{aligned} G_x = \u0026f(x+1,y-1)+2f(x+1,y)+f(x+1,y+1)\\ \u0026-f(x-1,y-1)-2f(x-1,y)-f(x-1,y+1) \\ G_y = \u0026f(x-1,y+1)+2f(x,y+1)+f(x+1,y+1)\\ \u0026- f(x-1,y-1)-2f(x,y-1)-f(x+1,y-1) \\end{aligned} $$ Sobel算子： $$ 垂直方向 \\begin{bmatrix} -1 \u0026 -2 \u0026 -1 \\ 0 \u0026 \\underline{0} \u0026 0 \\ 1 \u0026 2 \u0026 1 \\end{bmatrix} \\quad 水平方向 \\begin{bmatrix} -1 \u0026 0 \u0026 1 \\ -2 \u0026 \\underline{0} \u0026 2 \\ -1 \u0026 0 \u0026 1 \\end{bmatrix} $$ 下划线标出元素为滤波器模板的原点。 可以看出，实现平滑的滤波器系数之和为1，实现锐化的滤波器系数之和为0。 应用 工业检测、辅助人工检测缺陷，或更为通用的自动检测的预处理。 基于二阶微分的锐化滤波器——拉普拉斯算子 数字图像$f(x,y)$的拉普拉斯变换定义为： $$ \\nabla ^2f=\\frac{\\partial ^2f}{\\partial x^2}+\\frac{\\partial ^2f}{\\partial y^2} $$ 其中： $$ \\begin{aligned} \\frac{\\partial ^2f}{\\partial x^2}=f(x+1,y)+f(x-1,y)-2f(x,y)\\ \\frac{\\partial ^2f}{\\partial y^2}=f(x,y+1)+f(x,y-1)-2f(x,y) \\end{aligned} $$ 即： $$ \\nabla ^2f=f(x-1,y)-2f(x,y)+f(x,y+1)+f(x,y-1)]-4f(x,y) $$ 执行上式定义的离散拉普拉斯变化所用的滤波器模板： $$ (a) \\begin{bmatrix} 0 \u0026 1 \u0026 0 \\ 1 \u0026 -4 \u0026 1 \\ 0 \u0026 1 \u0026 0 \\end{bmatrix} $$ $$ (b) \\begin{bmatrix} 1 \u0026 1 \u0026 1 \\ 1 \u0026 -8 \u0026 1 \\ 1 \u0026 1 \u0026 1 \\end{bmatrix} \\quad (c) \\begin{bmatrix} 0 \u0026 -1 \u0026 0 \\ -1 \u0026 4 \u0026 -1 \\ 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\quad (d) \\begin{bmatrix} -1 \u0026 -1 \u0026 -1 \\ -1 \u0026 8 \u0026 -1 \\ -1 \u0026 -1 \u0026 -1 \\end{bmatrix} $$ $(b)$为执行离散拉普拉斯变换的扩展模板，包括了对角方向的的领域像素;$(c)、(d)$为其他两种拉普拉斯变换的实现，仅符号相反，结果等效。 使用拉普拉斯变换对图像进行增强的基本方法可表示为： $$ g(x,y)= \\begin{cases} f(x,y)-\\nabla ^2f,若拉普拉斯模板中心系数为负 \\ f(x,y)+\\nabla ^2f,若拉普拉斯模板中心系数为正 \\end{cases} $$ 将原始图像和拉普拉斯图像叠加在一起，以增强细节。 混合空间增强法 若原始图像的灰度动态范围很窄并且伴随着很高的噪声，则采用单一的图像增强算法很难对其进行增强。 傅里叶变换 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:7:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"傅里叶变换及其反变换 空域$\\stackrel{正变换}{\\longrightarrow}$其他空间$\\stackrel{反变换/逆变换}{\\longrightarrow}$空域。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:8:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"一维连续傅里叶变换及反变换 $$ \\begin{aligned} F(\\mu)=\\int_{-\\infty}^{\\infty}f(t)e^{-j2\\pi \\mu t}dt \\ f(t)=\\int_{-\\infty}^{\\infty}F(\\mu)e^{j2\\pi \\mu t}d\\mu \\end{aligned} $$ 其中，$j=\\sqrt{-1}$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:8:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"二维连续傅里叶变换及反变换 $$ \\begin{aligned} F(\\mu,v)=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}f(t,z)e^{-j2\\pi(\\mu t+vz)}dtdz \\ f(t,z)=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}F(\\mu,v)e^{j2\\pi(\\mu t+vz)}d\\mu dv \\end{aligned} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:8:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"一维DFT及IDFT $$ \\begin{aligned} F_m=\\frac{1}{M}\\sum_{n=0}^{M-1}f_ne^{-j2\\pi mn/M},\\quad m=0,1,2,\\cdots,M-1 \\ f_n=\\sum_{m=0}^{M-1}F_me^{j2\\pi mn/M},\\quad n=0,1,2,\\cdots,M-1 \\end{aligned} $$ $x$和$y$表示图像坐标变量（空域变量）并使用$u$和$v$表示频率变量，上式变为： $$ \\begin{aligned} F(\\mu)=\\frac{1}{M}\\sum_{x=0}^{M-1}f(x)e^{-j2\\pi ux/M},\\quad u=0,1,2,\\cdots,M-1\\ f(x)=\\sum_{u=0}^{M-1}F(u)e^{j2\\pi ux/M},\\quad x=0,1,2,\\cdots,M-1 \\end{aligned} $$ 由欧拉公式 $$ e^{j\\theta}=\\cos\\theta+j\\sin\\theta $$ 有： $$ \\begin{aligned} F(u)\u0026=\\frac{1}{M}\\sum_{x=0}^{M-1}f(x)e^{-j2\\pi ux/M} \\ \u0026=\\frac{1}{M}\\sum_{x=0}^{M-1}f(x)(\\cos\\frac{2\\pi ux}{M}-j\\sin\\frac{2\\pi ux}{M}) \\end{aligned} $$ 傅里叶变换$F(u)$的极坐标表示 $$ F(u)=|F(u)|e^{-j\\varphi(u)} $$ 其中， 相角或相位谱： $$ \\varphi(u)=\\arctan[\\frac{I(u)}{R(u)}] $$ $R(u)$和$I(u)$分别是$F(u)$的实部和虚部。 幅度谱（频谱）： $$ |F(u)|=\\sqrt{R(u)^2+I(u)^2} $$ 功率谱： $$ P(u)=|F(u)|^2=R(u)^2+I(u)^2 $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:8:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"二维DFT及IDFT 对大小为$M\\times N$的图像$f(x,y)$： $$ F(u,v)=\\frac{1}{MN}\\sum_{x=0}^{M-1}\\sum_{y=0}^{N-1}f(x,y)e^{-j2\\pi(ux/M+vy/N)} $$ 其中， $$ u=0,1,2,\\cdots,M-1 \\ v=0,1,2,\\cdots,N-1 $$ $$ f(x,y)=\\sum_{x=0}^{M-1}\\sum_{y=0}^{N-1}F(u,v)e^{-j2\\pi(ux/M+vy/N)} $$ 其中， $$ x=0,1,2,\\cdots,M-1 \\ y=0,1,2,\\cdots,N-1 $$ 在有些文献中，常数$1/MN$通常出现在DFT而非IDFT的前面。这时，这个常数的平方根应包含在正变换和反变换的前面，以便形成一个更为对称的变换对。只要使用一致，这种形式的任何表述就都是正确的。 二维DFT的极坐标表示 $$ F(u,v)=|F(u,v)|e^{-j\\varphi(u,v)} $$ 其中， 相角或相位谱： $$ \\varphi(u,v)=\\arctan[\\frac{I(u,v)}{R(u,v)}] $$ $R(u,v)$和$I(u,v)$分别是$F(u,v)$的实部和虚部。 幅度谱（频谱）： $$ |F(u,v)|=\\sqrt{R(u,v)^2+I(u,v)^2} $$ 功率谱： $$ P(u,v)=|F(u,v)|^2=R(u,v)^2+I(u,v)^2 $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:8:4","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"关于频谱$|F(u,v)|$ 频谱描述图像中某种频率的成分数量； 频谱中出现的明亮线反映了原始图像的灰度级变化方向。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:8:5","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"傅里叶变换的性质 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:9:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"平移 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:9:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"可分离性 $$ \\begin{aligned} F(u,v)\u0026=\\frac{1}{MN}\\sum_{x=0}^{M-1}\\sum_{y=0}^{N-1}f(x,y)e^{-j2\\pi (ux/M+vy/N)} \\ \u0026= \\frac{1}{M}\\sum_{x=0}^{M-1}e^{-j2\\pi ux/M}\\frac{1}{N}\\sum_{y=0}^{N-1}f(x,y)e^{-j2\\pi vy/N} \\ \u0026= \\frac{1}{M}\\sum_{x=0}^{M-1}e^{-j2\\pi ux/M}F(x,v) \\end{aligned} $$ $F(x,v)$是沿着$f(x,y)$的一行进行傅里叶变换的结果，当$x=0,1,\\cdots,M-1$，则沿着$f(x,y)$的所有行计算傅里叶变换。 $$ f(x,y) \\stackrel{一维行变换}{\\longrightarrow} F(x,v) \\stackrel{一维列变换}{\\longrightarrow} F(u,v) $$ 二维IDFT与上述过程类似。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:9:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"平均值 图像$f(x,y)$在原点处的傅里叶变换等于图像的平均灰度级。 $$ F(0,0)=\\frac{1}{MN}\\sum_{x=0}^{M-1}\\sum_{y=0}^{N-1}f(x,y) $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:9:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"快速傅里叶变换（FFT） 频率域图像增强 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:10:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"频率域滤波基础 在频率域研究图像增强： 可以利用频率成分和图像外表之间的对应关系；（一些在空间域表述困难的增强任务，在频率域中变得非常普通。） 滤波在频率域更为直观，它可以解释空间域滤波的某些性质；（利用这些性质进行处理，再转换回图像空间，可以得到所需的效果。） 空间域和频率域中的滤波器组成了傅里叶变换对。（可以在频率域指定滤波器，并对其执行反变换，最后在空间域使用该反变换的结果作为空域滤波器。） ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:11:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"傅里叶变换的频率分量与图像空间特征 变化最慢的频率成份$(u=v=0)$对应图像的平均灰度级： $$ F(0,0)=\\frac{1}{MN}\\sum_{x=0}^{M-1}\\sum_{y=0}^{N-1}f(x,y) $$ 从变换的原点移开时，低频成分对应着图像中灰度慢变化的分量（图像的平滑部分）； 进一步偏离原点时，较高的频率成分对应图像中变化越来越快的灰度（边缘或噪声等尖锐部分）。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:11:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"频率域滤波的基本步骤 用$(-1)^{x+y}$乘输入图像$f(x,y)$，使其原点中心化； 对步骤1的结果执行DFT，得到关于中心对称的频谱$F(u,v)$； 生成一个实的、中心对称的频域滤波器$H(u,v)$； 对滤波器$H(u,v)$、频谱$F(u,v)$执行阵列相乘（对应元素逐个进行相乘),形成乘积$G(u,v)=H(u,v)F(u,v)$，其中$G(m,n)=H(m,n)F(m,n)$，且$0\\le m \\le M-1,0\\le n \\le N-1$； 对步骤4的结果$G(u,v)$执行反DFT，并取其结果的实部； 用$(-1)^{x+y}$乘步骤5的反DFT结果的实部，得到滤波结果$g(x,y)$。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:11:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"频域滤波器如何作用于图像 低通滤波器 使频谱的低频成分通过，同时使其高频成分衰减。 被低通滤波的图像比原始图像减少了尖锐的细节部分，突出了平滑过渡部分； 对应于空间域滤波的平滑处理，如均值滤波器。 高通滤波器 使频谱的高频成分通过，同时使其低频成分衰减。 被高通滤波的图像比原始图像少了灰度级的平滑过渡，突出了边缘等细节部分； 对应于空间域滤波的锐化处理，如梯度算子、拉普拉斯算子。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:11:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"频率域低通（平滑）滤波器 低通滤波器的作用：用于截断频谱中所有处于指定距离$D_0$之外的高频成分。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:12:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"理想低通滤波器（ILPF） 假设频谱中心在$(M/2,N/2)$处，则任意频谱成分$(u,v)$到中心（原点）的距离$D(u,v)$定义为： $$ D(u,v)=\\sqrt{(u-\\frac{M}{2})^2+(v-\\frac{N}{2})^2} $$ 理想低通滤波器$H(u,v)$定义为： $$ H(u,v)= \\begin{cases} 1\\quad D(u,v)\\le D_0 \\ 0\\quad D(u,v)\\gt D_0 \\ \\end{cases} $$ 在半径为$D_0$的圆内，所有频率没有衰减地完全通过滤波器，而在此半径的圆之外的所有频率完全被衰减掉。 总图像功率值$P_T$： $$ P_T=\\sum_{u=0}^{M-1}\\sum_{v=0}^{N-1}P(u,v) $$ 其中： $$ P(u,v)=|F(u,v)|^2=R(u,v)^2+I(u,v)^2 $$ 原点位于频谱中心处，半径为$D_0$的圆包含$\\alpha%$的总功率， 其中： $$ \\alpha=100[\\sum_u\\sum_vP(u,v)/P_T] $$ 随着滤波器半径的增大，滤除的功率越来越少，导致的模糊也越来越弱。 理想低通滤波器产生模糊和振铃现象，且模糊和振铃现象反比于截断频率（即半径$D_0$）。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:12:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"巴特沃斯低通滤波器（BLPF） $n$阶巴特沃斯低通滤波器定义如下： $$ H(u,v)=\\frac{1}{1+{[D(u,v)/D_0]}^{2n}} $$ 低阶滤波器没有明显振铃现象（滤波器在低频和高频之间平滑过渡）。且1阶BLPF核即没有振铃效应又没有负值。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:12:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"高斯低通滤波器（GLPF） 二维高斯低通滤波器定义如下： $$ H(u,v)=e^{-D(u,v)^2/2\\sigma ^2} $$ $\\sigma$是关于频谱中心的扩展度的度量。 令$\\sigma=D_0$，则二维高斯低通滤波器表示为： $$ H(u,v)=e^{-D(u,v)^2/2D_0 ^2} $$ 平滑效果稍差于相同截止频率的二阶BLPF； 没有出现振铃现象，优于BLPF。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:12:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"应用实例 用于机器识别系统识别字符的预处理； 减少人脸图像的皮肤细纹核小斑点； 消除卫星、航空图像中的不重要特征。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:12:4","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"频率域高通（锐化）滤波器 高通滤波器的作用：用于截断频谱中所有处于指定距离$D_0$之内的低频成分。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:13:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"理想高通滤波器（IHPF） 截止频率距原点的距离为$D_0$的IHPF定义为： $$ H(u,v)= \\begin{cases} 0\\quad D(u,v)\\le D_0 \\ 1\\quad D(u,v)\\gt D_0 \\end{cases} $$ 振铃现象明显。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:13:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"巴特沃斯高通滤波器（BHPF） $n$阶且截止频率距原点的距离为$D_0$的BHPF定义为： $$ H(u,v)=\\frac{1}{1+{[D_0/D(u,v)]}^{2n}} $$ BHPF的结果比IHPF的结果尖锐得多，边缘失真也小得多。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:13:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"高斯高通滤波器（GHPF） 截止频率距原点的距离为$D_0$的GHPF定义为： $$ H(u,v)=1-e^{-D(u,v)^2/2D_0^2} $$ GHPF的结果比BHPF和IHPF的结果更尖锐，即使是对微小物体和细线条的滤波也是较清晰的。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:13:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"高通滤波器与低通滤波器的关系 $$ H_{HP}(u,v)=1-H_{LP}(u,v) $$ 其中： $H_{LP}(u,v)$：低通滤波器函数；$H_{HP}(u,v)$：高通滤波器函数。 被低通滤波器衰减的频率成分能通过高通滤波器，反之亦然。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:13:4","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"高频提升和高频加强 高通滤波效果等同于用原始图像的频谱减去低通滤波的结果图像频谱。 图像经过高通滤波后，由于高通滤波器除去了傅里叶变换的零频率，其背景的平均强度减小到接近黑色。 原始图像加到滤波后的结果图像，即高频提升滤波或高频加强滤波。 高频提升滤波 将原始图像按一定比例加到滤波后的结果中，以保留原始图像的背景。 设在空域中，原始图像为$f(x,y)$，高通滤波后的结果图像为$f_{HP}(x,y)$，低通滤波后的结果图像为$f_{LP}(x,y)$，高通提升滤波的结果图像为$f_{HB}(x,y)$，则高频提升滤波的空域形式如下： $$ f_{HB}(x,y)=A\\times f(x,y)-f_{LP}(x,y),\\quad A\\ge1 $$ 亦即： $$ \\begin{aligned} f_{HB}(x,y)\u0026=(A-1)\\times f(x,y)+f(x,y)-f_{LP}(x,y) \\ \u0026=(A-1)\\times f(x,y)+f_{HP}(x,y) \\end{aligned} $$ 对于高频提升滤波的空域形式$f_{HB}(x,y)$和频域形式$F_{HB}(u,v)$： $$ \\begin{gather*} f_{HB}(x,y)=(A-1)\\times f(x,y)+f_{HP}(x,y) \\ \\downarrow \\ F_{HB}(u,v)=(A-1)\\times F(u,v)+F_{HP}(u,v) \\ \\downarrow \\ F_{HB}(u,v)=(A-1)\\times F(u,v)+H_{HP}(u,v)\\times F(u,v) \\ \\downarrow \\ F_{HB}(u,v)=[(A-1)+H_{HP}(u,v)]\\times F(u,v) \\end{gather*} $$ 高频提升滤波器： $$ H_{HB}(u,v)=(A-1)+H_{HP}(u,v),\\quad A\\ge1,A=1时普通高通 $$ 高频提升滤波： $$ F_{HB}(u,v)=H_{HB}(u,v)\\times F(u,v) $$ 高频加强滤波 加强增强图像的高频成分。 在高通滤波器函数前乘一个常数，再增加一个偏移量以便使零频率不被滤波器滤除掉。 高通滤波： $$ G(u,v)=H_{HP}(u,v)\\times F(u,v) $$ 高频加强滤波器： $$ H_E(u,v)=k\\times H_{HP}(u,v)+c $$ $k\\ge 0$且$k\\gt c$，$k$的典型值在$1.5$到$2.0$之间，$c$的典型值在$0.25$到$0.5$之间。 高频加强滤波： $$ \\begin{aligned} G_E(u,v)\u0026=H_E(u,v)\\times F(u,v) \\ \u0026= [k\\times H_{HP}(u,v)+c]\\times F(u,v) \\ \u0026=k\\times H_{HP}(u,v)\\times F(u,v) + c\\times F(u,v) \\ \u0026=k\\times G(u,v)+c\\times F(u,v) \\end{aligned} $$ 图像复原 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:13:5","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像退化/复原过程的模型 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:14:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像退化与图像复原 图像退化是指图像在形式、存储、处理和传输过程中，由于成像系统、存储设备、处理方法和传输介质的不完善，从而导致的图像质量下降。 引起图像退化的原因有： 成像系统的散焦； 成像设备与物体的相对运动； 成像器材的固有缺陷； 外部干扰； …… 图像复原（图像恢复）指的是对退化的图像进行处理，试图恢复降质的图像。 二者关系： 图像复原可以看作是图像退化的逆过程； 实际情况中，退化过程往往并不知晓，这种复原称为盲目复原； 图像模糊的同时，噪声和干扰也会同时存在。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:14:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像退化/复原模型 $$ \\begin{aligned} f(x,y)\\rightarrow 退化函数H \\rightarrow \u0026\\sum \\stackrel{退化图像g(x,y)}{\\longrightarrow} 复原滤波器 \\rightarrow \\hat{f}(x,y) \\ \u0026\\uparrow 噪声n(x,y) \\ \\end{aligned} $$ $$ g(x,y)=H[f(x,y)]+n(x,y) $$ 图像复原：在给定$g(x,y)$和$H$的基础上得到对$f(x,y)$的某个近似，通常采用线性的、空间不变的复原技术。 如果退化系统（函数）$H$是线性空间不变系统： 线性： $$ \\begin{aligned} \u0026 H[k_1f_1(x,y)+k_2f_2(x,y)]=k_1H[f_1(x,y)]+k_2H[f_2(x,y)] \\ \\end{aligned} $$ 齐次性：$H[kf(x,y)]=kH[f(x,y)]$ 叠加性：$H[f_1(x,y)+f_2(x,y)]=H[f_1(x,y)]+H[f_2(x,y)]$ 空间不变性： $$ H[f(x-a,y-b)]=g(x-a,y-b)\\quad H[f(x,y)]=g(x,y) $$ 即图像中任一像素点通过退化系统时的响应只取决于该点的输入值，而与该点的位置无关。 则退化图像可以表示为： 空域模型： $$ g(x,y)=h(x,y)*f(x,y)+n(x,y) $$ 频域模型： $$ G(u,v)=H(u,v)F(u,v)+N(u,v) $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:14:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"噪声模型 图像中的噪声是随机的，其灰度值的统计特征可以用概率密度函数（PDF）或相应的累积分布函数（CDF）进行表征。 对于退化图像中的噪声$n(x,y)$（噪声的灰度值，非位置），有多种不同的统计模型： 均匀（Uniform）噪声 指数（Exponential）噪声 高斯（Gaussian）噪声 瑞利（Rayleigh）噪声 伽马（爱尔兰）噪声 脉冲（椒盐）噪声 周期噪声 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:15:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"均匀噪声 $$ \\Large p(z)= \\begin{cases} \\frac{1}{b-a}\\quad \u0026a\\le z\\le b \\ 0\\quad \u0026其他 \\end{cases} $$ 其中，$z$表示噪声灰度值。 $$ z=a+(b-a)\\times U(0,1) $$ $U(0,1)$表示区间$[0,1]$内的均匀随机数。 $$ \\begin{aligned} \\mu \u0026= \\frac{a+b}{2} \\ \\sigma^2 \u0026= \\frac{(b-a)^2}{12} \\end{aligned} $$ 实例（MATLAB）： a=2; b=5; noise=a+(b-1)*rand(100,100); blackIm=zeros(100,100); noisedIm=noise+blackIm; ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:15:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"指数噪声 $$ \\Large p(z)= \\begin{cases} ae^{-az}\\quad \u0026 z\\ge 0\\ 0\\quad \u0026 z\\lt0 \\end{cases} $$ 其中，$a\\gt 0$。 $$ z=-\\frac{1}{a}\\times ln[1-U(0,1)] $$ $$ \\begin{aligned} \\mu\u0026=\\frac{1}{a} \\ \\sigma^2 \u0026= \\frac{1}{a^2} \\end{aligned} $$ 实例（MATLAB）： a=2; noise=(-1/a)*log(1-rand(100,100)); blackIm=zeros(100,100); noiseIm=noise+blackIm; ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:15:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"高斯噪声 $$ \\Large p(z)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp[{-\\frac{(z-\\mu)^2}{2\\sigma^2}}] $$ $$ z=\\mu+\\sigma\\times N(0,1) $$ $N(0,1)$表示标准正态分布的随机数。 灰度值有$70%$落在$[\\mu-\\sigma,\\mu+\\sigma]$范围内。 实例（MATLAB）： mu=0; sigma=0.1; noise=mu+sigma*randn(100,100); blackIm=zeros(100,100); noiseIm=noise+blackIm; ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:15:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"瑞利噪声 $$ \\Large p(z)= \\begin{cases} \\frac{2}{b}(z-a)\\exp[-\\frac{(z-a)^2}{b}] \u0026z\\ge a\\ 0 \u0026z\\lt a \\end{cases} $$ $$ z=a+\\sqrt{-b\\times ln[1-U(0,1)]} $$ $$ \\begin{aligned} \\mu \u0026= a + \\sqrt{\\frac{\\pi b}{4}} \\ \\sigma^2\u0026=\\frac{b(4-\\pi)}{4} \\end{aligned} $$ 实例（MATLAB）： a=0; b=0.1; noise=a+(-b*log(1-rand(100,100))).^2; blackIm=zeros(100,100); noiseIm=noise+blackIm; ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:15:4","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"伽马噪声 $$ \\Large p(z)= \\begin{cases} \\frac{a^bz^{b-1}}{(b-1)!}e^{-az} \\quad \u0026z\\gt0 \\ 0 \u0026z\\lt0 \\end{cases} $$ 其中，$a\\gt0$，$b$为正整数。 $$ z=E_1+E_2+\\cdots+E_b $$ $E_i$是具有参数$a$的指数随机数。 $$ \\begin{aligned} \\mu \u0026= \\frac{b}{a} \\ \\sigma^2 \u0026= \\frac{b}{a^2} \\end{aligned} $$ 实例（MATLAB）： a=2; b=5; noise=zeros(100,100); for j=1:b noise=noise+(-1/a)*log(1-rand(100,100)); end blackIm=zeros(100,100); noiseIm=noise+blackIm; ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:15:5","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"脉冲噪声 $$ \\Large p(z)= \\begin{cases} P_a \\quad \u0026z=a \\ P_b \u0026z=b \\ 0 \u0026其他 \\end{cases} $$ 若$P_a$或$P_b$为零，则脉冲噪声称为单极脉冲；若$P_a$或$P_b$均不为零，则脉冲噪声成为双脉冲噪声或椒盐噪声。 通常，$a$、$b$等于所允许的最小值和最大值。 d=0.5; noise=rand(100,100); noise(noise\u003cd/2)=0; noise(noise\u003e=d/2 \u0026 noise\u003cd)=1; blackIm=zeros(100,100); noiseIm=noise+blackIm; ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:15:6","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"空间域滤波复原 当一幅图像中存在的唯一退化因素是噪声时，其退化模型如下： 空域模型： $$ g(x,y)=f(x,y)+n(x,y) $$ 频域模型： $$ G(u,v)=F(u,v)+N(u,v) $$ 可以选择空域滤波的方法来复原图像。 均值滤波器、中点滤波器适合处理高斯或均匀分布等随机噪声； 中值滤波器适合处理椒盐噪声； 最大值滤波器适合处理“椒”噪声； 最小值滤波器适合处理“盐”噪声。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:16:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"自适应滤波器 自适应滤波行为基于由$m\\times n$矩形窗口$S_{xy}$定义的区域内图像的统计特征。 该类滤波器的响应基于： $g(x,y)$：图像$g$任意像素点的灰度值 $\\sigma_n^2$：被污染图像$g$的方差 $m_L$：区域$S_{xy}$上像素点的灰度局部均值 $\\sigma_L^2$：区域$S_{xy}$上像素点的灰度局部方差 预期性能： 若$\\sigma_n^2=0$（零噪声），滤波器返回$g(x,y)$； 若$\\sigma_L^2$与$\\sigma_n^2$高相关，滤波器返回$g(x,y)$的近似值； 若$\\sigma_L^2=\\sigma_n^2$（局部性质和整个图像的性质相同），滤波器返回区域$S_{xy}$上像素的局部均值$m_L$。 假设噪声是加性和位置无关的，$\\sigma_n^2 \\le \\sigma_L^2$。 表达式如下： $$ \\hat{f}(x,y)=g(x,y)-\\frac{\\sigma_n^2}{\\sigma_L^2}[g(x,y)-m_L] $$ $\\sigma_n^2$是唯一事先需要知道的量。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:16:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"退化函数的估计 频域退化模型： $$ G(u,v)=H(u,v)F(u,v)+N(u,v) $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:17:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像观察估计法 寻找简单结构、受噪声影响小的子图像$g_s(x,y)$； 构造一个估计图像$\\hat{f}_s(x,y)$，它和观察的子图像$g_s(x,y)$有相同大小和特性； 根据位置不变的假设： $$ H_s(u,v)=\\frac{G_s(u,v)}{\\hat{F}_s(u,v)} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:17:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"试验估计法 $$ H(u,v)=\\frac{G(u,v)}{A} $$ 其中，$A$为常量，表示脉冲强度。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:17:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"模型估计法 散焦模糊（Disk Blur） $$ \\large h(x,y)= \\begin{cases} \\frac{1}{\\pi R^2} \\quad \u0026x^2+y^2\\le R^2 \\ 0 \u0026others \\end{cases} $$ $$ \\Downarrow{DFT} $$ $$ H(u,v)=2\\pi R \\frac{J_1(R\\sqrt{u^2+v^2})}{\\sqrt{u^2+v^2}} $$ 其中： $R$是散焦半径； $J_1(\\cdot)$是一阶第一类贝塞尔（Bessel）函数； $H(u,v)$是圆对称的。 运动模糊（Motion Deblur） $$ H(u,v)=\\frac{T}{\\pi (ua+vb)}sin[\\pi (ua+vb)]e^{-j\\pi (ua+vb)} $$ 其中： $T$为采集时间长度（曝光时间）； $a$、$b$分别为垂直、水平方向的运动距离。 大气湍流模糊 $$ H(u,v)=e^{-k(u^2+v^2)^{5/6}} $$ 其中，常数$k$与湍流的性质有关，$k$越大，湍流越剧烈。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:17:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像复原方法——逆滤波 频域退化模型： $$ G(u,v)=H(u,v)F(u,v)+N(u,v) $$ 原始图像傅里叶变换结果的估计： $$ \\hat{F}(u,v)=\\frac{G(u,v)}{H(u,v)} $$ 没有考虑噪声的处理。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:18:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像复原方法——维纳滤波 综合了退化函数和噪声统计特性，引入最小二乘约束条件，使得$\\hat{f}(x,y)$域原始的未退化图像$f(x,y)$之间的均方误差最小。 $$ \\min{MSE}=\\min{\\frac{1}{MN}\\sum_{x=0}^{M-1}\\sum_{y=0}^{N-1}[\\hat{f}(x,y)-f(x,y)]^2} $$ 维纳滤波器： $$ H_w(u,v)=\\frac{1}{H(u,v)}\\frac{|H(u,v)|^2}{|H(u,v)|^2+s\\frac{|N(u,v)|^2}{|F(u,v)|^2}} $$ 其中： $H(u,v)$为退化函数； $|H(u,v)|^2$为$H(u,v)$的功率谱； $s$为最小二乘约束条件的拉格朗日常数； $|N(u,v)|^2$为噪声的功率谱； $|F(u,v)|^2$为未退化图像的功率谱。 $\\frac{|N(u,v)|^2}{|F(u,v)|^2}$为噪信功率比。 若退化图像具有较低的噪信功率比，则维纳滤波器$H_w(u,v)$近似为逆滤波器$\\frac{1}{H(u,v)}$。如果噪声为0，则维纳滤波器退化为逆滤波。 如果噪信功率比未知或不能估计，则维纳滤波器可近似为： $$ H_w(u,v)=\\frac{1}{H(u,v)}\\frac{|H(u,v)|^2}{|H(u,v)|^2+K} $$ 形态学图像处理 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:19:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"概述 作用：简化图像数据，去除图像中不重要的结构，仅保持图像的基本形状特性。 基本思想：使用具有一定形态的结构元素去度量和提取图像中的对应形状，以达到对图像进行处理和分析的目的。 数学基础和所用语言：集合论 基本运算：膨胀、腐蚀、开启、闭合。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:20:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"集合论基础 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:21:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"并、交、补、差 $$ \\begin{gather*} \u0026C=A\\cup B \\ \u0026D=A\\cap B \\ \u0026A^c={w|w\\notin A} \\ \u0026A-B={w|w\\in A, w\\notin B}=A\\cap B^c \\end{gather*} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:21:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"反射与平移 反射 一个集合$B$的反射表示为$\\hat{B}$： $$ \\hat{B}={w|w=-b,b\\in B} $$ $\\hat{B}$关于原集合$B$原点对称。 $$ B:(x,y)\\rightarrow \\hat{B}:(-x,-y) $$ 平移 一个集合$B$的平移表示为$(B)_z$： $$ (B)_z={c|c=b+z,b\\in B} $$ 其中，$z=(z_1,z_2)$。 $$ B:(x,y)\\rightarrow (B)_z:(x+z_1,y+z_2) $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:21:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"二值图像的逻辑运算 $$ \\begin{gather*} NOT(A) \\ (A) AND (B) \\ (A)OR(B) \\ (A)XOR(B) \\end{gather*} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:21:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"二值图像形态学处理 设$A$：像素集合，$B$：结构元素（成员是感兴趣目标的像素的集合），处理过程是用$B$对$A$进行操作。 通过让$B$在$A$上平移，以便$B$的原点访问$A$的每一个像素，以此得到一个新的像素集合。 结构元素的原点是形态学运算的参考点。 原点可以包含在结构元素中，也可以不包含在结构元素中。 转换为矩阵阵列的结构元素示例： $$ \\begin{bmatrix} \u0026 \\cdot \u0026 \\ \\cdot \u0026 \\bullet \u0026 \\cdot \\ \u0026 \\cdot \u0026 \\ \\end{bmatrix} \\quad \\begin{bmatrix} \\cdot \u0026 \\cdot \u0026 \\cdot \\ \\cdot \u0026 \\bullet \u0026 \\cdot \\ \\cdot \u0026 \\cdot \u0026 \\cdot \\ \\end{bmatrix} \\quad \\begin{bmatrix} \\cdot \\ \\cdot \\ \\bullet \\ \\cdot \\ \\cdot \\end{bmatrix} \\quad \\begin{bmatrix} \u0026 \u0026 \u0026 \\cdot \u0026 \u0026 \u0026 \\ \u0026 \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \u0026 \\ \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\ \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\bullet \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \\ \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \\ \u0026 \u0026 \\cdot \u0026 \\cdot \u0026 \\cdot \u0026 \u0026 \\ \u0026 \u0026 \u0026 \\cdot \u0026 \u0026 \u0026 \\ \\end{bmatrix} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:22:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"膨胀和腐蚀 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:23:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"膨胀 效果：扩大图像中的物体。 设$A$：原始二值图像，$B$：结构元素，则$A$被$B$膨胀定义为： $$ A\\oplus B={z|(\\hat{B})_z\\cap A \\ne \\emptyset} $$ 或： $$ A\\oplus B = {z|[(\\hat{B})_z\\cap A]\\subseteq A } $$ 即$A$被$B$膨胀的结果是满足上式的所有位移$z$的点（前景像素点）的集合。 膨胀应用实例：桥接裂缝 A=imread(\"broken_text.tif\"); B=[0 1 0;1 1 1;0 1 0]; result=imdilate(A,B); 其中结构元素$B:\\begin{bmatrix} 0 \u0026 1 \u0026 0 \\ 1 \u0026 1 \u0026 1 \\ 0 \u0026 1 \u0026 0 \\end{bmatrix}$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:23:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"腐蚀 效果：缩小图像中的物体。 设$A$：原始二值图像，$B$：结构元素，则$A$被$B$腐蚀定义为： $$ A \\ominus B = {z|(B)_z \\subseteq A} $$ 即，将结构元素$B$相对于集合$A$进行平移，只要平移后的结构元素都包含在集合$A$中，则这些位移$z$的点的集合（前景像素点）为腐蚀结果。 如果结构元素取$\\begin{bmatrix} 1 \u0026 1 \u0026 1 \\ 1 \u0026 1 \u0026 1 \\ 1 \u0026 1 \u0026 1 \\end{bmatrix}$，腐蚀将使物体的边界沿周边减少一个像素。 腐蚀可以去除小于结构元素的物体。 腐蚀应用实例（MATLAB）： A=imread('wirebond.tif'); B=strel('square',11); %边长为11的方形结构元素 result=imerode(A,B); ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:23:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"开启和闭合 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:24:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"开启 效果：平滑物体的轮廓、断开较窄的狭颈、消除细的突出物。 $$ A \\circ B=(A\\ominus B)\\oplus B $$ 即先用$B$对$A$腐蚀，然后用$B$对腐蚀结果进行膨胀。 性质： $A\\circ B$是$A$的子集 若$C \\subseteq D$，则$C\\circ B\\subseteq D\\circ B$ $(A\\circ B)\\circ B=A \\circ B$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:24:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"闭合 效果：同样平滑物体的轮廓，但弥合狭窄的断裂和细长的沟壑，消除小孔，并填补轮廓中的缝隙。 $$ A\\bullet B=(A\\oplus B)\\ominus B $$ 即先用$B$对$A$膨胀，然后用$B$对腐蚀结果进行腐蚀。 性质： $A\\bullet B$是$A$的子集 若$C \\subseteq D$，则$C\\bullet B\\subseteq D\\bullet B$ $(A\\bullet B)\\bullet B=A \\bullet B$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:24:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"实例（MATLAB） 实例1 A=imread('shapes.tif'); B=strel('square',20); result_open=imopen(A,B); result_close=imclose(A,B); result_open_close(result_open,B); 实例2（去除指纹图像上的杂散点） A=imread('noisy-fingerprint.tif'); B=strel('square',3); result_open=imopen(A,B); result_open_close=imclose(result_open,B); ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:24:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"形态学的主要应用 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:25:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"边界提取 图像$A$的边界$b(A)$定义为： $$ b(A)=A-(A\\ominus B) $$ 其中，$B$是适当的结构元素。 边界提取实例（MATLAB）： A=imread('people.jpg'); B=strel('square',3); result=A-imerode(A,B); ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:25:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"孔洞填充 孔洞：被前景像素连成的边框所包围的背景区域。 令$A$表示一个集合：其元素是$8$连通的边界，且每个边界包围一个孔洞； 令$X_0$表示一个与包含$A$的相同大小的阵列，其初始状态为： 包含每个孔洞中的一个指定位置处的前景像素点； 除上述的前景像素点外，其余元素均为背景像素点。 在给定$A$和$X_0$的前提下，采用前景像素填充$A$的所有空洞的过程如下： $$ X_k=(X_{k-1}\\oplus B)\\cap A^c\\quad k=1,2,3,\\cdots $$ 其中，$B$是对称结构元素，$B=\\begin{bmatrix}0 \u0026 1 \u0026 0 \\ 1 \u0026 1 \u0026 1 \\ 0 \u0026 1 \u0026 0\\end{bmatrix}$； 若$X_k=X_{k-1}$，则算法在迭代的第$k$步结束； 集合$X_k$包含所有被填充的孔洞，$X_k$和$A$的并集则包含被填充的孔洞及其边界。 每一步运算中，膨胀结果与$A^c$的交集操作实现了将膨胀结果限制在感兴趣区域内，即条件膨胀。 B对图像X的膨胀是B对X的前景元素的膨胀。 图像缩放 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:25:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像缩放的变换公式 直接坐标公式： $$ \\begin{aligned} x\u0026=c_xx_0 \\ y\u0026=c_yy_0 \\end{aligned} $$ 齐次坐标公式： $$ \\begin{bmatrix} x \u0026 y \u0026 1 \\end{bmatrix} \\begin{bmatrix} x_0 \u0026 y_0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} c_x \u0026 0 \u0026 0\\ 0 \u0026 c_y \u0026 0\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} c_xx_0 \u0026 c_yy_0 \u0026 1 \\end{bmatrix} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:26:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像的缩小 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:27:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像缩小的实现方法 一个简单方法是等间隔地选取样本（重采样）。 以采样间隔$2$为例： $$ \\begin{bmatrix} 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \\ 0 \u0026 1 \u0026 0 \u0026 2 \u0026 0 \u0026 3 \\ 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \\ 0 \u0026 4 \u0026 0 \u0026 5 \u0026 0 \u0026 6 \\ 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \u0026 0 \\ 0 \u0026 7 \u0026 0 \u0026 8 \u0026 0 \u0026 9 \\end{bmatrix}{6\\times 6} \\longrightarrow \\begin{bmatrix} 1 \u0026 2 \u0026 3\\ 4 \u0026 5 \u0026 6\\ 7 \u0026 8 \u0026 9 \\end{bmatrix}{3\\times 3} $$ 算法步骤： 确定重采样的行和列（采样间隔） $M\\times N\\rightarrow c_xM\\times c_yN$，采样间隔： $$ k_x=\\frac{1}{c_x}\\quad k_y=\\frac{1}{c_y} $$ 重采样 $$ G(x,y)=F(int(k_x\\times x),int(k_y\\times y)) $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:27:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像的放大 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:28:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像放大的实现方法 当放大倍数$k$为整数时，可以采取如下例（放大$3$倍）所示的简单方法： $$ \\begin{bmatrix} 1 \u0026 2\\ 3 \u0026 4 \\end{bmatrix}{2\\times 2} \\longrightarrow \\begin{bmatrix} 1 \u0026 1 \u0026 1 \u0026 2 \u0026 2 \u0026 2 \\ 1 \u0026 1 \u0026 1 \u0026 2 \u0026 2 \u0026 2 \\ 1 \u0026 1 \u0026 1 \u0026 2 \u0026 2 \u0026 2 \\ 3 \u0026 3 \u0026 3 \u0026 4 \u0026 4 \u0026 4 \\ 3 \u0026 3 \u0026 3 \u0026 4 \u0026 4 \u0026 4 \\ 3 \u0026 3 \u0026 3 \u0026 4 \u0026 4 \u0026 4 \\ \\end{bmatrix}{6\\times 6} $$ 问题：容易出现马赛克效应。 算法步骤： 计算放大后图像的大小 $M\\times N \\rightarrow c_xM\\times C_yN$ 求出放大的新图像像素值 $$ G(x,y)=F(\\frac{x}{c_x},\\frac{y}{c_y}) $$ 采用插值法解决映射坐标$(x/c_x,y/c_y)$在原图像空间中不存在的情况。 $$ \\begin{bmatrix} 11 \u0026 12 \u0026 13 \\ 21 \u0026 22 \u0026 23 \\ 31 \u0026 32 \u0026 33 \\end{bmatrix}{3\\times 3} \\longrightarrow \\begin{bmatrix} 11 \u0026 ? \u0026 12 \u0026 ? \u0026 13 \u0026 ? \\ 21 \u0026 ? \u0026 22 \u0026 ? \u0026 23 \u0026 ?\\ 31 \u0026 ? \u0026 32 \u0026 ? \u0026 33 \u0026 ? \\end{bmatrix}{3\\times 6} $$ $$ \\begin{aligned} G(0,0)=F(0,0) \\quad G(0,1)=F(0,0.5)=?\\ G(1,0)=F(1,0) \\quad G(1,1)=F(1,0.5)=?\\ G(2,0)=F(2,0) \\quad G(2,1)=F(2,0.5)=? \\end{aligned} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:28:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"最近邻插值 将放大后未知的像素点坐标换算到原始图像，与原始图像上邻近的$4$个像素点比较，最靠近邻近点的像素值即为该未知像素点的像素值。 算法步骤： $(u,v)(G)\\rightarrow(x+\\Delta{x},y+\\Delta{y})$； 计算$(x+\\Delta{x},y+\\Delta{y})$与$(x,y)、(x,y+1)、(x+1,y)、(x+1,y+1)$之间的距离，取距离最短的点的像素值作为$(u,v)$的像素值。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:28:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"双线性插值 将放大后未知的像素点坐标换算到原始图像，计算原始图像上$4$个邻近像素点$A、B、C、D$对$P$点的影响，$P$点灰度值由$4$个邻近点灰度值加权求和得到（权值可以用距离进行度量）。 算法步骤： 根据$(x+\\Delta{x},y+\\Delta{y})$确定： $$ (x,y)、(x,y+1)、(x+1,y)、(x+1,y+1) $$ 由$A、B$两点插值计算出$e$点的灰度值的$F(x,y+\\Delta{y})$； $$ \\begin{aligned} F(x,y+\\Delta{y})\u0026=\\frac{\\sqrt{(x-x)^2+((y+1)-(y+\\Delta{y}))^2}}{\\sqrt{(x-x)^2+((y+1)-y)^2}}F(x,y)\\ \u0026\\quad\\ +\\frac{\\sqrt{(x-x)^2+((y+\\Delta{y})-y)^2}}{\\sqrt{(x-x)^2+((y+1)-y)^2}}F(x,y+1) \\ \u0026= (1-\\Delta{y})\\times F(x,y)+\\Delta{y}\\times F(x,y+1) \\end{aligned} $$ $$ \\begin{bmatrix} B(x,y+1) \u0026 \\cdot \u0026 \\cdot \\ e(x,y+\\Delta{y}) \u0026 \\cdot \u0026 \\cdot\\ A(x,y) \u0026 \\cdot \u0026 \\cdot \\end{bmatrix} $$ 由$C、D$两点插值计算出$f$点的灰度值$F(x+1,y+\\Delta{y})$； $$ \\begin{aligned} F(x+1,y+\\Delta{y})\u0026=\\frac{\\sqrt{((x+1)-(x+1))^2+((y+1)-(y+\\Delta{y}))^2}}{\\sqrt{((x+1)-(x+1))^2+((y+1)-y)^2}}F(x+1,y)\\ \u0026\\quad\\ +\\frac{\\sqrt{((x+1)-(x+1))^2+((y+\\Delta{y})-y)^2}}{\\sqrt{((x+1)-(x+1))^2+((y+1)-y)^2}}F(x+1,y+1) \\ \u0026= (1-\\Delta{y})\\times F(x+1,y)+\\Delta{y}\\times F(x+1,y+1) \\end{aligned} $$ $$ \\begin{bmatrix} \\cdot \u0026 \\cdot \u0026 D(x+1,y+1) \\ \\cdot \u0026 \\cdot \u0026 f(x+1,y+\\Delta{y})\\ \\cdot \u0026 \\cdot \u0026 C(x+1,y) \\end{bmatrix} $$ 由$e、f$两点插值计算出$P$点的灰度值$F(x+\\Delta{x},y+\\Delta{y})$。 $$ \\begin{aligned} F(x+\\Delta{x},y+\\Delta{y})\u0026=\\frac{\\sqrt{((x+1)-(x+\\Delta{x}))^2+((y+\\Delta{y})-(y+\\Delta{y}))^2}}{\\sqrt{((x+1)-x)^2+((y+\\Delta{y})-(y+\\Delta{y}))^2}}F(x,y+\\Delta{y})\\ \u0026\\quad\\ +\\frac{\\sqrt{((x+\\Delta{x})-x)^2+((y+\\Delta{y})-(y+\\Delta{y}))^2}}{\\sqrt{((x+1)-x)^2+((y+\\Delta{y})-(y+\\Delta{y}))^2}}F(x+1,y+\\Delta{y}) \\ \u0026= (1-\\Delta{x})\\times F(x,y+\\Delta{y})+\\Delta{x}\\times F(x+1,y+\\Delta{y}) \\end{aligned} $$ $$ \\begin{bmatrix} \\cdot \u0026 \\cdot \u0026 \\cdot \\ e(x,y+\\Delta{y}) \u0026 P(x+\\Delta{x},y+\\Delta{y}) \u0026 f(x+1,y+\\Delta{y})\\ \\cdot \u0026 \\cdot \u0026 \\cdot \\end{bmatrix} $$ 示例： $$ \\begin{bmatrix} 11 \u0026 12 \u0026 13 \\ 21 \u0026 22 \u0026 23 \\ 31 \u0026 32 \u0026 33 \\end{bmatrix}{3\\times 3} \\longrightarrow \\begin{bmatrix} ? \u0026 ? \u0026 ? \u0026 ? \u0026 ? \u0026 ? \\ ? \u0026 ? \u0026 ? \u0026 ? \u0026 ? \u0026 ?\\ ? \u0026 ? \u0026 ? \u0026 ? \u0026 ? \u0026 ? \\end{bmatrix}{3\\times 6} $$ 放大比例$c_x=1,c_y=2$，新图像$G$的像素坐标： $$ \\begin{aligned} X\u0026= \\begin{bmatrix} 0 \u0026 1 \u0026 2 \\end{bmatrix} \\ Y\u0026= \\begin{bmatrix} 0 \u0026 1 \u0026 2 \u0026 3 \u0026 4 \u0026 5 \\end{bmatrix} \\end{aligned} $$ 则在原图像$F$中的映射坐标： $$ \\begin{aligned} X\u0026= \\begin{bmatrix} 0 \u0026 1 \u0026 2 \\end{bmatrix} \\ Y\u0026= \\begin{bmatrix} 0 \u0026 0.5 \u0026 1 \u0026 1.5 \u0026 2 \u0026 2.5 \\end{bmatrix} \\end{aligned} $$ 则可得$G$中部分点的像素值： $$ \\begin{bmatrix} 11 \u0026 ? \u0026 12 \u0026 ? \u0026 13 \u0026 ? \\ 21 \u0026 ? \u0026 22 \u0026 ? \u0026 23 \u0026 ?\\ 31 \u0026 ? \u0026 32 \u0026 ? \u0026 33 \u0026 ? \\end{bmatrix}_{3\\times 6} $$ 对于$G(0,1)=F(0,0.5)$，$F(0,0.5)$的邻近像素： $$ \\begin{bmatrix} F(0,0) \u0026 F(0,1) \\ F(1,0) \u0026 F(1,1) \\end{bmatrix} $$ $\\cdots\\cdots$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:28:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"双三次插值 算法原理： 未知像素点$P(u,v)(G)\\rightarrow$ 原始图像空间$(x,y)$； 确定原始图像上的$16$个邻近像素点； 采用下式计算$P$点的灰度值$F(x,y)$： $$ F(x,y)=\\sum_{i=0}^3\\sum_{j=0}^{3}a_{ij}x^iy^j $$ 其中，$16$个未知系数$a_{ij}$可由原始图像$(x,y)$处的$16$个邻近像素所确定的方程组进行求解。 算法步骤： 坐标映射，确定原图像中的16个邻近点； $$ \\begin{bmatrix} \\cdot \u0026 \u0026 \\cdot \u0026 \u0026 \\cdot \u0026 \u0026 \\cdot \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \\cdot \u0026 \u0026 \\cdot \u0026 \u0026 \\cdot \u0026 \u0026 \\cdot \\ \u0026 \u0026 \u0026 \\bullet\u0026 \u0026 \u0026 \\ \\cdot \u0026 \u0026 \\cdot \u0026 \u0026 \\cdot \u0026 \u0026 \\cdot \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \\cdot \u0026 \u0026 \\cdot \u0026 \u0026 \\cdot \u0026 \u0026 \\cdot \\ \\end{bmatrix} $$ 在$4$条水平直线上分别用三次多项式插值，计算点$A、B、C、D$处的灰度值； $$ \\begin{bmatrix} \\cdot \u0026 \u0026 \\cdot \u0026 A\\cdot \u0026 \\cdot \u0026 \u0026 \\cdot \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \\cdot \u0026 \u0026 \\cdot \u0026 B\\cdot \u0026 \\cdot \u0026 \u0026 \\cdot \\ \u0026 \u0026 \u0026 \\bullet\u0026 \u0026 \u0026 \\ \\cdot \u0026 \u0026 \\cdot \u0026 C\\cdot \u0026 \\cdot \u0026 \u0026 \\cdot \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \\cdot \u0026 \u0026 \\cdot \u0026 D\\cdot \u0026 \\cdot \u0026 \u0026 \\cdot \\end{bmatrix} $$ $$ F(x,y)=\\sum_{j=0}^{3}a_jy^j $$ 对$A、B、C、D$四点在垂直方向上再做三次多项式插值。 $$ \\begin{bmatrix} \\cdot \u0026 \u0026 \\cdot \u0026 A\\cdot \u0026 \\cdot \u0026 \u0026 \\cdot \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \\cdot \u0026 \u0026 \\cdot \u0026 B\\cdot \u0026 \\cdot \u0026 \u0026 \\cdot \\ \u0026 \u0026 \u0026 P\\bullet\u0026 \u0026 \u0026 \\ \\cdot \u0026 \u0026 \\cdot \u0026 C\\cdot \u0026 \\cdot \u0026 \u0026 \\cdot \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \\cdot \u0026 \u0026 \\cdot \u0026 D\\cdot \u0026 \\cdot \u0026 \u0026 \\cdot \\end{bmatrix} $$ $$ F(x,y)=\\sum_{i=0}^{3}b_ix^i $$ 图像边缘检测 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:28:4","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"概述 物体边界、表面方向的改变、不同的颜色、光照明暗的变化… 图像边缘是一组相连的像素集合，这些像素位于两个不同区域的边界上。边缘检测是一种典型的图像预处理过程。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:29:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像的边缘模型 台阶边缘 在1个像素的距离上发生两个灰度级间理想的过渡。 $$ \\begin{bmatrix} 0 \u0026 0 \u0026 0 \u0026 3 \u0026 3 \u0026 3 \\end{bmatrix} $$ 斜坡边缘 边缘的宽度不只1个像素宽。 $$ \\begin{bmatrix} 0 \u0026 0 \u0026 0 \u0026 1 \u0026 2 \u0026 3 \u0026 3 \u0026 3 \\end{bmatrix} $$ 屋顶边缘 通过一个区域的线的模型，边缘的宽度由该线的宽度和尖锐度决定。 $$ \\begin{bmatrix} 0 \u0026 0 \u0026 1 \u0026 3 \u0026 1 \u0026 0 \u0026 0 \\end{bmatrix} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:29:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"无噪图像的导数与边缘的关系 $$ \\begin{bmatrix} f \u0026 \u00260 \u0026 0 \u0026 1 \u0026 2 \u0026 3 \u0026 3 \u0026 3 \\ f’ \u0026 \u00260 \u0026 0 \u0026 1 \u0026 1 \u0026 1 \u0026 0 \u0026 0 \\ f’’ \u0026 \u00260 \u0026 0 \u0026 1 \u0026 0 \u0026 -1 \u0026 0 \u0026 0 \\end{bmatrix} $$ 一阶导数的幅值可检测图像中某个点处是否存在一个边缘（峰值为边缘的位置）； 二阶导数的符号可用于确定一个边缘像素位于该边缘偏暗的一侧还是偏亮的一侧； 对于图像中的每条边缘，二阶导数生成两个值，同时二阶导数的零交叉点可用于定位粗边缘的中心。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:29:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"基本的边缘检测技术 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:30:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"图像梯度及其性质 梯度$\\nabla f$、梯度的幅值$|\\nabla f|$、梯度的方向$\\alpha(x,y)$： $$ \\begin{gather*} \\nabla f= \\begin{bmatrix} g_x \u0026 g_y \\end{bmatrix}^T \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \u0026 \\frac{\\partial f}{\\partial y} \\end{bmatrix}^T \\ |\\nabla f|=\\sqrt{g_x^2+g_y^2}=\\sqrt{(\\frac{\\partial f}{\\partial x})^2 + (\\frac{\\partial f}{\\partial y})^2} \\ \\alpha(x,y)=\\arctan[\\frac{g_y}{g_x}] \\end{gather*} $$ 任意点$(x,y)$处边缘的方向与该点处梯度的方向$\\alpha(x,y)$正交。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:30:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"梯度算子——直接差分算子 $$ \\begin{aligned} g_x=f(x+1,y)-f(x,y) \\ g_y=f(x,y+1)-f(x,y) \\end{aligned} $$ 直接差分模板： $$ \\begin{bmatrix} \\underline{-1} \u0026 0\\ 1 \u0026 0 \\end{bmatrix} \\quad \\begin{bmatrix} \\underline{-1} \u0026 1\\ 0 \u0026 0 \\end{bmatrix} $$ 直接差分算子仅能检测水平、垂直方向的边缘。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:30:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"梯度算子——Roberts算子 $$ \\begin{aligned} g_x=f(x+1,y+1)-f(x,y) \\ g_y=f(x+1,y)-f(x,y+1) \\end{aligned} $$ Roberts模板： $$ \\begin{bmatrix} \\underline{-1} \u0026 0\\ 0 \u0026 1 \\end{bmatrix} \\quad \\begin{bmatrix} \\underline{0} \u0026 -1\\ 1 \u0026 0 \\end{bmatrix} $$ Roberts算子可用于检测对角线方向的边缘。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:30:3","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"梯度算子——Prewitt算子 Prewitt模板： $$ \\begin{bmatrix} -1 \u0026 -1 \u0026 -1 \\ 0 \u0026 \\underline{0} \u0026 0\\ 1 \u0026 1 \u0026 1 \\end{bmatrix} \\quad \\begin{bmatrix} -1 \u0026 0 \u0026 1 \\ -1 \u0026 \\underline{0} \u0026 1\\ -1 \u0026 0 \u0026 1 \\end{bmatrix} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:30:4","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"梯度算子——Sobel算子 Sobel模板： $$ \\begin{bmatrix} -1 \u0026 -2 \u0026 -1 \\ 0 \u0026 \\underline{0} \u0026 0\\ 1 \u0026 2 \u0026 1 \\end{bmatrix} \\quad \\begin{bmatrix} -1 \u0026 0 \u0026 1 \\ -2 \u0026 \\underline{0} \u0026 2\\ -1 \u0026 0 \u0026 1 \\end{bmatrix} $$ ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:30:5","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"梯度算子——用于检测对角边缘的Prewitt、Sobel算子 对上述的Prewit模板和Sobel模板作出修改，以便它们沿对角线方向有最大的响应。 用于检测对角边缘的Prewitt模板： $$ 45\\degree 方向梯度 \\begin{bmatrix} 0 \u0026 1 \u0026 1 \\ -1 \u0026 \\underline{0} \u0026 1\\ -1 \u0026 -1 \u0026 0 \\end{bmatrix} \\quad -45\\degree 方向梯度 \\begin{bmatrix} -1 \u0026 -1 \u0026 0 \\ -1 \u0026 \\underline{0} \u0026 1\\ 0 \u0026 1 \u0026 1 \\end{bmatrix} $$ 用于检测对角边缘的Sobel模板： $$ 45\\degree 方向梯度 \\begin{bmatrix} 0 \u0026 1 \u0026 2 \\ -1 \u0026 \\underline{0} \u0026 1\\ -2 \u0026 -1 \u0026 0 \\end{bmatrix} \\quad -45\\degree 方向梯度 \\begin{bmatrix} -2 \u0026 -1 \u0026 0 \\ -1 \u0026 \\underline{0} \u0026 1\\ 0 \u0026 1 \u0026 2 \\end{bmatrix} $$ 一些对边缘检测不必要的细节往往表现为噪声，处理方法为：对图像进行平滑处理后再进行边缘检测。 参考程序（MATLAB）： im=im2double(imread('building.tif')); im=filter2(fspecial('average',5),im); template=[-1 -2 -1;0 0 0;1 2 1]; gx=abs(filter2(template,im)); gy=abs(filter2(template,im)); imGrad=gx+gy; subplot(2,2,1);imshow(im); subplot(2,2,2);imshow(gx); subplot(2,2,3);imshow(gy); subplot(2,2,4);imshow(imGrad); im=im2double(imread('building.tif')); im=filter2(fspecial('average',5),im); template45=[0 1 2;-1 0 1;-2 -1 0]; template135=[-2 -1 0;-1 0 1;0 1 2]; grad45=abs(filter2(template45,im)); grad135=abs(filter2(template135,im)); subplot(3,1,1);imshow(im); subplot(3,1,2);imshow(grad45); subplot(3,1,3);imshow(grad135); ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:30:6","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"先进的边缘检测技术 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:31:0","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Marr-Hildreth（马尔-希尔德雷斯）边缘检测器 基于二阶微分（导数）的边缘检测技术——拉普拉斯算子 图像$f$在$(x,y)$处的拉普拉斯变换定义为： $$ \\nabla^2f=\\frac{\\partial^2f}{\\partial x^2}+\\frac{\\partial^2f}{\\partial y^2} $$ 其中： $$ \\begin{aligned} \\frac{\\partial^2f}{\\partial x^2}=f(x+1,y)+f(x-1,y)-2f(x,y) \\ \\frac{\\partial^2f}{\\partial y^2}=f(x,y+1)+f(x,y-1)-2f(x,y) \\end{aligned} $$ 拉普拉斯模板： $$ \\begin{bmatrix} 0 \u0026 -1 \u0026 0\\ -1 \u0026 \\underline{4} \u0026 -1\\ 0 \u0026 -1 \u0026 0 \\end{bmatrix} $$ 优点： 可以利用零交叉的性质进行边缘定位； $$ \\begin{bmatrix} f’’ \u0026 \u0026 0 \u0026 0 \u0026 -1 \u0026 1 \u0026 0 \u0026 0 \\end{bmatrix} $$ 连接$-1$和$1$，与轴线相交的点即为零交叉点。 可以确定一个像素是在边缘暗的一边还是亮的一边。 缺点： 对噪声具有敏感性； 幅值产生双边缘； 不能检测边缘的方向。 Marr-Hildreth边缘检测器的提出及实现 Marr-Hildreth边缘检测算法由LoG滤波器（高斯-拉普拉斯滤波器）与输入图像$f(x,y)$卷积组成，即 $$ g(x,y)=[\\nabla^2G(x,y)]*f(x,y) $$ 然后，寻找零交叉来确定$f(x,y)$中边缘的位置，由于微分、卷积运算均为线性操作，则上式表示为： $$ g(x,y)=\\nabla^2[G(x,y)*f(x,y)] $$ 即，先使用一个高斯平滑滤波器平滑图像，然后对该结果执行拉普拉斯变换，故Marr-Hildreth边缘检测算法实现步骤如下： 使用高斯滤波器对输入图像进行平滑滤波； 计算由第一步骤得到的图像的拉普拉斯变换； 寻找第二步骤所的图像的零交叉（由此得到的边缘为一个像素宽）。 满足上述要求的算子是$\\nabla^2G$（高斯拉普拉斯算子，简称LoG算子），其中： $\\nabla^2$是拉普拉斯算子： $$ \\frac{\\partial^2}{\\partial x^2}+\\frac{\\partial^2}{\\partial y^2} $$ $G$是标准差为$\\sigma$的二维高斯函数： $$ G(x,y)=e^{-\\frac{x^2+y^2}{2\\sigma^2}} $$ 即： $$ \\begin{aligned} \\nabla^2G(x,y)\u0026=\\frac{\\partial^2G(x,y)}{\\partial x^2}+\\frac{\\partial^2G(x,y)}{\\partial y^2}\\ \u0026=\\frac{\\partial}{\\partial x}[\\frac{-x}{\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}]+\\frac{\\partial}{\\partial y}[\\frac{-y}{\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}] \\ \u0026=[\\frac{x^2}{\\sigma^4}-\\frac{1}{\\sigma^2}]e^{-\\frac{x^2+y^2}{2\\sigma^2}}+[\\frac{y^2}{\\sigma^4}-\\frac{1}{\\sigma^2}]e^{-\\frac{x^2+y^2}{2\\sigma^2}}\\ \u0026=\\frac{x^2+y^2-2\\sigma^2}{\\sigma^4}e^{-\\frac{x^2+y^2}{2\\sigma^2}} \\end{aligned} $$ 近似的$5\\times 5$模板（该近似不唯一）： $$ \\begin{bmatrix} 0 \u0026 0 \u0026 -1 \u0026 0 \u0026 0 \\ 0 \u0026 -1 \u0026 -2 \u0026 -1 \u0026 0 \\ -1 \u0026 -2 \u0026 16 \u0026 -2 \u0026 -1 \\ 0 \u0026 -1 \u0026 -2 \u0026 -1 \u0026 0 \\ 0 \u0026 0 \u0026 -1 \u0026 0 \u0026 0 \\end{bmatrix} $$ 通过该模板得到的图像来寻找零交叉点以进行图像的边缘检测。 实例（MATLAB）： edge_LoG=edge(inputImage,'log',T,sigma) 寻找零交叉的方法 判定图像$g(x,y)$的任意像素$p$是否为零交叉点的一种方法如下： 在图像$g(x,y)$中找到一个以$p$为中心的$3\\times 3$邻域； $p$像素为零交叉点意味着至少有两个相对的邻域像素的符号不同，有4种要测试的情况：左/右、上/下和两个对角； 如果相对的两个邻域像素的符号不同，而且它们的像素值与$p$的像素值的绝对值差值超过指定的阈值。那么，$p$即为一个零交叉像素。 对于阈值为$0$的零交叉检测，会产生严重的意大利通心粉效应：所有的边缘都形成闭环，使用正阈值可避免闭环边缘。 优点： 零交叉点图像中的边缘比梯度边缘细； 抑制噪声能力和反干扰性能好。 缺点： 边缘由零交叉点构成，而零交叉点计算比较复杂。 ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:31:1","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Canny（坎尼）边缘检测器 坎尼边缘检测器是基于一阶微分的边缘检测方法。 实现步骤： 用一个大小为$n\\times n$的高斯滤波器平滑输入图像（$n$的取值应为大于或等于$6$倍高斯滤波器的标准差的最小奇整数）； 计算滤波后图像的梯度幅值和方向角度； 对梯度幅值执行非极大值抑制（剔除伪边缘点，保留候选边缘点）； 对非极大值抑制的结果使用双阈值检测边缘（从候选边缘点中选择真实边缘点）； 采用连接分析对双阈值边缘检测结果进行连接（得到连续完整的边缘）。 非极大值抑制（Non-Maxima Suppression, NMS） 仅保留梯度幅值图像$M(x,y)$的极大值（严格上，保留梯度方向的极大值点），以实现边缘细化。 局部极值（$B$）周围存在相近数值的点（$A$、$C$），通过非极大值抑制选择适合的极值点作为边缘点. $$ \\begin{bmatrix} \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\cdot B\u0026 \u0026 \u0026 \u0026 \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\cdot C\u0026 \u0026 \u0026 \\ \u0026 \u0026 \u0026 \u0026 \u0026 \\cdot A\u0026 \u0026 \u0026 \u0026 \u0026 \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ Th-\u0026-\u0026-\u0026-\u0026-\u0026-\u0026-\u0026-\u0026-\u0026-\u0026- \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\ \u0026 \u0026 \u0026 \u0026\\cdot \u0026 \u0026 \u0026 \u0026 \\cdot\u0026 \u0026 \\ \u0026\\cdot \u0026 \u0026\\cdot \u0026 \u0026 \u0026 \u0026 \u0026 \u0026\\cdot \u0026 \\ \\cdot\u0026 \u0026\\cdot \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \u0026 \\cdot\\ \\end{bmatrix} $$ 实现步骤：（假设仅保留梯度幅值极大值的结果为$N(x,y)$） 将$N(x,y)$初始化为原始的梯度幅值图像$M(x,y)$； 对于每个点$N(x,y)$，在梯度方向和反梯度方向各找$n$个像素点，若$N(x,y)$不是这些点中的最大点，则将$N(x,y)$置零，否则保持$N(x,y)$不变。 对NMS结果使用双阈值检测边缘 检测过程： 指定两个阈值$T_H、T_L$：$T_H\\gt T_L$（建议高阈值与低阈值比率为$2:1$或$3:1$）； 使用高阈值$T_H$检测边缘，得到高阈值边缘图$E_H(x,y)$（边缘点少但可靠）； 使用低阈值$T_L$检测边缘，得到低阈值边缘图$E_L(x,y)$（边缘点多但错误检测率高）。 对双阈值边缘检测结果进行边缘连接 连接过程： 将高阈值边缘图$E_H(x,y)$中相连的边缘点输出为一副边缘图像$E(x,y)$； 对于$E(x,y)$中每条边，从端点出发在低阈值边缘图$E_L(x,y)$中寻找其延长的部分，直至与$E(x,y)$中另外一条边的端点相连（8连通性），否则认为$E_L(x,y)$中没有它延长的部分； 将$E(x,y)$作为结果输出。 Canny边缘检测实例（MATLAB）： edge_LoG=edge(inputImage,'canny',[T1 T2],sigma) ","date":"February 5, 2022","objectID":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/:31:2","tags":null,"title":"数字图像处理 课程笔记","uri":"/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"自从使用Hexo搭建个人博客以来，在建站、迁移以及服务器等方面都遇到了不少问题，本篇博文对所遇到的问题进行总结，会持续更新。 Linux设置定时任务 环境：CentOS 8 ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:0:0","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"执行内容 　新建文件_crond.sh，作为定时执行的内容。 #!/bin/bash cd /www/blog/hexo git pull git@github.com:egname/egrepo.git #echo pull successfully \u003e /home/gitpull.log ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:1:0","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"crontab服务 　启动crontab服务，CentOS版本不同，具体命令可能有所差异。 systemctl start crond 　启动服务 systemctl stop crond # 关闭服务 systemctl restart crond # 重启服务 systemctl reload crond # 重新载入配置 systemctl status crond # 状态 ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:2:0","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"设置计时器 　crontab 选项 参数 选项: -e：编辑该用户的计时器设置； -l：列出该用户的计时器设置； -r：删除该用户的计时器设置； -u：指定要设定计时器的用户名称。 crontab -e 　进入insert插入模式，以每五秒钟执行一次为例。ESC后输入wq保存并退出。 */5 * * * * /root/_crond.sh node版本过高 　具体Warning内容如下： (node:15748) Warning: Accessing non-existent property 'column' of module exports inside circular dependency (node:15748) Warning: Accessing non-existent property 'filename' of module exports inside circular dependency (node:15748) Warning: Accessing non-existent property 'lineno' of module exports inside circular dependency (node:15748) Warning: Accessing non-existent property 'column' of module exports inside circular dependency (node:15748) Warning: Accessing non-existent property 'filename' of module exports inside circular dependency 　解决方式：找到博客目录下node_modules\\stylus\\lib\\nodes\\index.js，在index.js下加入以下代码： exports.lineno = null; exports.column = null; exports.filename = null; 博客迁移 ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:3:0","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"1 环境安装 ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:4:0","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"git 1 配置git git config --global user.name \"yourname\" git config --global user.email \"youremail\" 2 生成、配置密钥 ssh-keygen -t rsa -C \"youremail\" 　获取密钥内容后在GitHub上配置SSH Keys，此处略。 ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:4:1","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"npm、hexo、node.js 　使用常规方式安装即可。 sudo apt install nodejs sudo apt-get install npm sudo npm install -g hexo-cli ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:4:2","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"2 文件迁移 　从原设备上将Hexo博客文件夹迁移至新设备。 ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:5:0","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"3 重新部署 ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:6:0","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"1 安装插件 cd HexoBlog npm install ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:6:1","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"2 清除缓存并重新生成 hexo clean hexo g hexo d 阿里云ECS连接出错 　具体报错如下： 访问公网IP地址需要在实例安全组白名单中增加Workbench的服务器白名单: xxx.xxx.xxx.xxx/24 xxx.xxx.xxx.xxx/24 　尝试多种方案未果，使用WinSCP，可以正常连接。 Valine评论系统 部分页面隐藏TOC栏 在对应界面的Markdown文件中设置： toc: enable: false ","date":"February 4, 2022","objectID":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/:6:2","tags":null,"title":"Hexo博客及各组件的部署过程和常见问题","uri":"/hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E9%83%A8%E7%BD%B2%E8%BF%87%E7%A8%8B%E5%92%8C%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"今天是2021年的最后一天，在此总结一下这一年来的收获。 回顾2021 ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:0:0","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"兴趣 ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:1:0","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"摄影📷 　去年年初将主力机换为小米10 Pro，16mm-28mm-50mm-94mm的组合让我第一次体验到了不同焦段下的视觉效果，今年年初也如愿购入一台富士无反相机和一支XC16-50mmⅡ镜头，从XC35mm F2再到7artisans 55mm F1.4第一次体验了到大光定的魅力，转接EF-S 55-250mm成为第一支长焦镜头，7artisans 12mm F2.8又把视角从长焦带回超广角… “摄影是一门用光的艺术”，这句话说的确实有道理，入坑摄影的这一年来，钱似乎已经被我用光了。但是相机已经成为了我出门必须要携带的工具，虽然开始的开始，总是忘记调整参数，大晚上的还傻乎乎把ISO拨到320、把光圈拨到F8，拍出来一片黑还抱怨相机不够“智能”，不能像手机一样一键出片，但年底的一次手机拍摄又让我疯狂想念用相机拍摄的日子。 下面放几张今年拍的照片吧，拍的很一般，这一年出门的机会也不多，希望明年能多出去走走。 ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:1:1","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"吉他🎸 　今年真正静下心来练琴的时间可能只有年初的寒假了，寒假之后只带了木吉他去学校，每天晚上回宿舍闲着了就拿起来简单弹一弹。去年年末在室友的疯狂输出下，学习了YoungsoKim的Like A Star。希望明年能多抽出时间练练琴、学学新歌，每次拿起琴都在磨同一首歌自己都有点听腻了。 ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:1:2","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"学习 ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:2:0","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"研考📖 　备战2022研考是我过去一年投入时间最多的一件事情，这可能也是我整个大学期间学习最认真的一段时间，期间经历了大起大落，也做出了很多我以前重来不敢想的决定。 我所报考的学校和我最初的想法相差甚远。虽然最初就准备考数一英一408这套噩梦组合，但中间因为参加了几场大大小小的比赛，耽误了一些时间，就把专业课从4门缩到2门最后再到一门DS，九月份返校后，在仅结束完DS一轮的情况下，我决定将专业课重新改回为408，也就在那天，408考纲大改，仅DS就增加了并查集和红黑树两个大头。那段时间非常痛苦，庆幸的是熬过来了。 写这篇文章时，初试已经过去几天了，粗略对了答案，虽然数学略有遗憾，但整体还是比较满意，没有辜负自己大半年的努力。 ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:2:1","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"竞赛🏆 　本以为准备考研了就基本不会再打比赛了，但是今年上半年还是抽出了很多时间来参加比赛，一方面是弥补一下去年的遗憾，二来是打比赛真的会让人上瘾[表情]，下面列举一些今年参加的一些大大小小的比赛吧~ - 山东省第二届数据应用创新创业大赛主赛场-疫情密切接触人员追踪 决赛Rank16 - 招商银行2021FinTech精英训练营 Rank53 - 中博教育财经求职力挑战赛 （当了一把摸鱼的混子） - 2021中国高校计算机大赛-微信大数据挑战赛 Rank70 全国三等奖 - 第十三届全国大学生数学竞赛-湖北赛区-非数学类 一等奖 明年如果能有机会读研，希望能有更多的时间参加比赛，也希望可以提高一下自己的能力，争取拿个top~ ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:2:2","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"生活 ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:3:0","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"音乐🎵 　今年非常喜欢房东的猫，每次试图让自己安静下来就喜欢听她们的歌。本想着疫情好转，今年能在武汉看到她们的现场，但今年下半年她们没有在武汉安排巡演，年底25号的演出也因为研考错过了，希望明年可以去现场看到小黑和佩岭。 小马丁和STMPD RCRDS今年也发了很多高质量曲目，可惜因为疫情，这两年可能很难在国内看到马老板的演出了。 ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:3:1","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"饮食🍕 　今年的活动半径似乎并不是很大，少有的出门时间几乎都花在吃饭上了，那就说说今年去过的一些店吧~ - 北疆饭店 新疆菜 在银泰创意城。去过好多次，比较喜欢大盘鸡和羊肉串，味道正宗。 - 添好彩、茶港 茶餐厅 在武汉天地。最喜欢叉烧饭，吃多了有点小腻。 - 海鲜烧烤 在建安街。很多次和朋友吃饭都会来这家，价格略贵，但味道很好。最爱红糖糍粑，每次和朋友去都会直接叫两份。 - 东北菜馆 在东湖学院附近。价格实惠，量也很足，虽然卖的最好的锅包肉我觉得很难吃… 规划2022 　2022年上半年的任务不多，完成毕业设计、（可能）准备复试，（可能）准备找份工作，其余的时间就做做比赛，学习一些新东西。 我不太喜欢给自己立一些Flag，不患得患失，确定要做什么事情尽力去做吧~ ","date":"December 31, 2021","objectID":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/:3:2","tags":null,"title":"2021年度总结","uri":"/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"2021大数据高校赛初赛已经结束，今年的比赛规则和去年有所不同，没有对在职队伍的数量做限制。我们队伍的初赛最终排名68/6768，线上A、B榜排名分别为91、85。在此记录一下我在初赛阶段的上分过程。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:0:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"赛题描述 　本次比赛基于脱敏和采样后的数据信息，对于给定的一定数量到访过微信视频号“热门推荐”的用户， 根据这些用户在视频号内的历史n天的行为数据，通过算法在测试集上预测出这些用户对于不同视频内容的互动行为（包括点赞、点击头像、收藏、转发等）的发生概率。 本次比赛以多个行为预测结果的加权uAUC值进行评分。 比赛提供训练集用于训练模型，测试集用于评估模型效果，提交结果demo文件用于展示提交结果的格式。 所有数据文件格式都是带表头的.csv格式，不同字段列之间用英文逗号分隔。初赛与复赛的数据分布一致，数据规模不同。 初赛提供百万级训练数据，复赛提供千万级训练数据。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:1:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"Baseline 　主办方为本次比赛提供了一份基线:Wechat_Big_Data_Challenge_Baseline，该基线基于Wide \u0026 Deep模型实现，除6列原始id特征和feed时长特征外，在id特征的基础上构造了一些统计特征。Weight_uAUC线下0.657003，线上0.607908。 官方提供的这份基线分为数据集生成、离线模型训练、离线模型评估、在线模型训练、生成线上提交结果几个步骤，流程比较复杂，且线上线下gap较大，达到了5个百分点（经验证是统计特征涉及时间穿越，删去此部分特征可以提高2-3个百，群里也有人在基线基础上调参也能得到线上0.65+的分数），故我并没有过多参考此份基线。 我所使用的是讨论区深度匹配树大佬所开源的基于MMoE的多任务学习模型，由于MMoE的多任务训练机制，训练速度相比四个任务逐个建模大大提升，可以迅速验证一些特征的有效性。线上分数约为0.635。 TensorFlow版：mmoe_tf，Pytorch版：mmoe_torch。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:2:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"统计特征 　基线中仅使用了6列id类特征，第一想法是在这六列id的基础上构建统计特征，由于数据带有时间序列的性质，提取特征时要注意时间穿越问题。我根据user、feed等多侧的历史行为，构建了点击、曝光、CTR等相关特征，这些特征在CTR类的比赛中非常常见，Kaggle、Github上也有非常多优秀的开源代码，故这部分特征的具体提取不再赘述。 但将此部分统计特征喂给nn时，nn几乎不收敛，loss波动极大，归一化后线上成绩也非常低，于是开始思考什么样的特征适合喂给nn，开始下一阶段的特征构建。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:3:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"512维多模态向量 　这部分特征的正确使用能够获得较大幅度的提升，我尝试了两种方法，第一种是直接merge到训练集上，不过直接merge极容易OOM（除非内存足够），第二种是给feedid的嵌入赋值权重，不过后者经过实验效果不佳，也可能是我使用的方式不对。我租用的服务器配置为2*P40 + 112G RAM，将512维多模态向量经过PCA降维到48维后并在训练集上送入nn进行训练，线上线下均有大幅度提升，仅加入多模态这部分embedding特征后，线上成绩可以直接突破0.65。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:4:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"tag、keyword：多值离散特征 　这部分特征的处理方式有很多，例如作为序列提取通过word2vec提取embedding，将每个离散取值当成词，整个tag/keyword列表当作句子，获取每个词的词向量后做pooling操作得到该部分的embedding，此处可参考序列问题必备特征工程——基于Word2Vec的文本向量，或者通过embedding_lookup，此处可参考推荐算法-4.多值离散特征的embedding解决方案。 该部分特征对分数的提升也能达到7-8个千，我的线上分数也达到了0.659。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:5:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"多种子融合 　由于tensorflow的内部机制，导致其无法完全固定随机种子，同特征同参数下训练结果有一定幅度波动，波动幅度大概有2-3个千，通过多次训练，取平均可以稳定结果，线上成绩有约2个千的小幅度提升。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:6:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"树模型 　我在0.664附近卡了近两周的时间，比赛中后期的时候，天才儿童在6.14的周周星分享中开源了一份线上成绩0.645的梯度提升决策树模型基线，当时队伍中仅我自己一人，仅靠单模进入复赛不太稳定，而且初赛由于数据采样的原因，树模型会比nn更有优势，故决定转手再做一个树模型。 树模型中主要构造了一些统计类特征，和前文提到的类似，主要包括曝光、转化、视频观看等情况的滑窗统计特征，以及包括曝光、偏好等全局信息统计特征（全局统计也能上分..Orz）。 我在此份基线的基础上添加了nn中使用的几个embedding特征，树模型单模单折分数做到0.655。和我此前0.664的nn仅5/5平均后，就能够有3个k的提升。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:7:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"基于embedding的衍生特征 　这时距离比赛结束还有一周的时间，我在群里找到了一个做nn的和一个做树模型的队有，单模分数都在0.664上下，我和另一个队友的sub简单融合后分数达到了0.670，提升较大，然后继续优化nn单模。 基于前面提取的多个embedding特征，我在此基础上又提取了一些衍生特征，方式包括滑窗pooling等，收益较大，简单衍生后就能提升3个千。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:8:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"初赛B榜 　B榜数据和A榜的user无重叠，分布一致，排行榜上普遍有3个k到6个k的下降，我们的B榜最终分数为0.67093。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:9:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"待解决的问题 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:10:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"部分feed冷启动 　简单观察数据可发现，第15天仍有2607个feed冷启动（未在user_action中出现），样本量为72758。 对于冷启动问题，目前的基本思路是做矩阵SVD分解，构建用户和商品的交互矩阵，对稀疏矩阵进行SVD分解，得到用户和商品的向量，将用户向量和商品向量作为特征拼接到用户和商品侧。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:10:1","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"模型结构 　比赛初期GDY郭大使用Transformer输入原始的id类特征轻松上到了0.65+，从后面周周星分享的一些思路也可以看出，模型结构的修改可以带来比较大的收益，例如参考DIN对用户的长短期兴趣进行表征等。 ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:10:2","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"参考代码 https://github.com/meurice996/WBDC2021_Solution ","date":"June 29, 2021","objectID":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/:11:0","tags":null,"title":"2021中国高校计算机大赛 微信大数据挑战赛","uri":"/2021%E4%B8%AD%E5%9B%BD%E9%AB%98%E6%A0%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A4%A7%E8%B5%9B%E5%BE%AE%E4%BF%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"本文就『Lending Club贷款数据转换与融合』、『行星数据分组与聚合』以及『德国能源数据时间序列分析』等案例对Pandas中的部分分析方法以及机器学习中部分算法进行总结。 ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:0:0","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"Lending Club贷款数据转换与融合 　该案例完整Jupyter Notebook可参考Lending Club贷款数据转换与融合。 ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:1:0","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"数据源 user = pd.read_csv(\"./input/user.csv\") loan = pd.read_csv(\"./input/loan.csv\") history = pd.read_csv(\"./input/history.csv\") ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:1:1","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"随机采样(sample) 　随机查看贷款交易数据中的5行。 loan.sample(n=5) 　随机查看贷款交易数据中的1%。 loan.sample(frac=0.01) 　sample默认的是不放回采样（每个样本只可能出现一次），可以调整replace参数为True改为有放回采样。 loan.sample(n=10,replace=True) 　若希望重复调用某次采样的结果，可以设定random_state参数为同一个数来实现。 loan.sample(n=5,random_state=42) 　除了行采样，sample也可以实现列采样，只需要调整axis参数为1即可。 loan.sample(n=3,axis=1) ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:1:2","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"数据融合(merge,join) test_user = user.loc[[1,3,5,7,8]] test_loan = loan[loan.user.isin([2,3,4,5,6,7])] 　merge和join作为Pandas中常用的数据融合方法，目的都是将两个数据表通过共同变量进行连接。 merge 　merge参数如下： left.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), indicator=False) 　left和right分别指代要进行连接的两个数据框。 on, left_on, right_on, 用来指定连接的变量。若这一变量在两个数据框中命名相同，直接使用on指定即可，否则通过left_on和right_on分别指定左表变量名和右表变量名。 若需要基于数据框的索引进行连接，则要通过设定left_index和right_index的参数为True来实现。 how为连接方式，有’inner’, ’left’, ‘right’, ‘outer’四种。 　基于用户信息数据的’user_id’变量和贷款交易数据的’user’变量进行内连接(inner)。这种方式下，只有所选定列在左表与右表能匹配的行会被保留。 test_user.merge(test_loan,how=\"inner\", left_on=\"user_id\",right_on=\"user\") 　基于用户信息数据的’user_id’变量和贷款交易数据的’user’变量进行左连接(left)。这种方式下，左表所有行都被保留，不能匹配的部分用缺失值填充。 test_user.merge(test_loan,how=\"left\", left_on=\"user_id\",right_on=\"user\") 　基于用户信息数据的’user_id’变量和贷款交易数据的’user’变量进行右连接(right)。这种方式下，右表所有行都被保留，不能匹配的部分用缺失值填充。 test_user.merge(test_loan,how=\"right\", left_on=\"user_id\",right_on=\"user\") 　基于用户信息数据的’user_id’变量和贷款交易数据的’user’变量进行外连接(outer)。这种方式下，左表和右表所有行都会被保留，不能匹配的部分用缺失值填充。 test_user.merge(test_loan,how=\"outer\", left_on=\"user_id\",right_on=\"user\") 　merge中的indicator参数能很好地找到返回结果的来源,设定indicator参数为Ture后，返回结果中多了一列\"_merge\"，取值有\"both\", “left_only”, “right_only\"三种。分别代表左右表匹配成功，左表有而右表没有，右表有而左表没有三种情况。 $$ \\begin{array}{c|c|c} \u0026 .. \u0026 _merge \\ \\hline 0 \u0026 .. \u0026 both \\ \\hline 1 \u0026 .. \u0026 left_only \\ \\hline 2 \u0026 .. \u0026 right_only \\end{array} $$ 　当左表与右表中变量同名时，我们可以通过suffixes参数为左表变量与右表变量附加不同字段，便于后续区分。 $$ \\begin{array}{c|c|c|c|c|c|c|c} \u0026 user \u0026 term_l \u0026 grade_l \u0026 .. \u0026 term_r \u0026 grade_r \u0026 .. \\ \\hline 0 \u0026 6 \u0026 60 months \u0026 .. \u0026 .. \u0026 60 months \u0026 .. \u0026 .. \\ \\hline .. \u0026 .. \u0026 .. \u0026 .. \u0026 .. \u0026 .. \u0026 .. \u0026 .. \\end{array} $$ join 　join参数如下： left.join(right, on=None, how='left', lsuffix='', rsuffix='', sort=False) 　事实上，join就是merge的简化版本，所有join能实现的操作，都可以使用merge实现。 使用join时，右表只能基于索引进行连接； 通过on参数，可以指定左表进行连接的变量（可以是索引也可以是任意列）。 　merge和join中还有一个参数sort，指定为True会让返回的结果按连接变量进行升序排列。 ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:1:3","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"排序(sort_index,sort_values) 　Pandas中的sort_index和sort_values也可以对DataFrame进行排序，sort_index是按照索引进行排序，sort_values是按照指定变量排序。 例如想将用户历史数据按账户平均存款排序。 history.sort_values(by='avg_cur_bal') 　若要降序排列，可以指定ascending参数为False。 history.sort_values(by='avg_cur_bal', ascending=False) 　也可以指定对缺失值的排序方式，默认缺失值将排在最后，可以设定na_position为first将缺失值排在最前面。 history.sort_values(by='avg_cur_bal', na_position='first') ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:1:4","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"离散化(cut,qcut) cut 　使用cut函数按照指定的分割点对数据进行划分。 通过设定bin参数设定了分割点，将数据按照中位数进行了划分。同时设定了参数labels，使用这个参数可以方便地为新的划分区间命名。 左开右闭区间 annual_inc = pd.cut(combine.annual_inc, bins=[np.min(combine.annual_inc)-1, np.percentile(combine.annual_inc,50), np.max(combine.annual_inc)+1], labels=['low','high']) 　cut也可以直接指定划分份数，将数据等距划分。 例如，将数据等距分为五份： pd.cut(combine.annual_inc,5) 　理论上，数据应被等距分为了五份，每一个区间的长度都相同，但我们计算可以发现，第一个区间的长度为113364，而其他几个区间的长度都为112800。这并不是cut分割错误，只是为了包含最小值或最大值，cut的左右端会拓展0.1%。 qcut 　Pandas中与cut相似的另一个函数是qcut，它将按照每个区间中频数相同的原则进行划分,当我们指定划分份数后，就会用相应的分位数进行划分。例如，当我们使用qcut将数据分为两份时，分割点就是中位数，四份时分割点就是四分位数。 pd.qcut(combine.annual_inc,2) ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:1:5","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"值替换(replace,map) 　认为状态为\"Charged Off”,“In Grace Period”, “Late (31-120 days)“的贷款有违约风险，视为不良贷款，将其值标记为1，其他贷款标记为0。 使用replace进行值替换。 combine['loan_status'].replace( to_replace=['Fully Paid','Current','Charged Off','In Grace Period','Late (31-120 days)'], value=[0,0,1,1,1], inplace=True) 　除了将需要替换的值与替换的新值分别用列表输入外，也可以使用字典进行指定。 test_loan.replace(to_replace={'loan_status':{'Fully Paid':0,'Charged Off':0,'In Grace Period':1}}) 　也可以同时指定不同变量的不同值替换为相同新值。 test_loan.replace(to_replace={'loan_status':'Fully Paid','grade':'A'},value='Good') 　也可以指定正则表达式进行替换，这时需要设定参数regex为True，代表to_replace部分输入的是正则表达式。如查找所有以C开头的字段并替换为Bad。 test_loan.replace(to_replace='C+.*$', value='Bad', regex=True) map 　在Pandas中，如果只是针对某一个Series进行数值替代，我们也可以使用map方法。 test_loan['loan_status'].map({'Fully Paid':0,'Charged Off':0,'In Grace Period':1}) 　这同样实现了将贷款状态进行替换的效果，但map不能像replace一样直接对DataFrame进行操作。不过map不仅仅可以像上面一样输入字典作为参数，也可以直接输入一个函数进行映射。 例如，将数据中利率低于12%的映射为’Low’，高于12%的映射为’High’。 def f(x): if x \u003c 12: return 'Low' else: return 'High' combine['int_rate'].map(f) ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:1:6","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"哑变量处理(get_dummies) cat_vars=['term','grade','emp_length','annual_inc','home_ownership','verification_status'] for var in cat_vars: cat_list = pd.get_dummies(combine[var], prefix=var, drop_first=True) combine=combine.join(cat_list) 　get_dummies函数中使用了两个参数。prefix可以为新生成的哑变量添加前缀，这方便我们识别新生成的变量是从原来哪一个变量中得来的。drop_first设置为True将删去所获得哑变量的第一个，这是因为在建模中，有k类的分类变量只需要k-1个变量就可以将其描述，如果使用k个变量则会出现完全共线性的问题。 此外，在这里选择了使用join而不是merge，这是因为get_dummies返回的结果与原始数据有相同的索引，使用join直接基于索引进行连接更简洁。 pd.get_dummies(combine['grade'], prefix='grade',drop_first=True)[:5] $$ \\begin{array}{c|c|c} \u0026grade_B\u0026 grade_C\u0026 grade_D\u0026 grade_E\u0026 grade_F\u0026 grade_G\\ \\hline 0\u0026 0\u0026 0\u0026 1\u0026 0\u0026 0\u0026 0\u0026 \\ \\hline 1\u0026 0\u0026 1\u0026 0\u0026 0\u0026 0\u0026 0\u0026 \\ \\hline 2\u0026 1\u0026 0\u0026 0\u0026 0\u0026 0\u0026 0\u0026 \\ \\hline 3\u0026 0\u0026 0\u0026 0\u0026 0\u0026 0\u0026 0\u0026\\ \\hline 4\u0026 0\u0026 1\u0026 0\u0026 0\u0026 0\u0026 0\u0026 \\end{array} $$ 　如果使用merge： combine=combine.merge(cat_list,left_index=True,right_index=True) ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:1:7","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"添加常数项列(concat) 　在回归分析中，我们往往还需要为自变量添加常数项列，值全为1。 首先创建一个长度为X的行数，值全为1的列表。再将其转化为Series，并命名\"const”。 const = pd.Series([1] * combine.shape[0],name=\"const\") 　重设X索引，使用concat对数据进行合并，并指定方向为列。 X.reset_index(drop=True,inplace=True) X = pd.concat([const,X],axis=1) 　这里之所以要先重新设置X的索引，是因为concat是基于索引进行拼接的。这么看来，对于列的拼接其实直接使用join就可以了，不过目前join只能作为DataFrame的方法，想拼接DataFrame和Series就必须把DataFrame写在前面： X.join(const) 　此外，concat更常用的是进行行的连接。concat参数如下： pandas.concat(objs, axis=0, join='outer') 　objs: Series,DataFrame等构成的list axis: 合并连接的方向，0是行，1是列 join：连接方式，“inner\"或者\"outer” 　可以看到，concat的对象必须是一个list。 　创建两个dataframe:df1,df2。 df1 = pd.DataFrame([['a','a', 1], ['b','b', 2]],columns=['letter','letter1','number']) $$ \\begin{array}{c|c|c|c} \u0026 letter \u0026 letter1 \u0026 number\\ \\hline 0 \u0026 a \u0026 a \u0026 1\\ \\hline 1 \u0026 b \u0026 b \u0026 2 \\end{array} $$ df2 = pd.DataFrame([['c','c', 3], ['d','d', 4]],columns=['letter','letter2','number']) $$ \\begin{array}{c|c|c|c} \u0026 letter \u0026 letter1 \u0026 number\\ \\hline 0 \u0026 c \u0026 c \u0026 3\\ \\hline 1 \u0026 d \u0026 d \u0026 4 \\end{array} $$ 　使用inner方式进行连接，只有能够匹配的变量才会保留。 pd.concat([df1,df2],axis=0,join='inner') $$ \\begin{array}{c|c|c} \u0026 letter \u0026 number \\ \\hline 0 \u0026 a \u0026 1 \\ \\hline 1 \u0026 b \u0026 2 \\ \\hline 0 \u0026 c \u0026 3 \\ \\hline 1 \u0026 d \u0026 4 \\end{array} $$ 使用outer方式进行连接，所有变量都会保留，不能匹配的部分用缺失值填充。 pd.concat([df1,df2],axis=0,join='outer') $$ \\begin{array}{c|c|c} \u0026 letter \u0026 letter1 \u0026 letter2 \u0026 number \\ \\hline 0 \u0026 a\u0026 a\u0026 NaN\u0026 1 \\ \\hline 1\u0026 b\u0026 b\u0026 NaN\u0026 2 \\ \\hline 0\u0026 c\u0026 NaN\u0026 c\u0026 3 \\ \\hline 1\u0026 d\u0026 NaN\u0026d 4\u0026 \\end{array} $$ 　ignore_index参数为Ture将忽略原来的索引，从0开始重建索引。 pd.concat([df1,df2],ignore_index=True) 　通过key参数可以建立多层索引，方便识别数据来自于哪个数据源。 pd.concat([df1,df2],keys=['df1', 'df2']) $$ \\begin{array}{c|c|c|c|c|c} \u0026 \u0026 letter \u0026 letter1 \u0026 letter2\u0026 number \\ \\hline df1 \u0026 0 \u0026 a \u0026 a \u0026 NaN \u0026 1 \\ \u0026 1 \u0026 b \u0026 b \u0026 NaN \u0026 2 \\ \\hline df2 \u0026 0 \u0026 c \u0026 NaN \u0026 c \u0026 3 \\ \u0026 1 \u0026 d \u0026 NaN \u0026 d \u0026 4 \\ \\end{array} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:1:8","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"行星数据分组与聚合 　该案例完整Jupyter Notebook可参考行星数据分组与聚合。 ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:2:0","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"数据源 　行星数据集记录了2014年之前发现的行星的信息。 planets = pd.read_csv(\"./input/planets.csv\") $$ \\begin{array}{c|c|c|c|c|c|c} \u0026 method\u0026number\u0026orbital_period\u0026mass\u0026distance\u0026year \\ \\hline 0\u0026 Radial Velocity \u00261\u0026 269.300 \u00267.10 \u002677.40 \u00262006 \\ \\hline 1\u0026 Radial Velocity \u00261\u0026 874.774 \u00262.21 \u002656.95 \u00262008 \\ \\hline 2\u0026 Radial Velocity \u00261\u0026 763.000 \u00262.60 \u002619.84 \u00262011 \\ \\hline 3\u0026 Radial Velocity \u00261\u0026 326.030 \u002619.40 \u0026110.62 \u00262007 \\ \\hline 4\u0026 Radial Velocity \u00261\u0026 516.220 \u002610.50 \u0026119.47 \u00262009 \\end{array} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:2:1","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"数据分组 通过特征分组 　groupby可以指定某一个特征或指定某一组特征进行分组。 例如按method特征对数据进行分组。 grouped = planets.groupby('method') Output: \u003cpandas.core.groupby.generic.DataFrameGroupBy object at 0x7f1d00504a58\u003e 　groupby还能通过指定一个与目标数据等长的array、list或Series进行分组。 例如，行星数据集共有1035条记录，生成一个长度为1035，前500都为0，后535都为1的array。 使用repeat，输入中第一部分指定了值，第二部分指定对应值的重复次数。我们将生成结果记为a。 a = np.repeat([0,1], [500, 535]) 　以其对原数据进行分组，并计算各特征的均值。 planets.groupby(a).mean() $$ \\begin{array}{c|c|c|c|c|c} \u0026number\u0026orbital_period\u0026mass\u0026distance\u0026year\\ \\hline 0\u0026 1.644000\u0026 1450.908401\u0026 2.580901\u0026 97.615625\u0026 2007.916000\u0026 \\ \\hline 1\u0026 1.917757\u0026 2526.729858\u0026 2.800112\u0026 507.660000\u0026 2010.149533\u0026 \\end{array} $$ 通过函数分组 　也可以通过函数进行分组。 例如，想将数据按发现年份在2000年前和2000年后进行分组。使用set_index设定year变量为数据的新索引，然后定义一个函数test，当数据小于2000时返回’Before 2000’，大于等于2000时返回’After 2000’，最后通过自定义函数test进行分组，并求各组各变量均值。 new = planets.set_index('year') def test(x): if x\u003c2000: return 'Before 2000' else: return 'After 2000' new.groupby(test).mean() $$ \\begin{array}{c|c|c|c|c} \u0026 number\u0026 orbital_period\u0026 mass\u0026 distance\\ \\hline After 2000\u0026 1.780658\u0026 2058.025770\u0026 2.615027\u0026 272.918742\u0026\\ \\hline Before 2000\u0026 1.937500\u0026 349.672379\u0026 3.071469\u0026 26.354483\u0026 \\end{array} $$ 函数的输入是数据的索引列。以上代码相当于这样两步操作： 1. 对目标数据索引的每一个元素执行相应函数； group_index = new.index.map(test) Output: Index(['After 2000', 'After 2000', 'After 2000', 'After 2000', 'After 2000', 'After 2000', 'After 2000', 'Before 2000', 'After 2000', 'After 2000', ... 'After 2000', 'After 2000', 'After 2000', 'After 2000', 'After 2000', 'After 2000', 'After 2000', 'After 2000', 'After 2000', 'After 2000'], dtype='object', name='year', length=1035) 　2. 以这一个新变量group_index进行分组。 new.groupby(group_index).mean() $$ \\begin{array}{c|c|c|c|c} \u0026 number\u0026 orbital_period\u0026 mass\u0026 distance\\ \\hline year \u0026 \u0026 \u0026 \u0026 \\ \\hline After 2000\u0026 1.780658\u0026 2058.025770\u0026 2.615027\u0026 272.918742\\ \\hline Before 2000\u0026 1.937500\u0026 349.672379\u0026 3.071469\u0026 26.354483 \\end{array} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:2:2","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"GroupBy对象的基本操作 对分组进行迭代 　groupby返回的结果是一个GroupBy类型的对象，可以使用循环查看其内部结构： pd.set_option('expand_frame_repr',False) for (name,group) in grouped: print(name) print(group.head(n=2),'\\n') 　GroupBy类型的对象是由各组组名与其对应的分组数据构成。这里只依据method一个特征进行了分组，若基于多个特征进行分组，则返回的GroupBy的组名会是一个多元元组。 for (name,group) in planets.groupby(['method','year']): print(name) 　GroupBy内部是由一个个DataFrame组成，可以在循环中对每组数据进行操作。 例如，对每组数据使用shape。为了使输出更美观，我们使用format指定了输出的字符串格式，第一个{0:30s}匹配format中第一个字符串method，并指定字符串长度为30；第二个{1}匹配format中第二个字符串group.shape。 for (method, group) in planets.groupby('method'): print(\"{0:30s} shape={1}\".format(method, group.shape)) Output: Astrometry shape=(2, 6) Eclipse Timing Variations shape=(9, 6) Imaging shape=(38, 6) Microlensing shape=(23, 6) Orbital Brightness Modulation shape=(3, 6) Pulsar Timing shape=(5, 6) Pulsation Timing Variations shape=(1, 6) Radial Velocity shape=(553, 6) Transit shape=(397, 6) Transit Timing Variations shape=(4, 6) 　也有一些可以直接对GroupBy使用的方法，例如size方法可以查看每个分组的数据量。 grouped.size() Output: method Astrometry 2 Eclipse Timing Variations 9 Imaging 38 Microlensing 23 Orbital Brightness Modulation 3 Pulsar Timing 5 Pulsation Timing Variations 1 Radial Velocity 553 Transit 397 Transit Timing Variations 4 dtype: int64 选择指定特征分析 　针对GroupBy类型的对象，我们可以直接选取出需要的列。例如，取出year特征。 grouped['year'] 　这仍然是一个GroupBy类型的对象，但和之前的结果相比，这是一个SeriesGroupBy，而之前的是一个DataFrameGroupBy。 对于这种类型，可以直接使用一些聚合函数（如sum、mean、max、min…）。例如，查看不同方法发现的行星与地球距离的中位数： planets.groupby('method')['distance'].median() 　也可以直接使用describe。例如查看不同方法发现行星的时间情况。 grouped['year'].describe() $$ \\begin{array}{c|c|c|c|c|c} \u0026 count \u0026 mean \u0026 std \u0026 min \u0026 25% \u0026 50% \u0026 75% \u0026 max \\ \\hline method\\ \\hline Astrometry \u00262.0\u00262011.500000\u00262.121320\u00262010.0\u00262010.75\u00262011.5\u00262012.25\u00262013.0\\ \\hline … \\end{array} $$ 结合分组方法与聚合函数分析 　首先将年份按每10年进行划分。通过//将年份整除10（向下取整），再乘以10，可以将年份变换为对应年代。再使用astype将类型转换为字符串并加上’s’代表对应年代。 decade = 10 * (planets['year'] // 10) decade = decade.astype(str) + 's' 　按发现行星的方法和发现的年代进行分组，并统计相应分组下发现的行星的总数。 planets.groupby(['method', decade])['number'].sum() Output: method year Astrometry 2010s 2 Eclipse Timing Variations 2000s 5 2010s 10 Imaging 2000s 29 2010s 21 ... 　使用unstack将按层次化索引拆开为新的列索引。 planets.groupby(['method', decade])['number'].sum().unstack() $$ \\begin{array}{c|c|c|c|c} year\u00261980s\u00261990s\u00262000s\u00262010s \\ \\hline method \\ \\hline Astrometry\u0026NaN\u0026NaN\u0026NaN\u00262.0 \\ \\hline Eclipse Timing Variations\u0026NaN\u0026NaN\u00265.0\u002610.0\\ \\hline … \\end{array} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:2:3","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"GroupBy.apply 　apply方法能够分别对每一份分组数据进行对应的函数操作，再合并成一个数据表。因此，apply中使用的函数必须是以DataFrame作为输入的，而且每一个apply语句只能传入一个函数。 例如：使用apply计算不同方法发现的行星在各特征上的极差(最大值与最小值之差)。 grouped.apply(lambda x: x.max() - x.min()) $$ \\begin{array}{c|c|c|c|c|c} \u0026number\u0026orbital_period\u0026mass\u0026distance\u0026year\\ \\hline method \\ \\hline Astrometry\u0026 0.0\u0026769.640000\u0026NaN\u00265.79 \u00263.0 \\ \\hline Eclipse Timing Variations\u00261.0\u00268303.750000\u00261.8500\u0026369.28 \u00264.0 \\ \\hline … \\end{array} $$ 　此例中，每一组数据返回了一个Series。apply应用的函数也可以只返回一个标量，例如计算每种方法发现的行星中和地球距离的最大值与轨道周期的最大值之比。 Output: method Astrometry 0.020443 Eclipse Timing Variations 0.048924 Imaging 0.000226 Microlensing 1.513725 Orbital Brightness Modulation 763.789269 Pulsar Timing 0.032854 Pulsation Timing Variations NaN Radial Velocity 0.020418 Transit 25.633248 Transit Timing Variations 13.243750 dtype: float64 　apply应用的函数也可以返回一个DataFrame。例如分组中心化数据。 grouped.apply(lambda x: x-x.mean()) $$ \\begin{array}{c|c|c|c|c|c|c} \u0026distance\u0026 mass\u0026 method\u0026 number\u0026 orbital_period\u0026 year\\ \\hline 0\u0026 25.799792\u0026 4.469301\u0026 NaN\u0026 -0.721519\u0026 -554.05468\u0026 -1.518987\\ \\hline 1\u0026 5.349792\u0026 -0.420699\u0026 NaN\u0026 -0.721519\u0026 51.41932\u0026 0.481013\\ \\hline … \\end{array} $$ 　当apply中运用的函数除了输入的DataFrame外还有其他参数时，直接在apply中进行赋值即可。例如查看按method分组后各组数据的前两行。 def func1(x,n): return(x.head(n)) grouped.apply(func1,n=2) 　apply的运行实际过程有分开运算、结果合并两步，因此，在数据量较大时，apply的运行速度会比可以实现同样操作的其他方法要慢。 %timeit grouped.apply(np.mean) 16.1 ms ± 50.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) %timeit grouped.mean() 624 µs ± 337 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each) 　总结来看，apply方法只需要传入的函数的输入为DataFrame即可，函数的输出可以是标量、Series或DataFrame。但必须以DataFrame为输入就会导致当我们想对不同特征分别进行操作时比较麻烦。例如，分别计算各种方法发现的行星的距离的均值和发现的数量之和。 def func2(df): mean_distance = np.mean(df['distance']) sum_number = np.sum(df['number']) return(pd.Series({'mean_distance':mean_distance,'sum_number':sum_number})) grouped.apply(func2) ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:2:4","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"GroupBy.agg 　同样，分别计算各种方法发现的行星的距离的均值和发现的数量之和。 grouped.agg({'distance':'mean','number':'sum'}) 　这里使用“变量名:函数名”的形式向agg传入一个字典。agg方法可以针对某个特征同时执行多个函数。 grouped.agg({'distance':['min','max','mean','median'],'number':'sum'}) 　agg方法中同样可以使用自定义函数，例如求极差： grouped.agg(lambda x: x.max()-x.min()) 　需要注意，尽管这里使用agg和apply获得了相同的结果，但是，在apply中是对每一组数据整个DataFrame进行一次运算，而在agg中将对每一组数据中的每一个特征进行运算。 def test2(x): return(x.shape) grouped.apply(test2) Output: method Astrometry (2, 6) Eclipse Timing Variations (9, 6) Imaging (38, 6) Microlensing (23, 6) Orbital Brightness Modulation (3, 6) Pulsar Timing (5, 6) Pulsation Timing Variations (1, 6) Radial Velocity (553, 6) Transit (397, 6) Transit Timing Variations (4, 6) dtype: object grouped.agg(test2) $$ \\begin{array}{c|c|c|c|c|c|c} \u0026 number\u0026 orbital_period \u0026 mass \u0026 distance \u0026 year \\ \\hline method \\ \\hline Astrometry\u0026 (2,)\u0026 (2,)\u0026 (2,)\u0026 (2,)\u0026 (2,)\\ \\hline Eclipse Timing Variations\u0026 (9,)\u0026 (9,)\u0026 (9,)\u0026 (9,)\u0026 (9,)\\ \\hline … \\end{array} $$ 可以看到，apply返回的是每一组数据的维度，而agg返回的是每组数据下，每一个特征对应的数据的维度。因此，我们可以将agg的操作分为3步： 1. 对每组数据中的每一列执行函数; 2. 将每一列返回结果合并; 3. 将每一组数据返回结果合并 %timeit grouped.apply(lambda x: x.max()-x.min()) 32.2 ms ± 28.9 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) %timeit grouped.agg(lambda x:x.max()-x.min()) 19.6 ms ± 7.73 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) 　因此，尽管相比于apply，agg可以从更细的维度进行数据处理，但也意味着更多的运算消耗。同时，agg方法对使用的函数的返回也有一定要求：对每一个特征，函数只能返回一个标量。例如，使用apply进行中心化的操作无法使用agg完成。 grouped.agg(lambda x: x-x.mean()) Output: ValueError: Shape of passed values is (6, 10), indices imply (5, 10) ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:2:5","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"GroupBy.transform 　transform方法中传入的函数只能返回两种结果，可以广播的标量值或者与分组数据维度相同的数据。 对分组数据求均值，然后把这个均值赋值给整个组（可广播的标量值）。 $$ \\begin{array}{c|c|c|c|c|c} \u0026 number\u0026 orbital_period\u0026 mass\u0026 distance\u0026 year \\ \\hline 0\u0026 1.721519\u0026 823.35468\u0026 2.630699\u0026 51.600208\u0026 2007.518987\\ \\hline 1\u0026 1.721519\u0026 823.35468\u0026 2.630699\u0026 51.600208\u0026 2007.518987\\ \\hline … \\end{array} $$ 　使用transform实现分组数据标准化($\\dfrac{x-\\bar{x}}{s}$)(分组数据维度相同的数据): grouped.transform(lambda x: (x - x.mean()) / x.std()) 　apply中自定义函数对每个分组数据单独进行处理，再将结果合并；整个DataFrame的函数输出可以是标量、Series或DataFrame；每个apply语句只能传入一个函数； agg可以通过字典方式指定特征进行不同的函数操作，每一特征的函数输出必须为标量； transform不可以通过字典方式指定特征进行不同的函数操作，但函数运算单位也是DataFrame的每一特征，每一特征的函数输出可以是标量或者Series，但标量会被广播。 ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:2:6","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"德国能源数据时间序列分析 　该案例完整Jupyter Notebook可参考德国能源数据时间序列分析。 ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:3:0","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"数据源 　数据的字段及其说明如下： $$ \\begin{array}{c|c} 变量名称\u0026含义说明 \\ \\hline Date\u0026日期 \\ \\hline Consumption\u0026电力消耗 \\ \\hline Wind\u0026风能发电量 \\ \\hline Solar\u0026太阳能发电量 \\end{array} $$ 　使用dtypes查看数据类型。 opsd.dtypes Output: Date datetime64[ns] Consumption float64 Wind float64 Solar float64 Wind+Solar float64 dtype: object 　使用set_index将Date变量设定为索引。 opsd.set_index('Date',inplace=True) 　也可以在数据导入时通过参数设置实现这些操作。设定index_col为0即以数据中第一列为索引，设定parse_dates为True，会把索引识别为时间数据类型。 opsd = pd.read_csv('./input/opsd_germany_daily.csv', index_col=0, parse_dates=True) 　查看此时索引格式。 opsd.index Output: DatetimeIndex(['2006-01-01', '2006-01-02', '2006-01-03', '2006-01-04', '2006-01-05', '2006-01-06', '2006-01-07', '2006-01-08', '2006-01-09', '2006-01-10', ... '2017-12-22', '2017-12-23', '2017-12-24', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-30', '2017-12-31'], dtype='datetime64[ns]', name='Date', length=4383, freq=None) 　可以使用asfreq进行指定。如果数据中缺失了某个时间，asfreq将自动为这些时间添加新行，并默认分配空值。 opsd = opsd.asfreq('D') Output: DatetimeIndex(['2006-01-01', '2006-01-02', '2006-01-03', '2006-01-04', '2006-01-05', '2006-01-06', '2006-01-07', '2006-01-08', '2006-01-09', '2006-01-10', ... '2017-12-22', '2017-12-23', '2017-12-24', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-30', '2017-12-31'], dtype='datetime64[ns]', name='Date', length=4383, freq='D') ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:3:1","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"基于时间索引筛选数据 　对于时间数据索引，可以使用loc提取数据。例如，查找2017年8月10日的数据。 opsd.loc['2017-08-10'] 　也可以选择一段时间，例如2014年1月20日至2014年1月22日的数据。与使用loc的常规索引一样，切片将包含两个端点。 opsd.loc['2014-01-20':'2014-01-22'] 　可以不具体到日，而仅仅指定对应的年和月，将返回当月的所有数据。例如，查找2017年1月份的数据。 opsd.loc['2017-01'] 　获取时间范围内的数据也可以使用truncate进行筛选。before将删去给定日期之前的数据，after将删去给定日期之后的数据。例如，筛选2017年1月份的数据。 opsd.truncate(before='2017-01-01',after='2017-01-31') ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:3:2","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"时间数据基本操作 　针对时间数据，可以使用year，month，weekday等多种方法获取对应时间的年份、月份和星期。 首先使用index提取数据的索引。 opsdtime = opsd.index Output: DatetimeIndex(['2006-01-01', '2006-01-02', '2006-01-03', '2006-01-04', '2006-01-05', '2006-01-06', '2006-01-07', '2006-01-08', '2006-01-09', '2006-01-10', ... '2017-12-22', '2017-12-23', '2017-12-24', '2017-12-25', '2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2017-12-30', '2017-12-31'], dtype='datetime64[ns]', name='Date', length=4383, freq='D') 　使用year提取每个数据对应的年份。 opsdtime.year Output: Int64Index([2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, ... 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017], dtype='int64', name='Date', length=4383) 　使用month提取月份。 opsdtime.month Output: Int64Index([ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 12, 12, 12, 12, 12, 12, 12, 12, 12, 12], dtype='int64', name='Date', length=4383) 　month返回的是对应月份的数字，若想要获得月份的名字可以使用month_name。 opsdtime.month_name() Output: Index(['January', 'January', 'January', 'January', 'January', 'January', 'January', 'January', 'January', 'January', ... 'December', 'December', 'December', 'December', 'December', 'December', 'December', 'December', 'December', 'December'], dtype='object', name='Date', length=4383) 　可以使用weekday和weekday_name（新版本API已修改为day_name()）查看日期是星期几。 opsdtime.weekday Output: Int64Index([6, 0, 1, 2, 3, 4, 5, 6, 0, 1, ... 4, 5, 6, 0, 1, 2, 3, 4, 5, 6], dtype='int64', name='Date', length=4383) opsdtime.weekday_name # opsdtime.day_name() Output: Index(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', ... 'Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], dtype='object', name='Date', length=4383) 　构建月份与对应季节间的映射字典。 seasons = [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1] month_to_season = dict(zip(range(1,13), seasons)) opsdtime.month.map(month_to_season) Output: {1: 1, 2: 1, 3: 2, 4: 2, 5: 2, 6: 3, 7: 3, 8: 3, 9: 4, 10: 4, 11: 4, 12: 1} Int64Index([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype='int64', name='Date', length=4383) ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:3:3","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"周期性分析 重采样分析周期性 　使用plot查看数据整体情况，电力消耗总量： opsd['Consumption'].plot(figsize=(12,6)) 　具体查看2007年的数据。 opsd.loc['2007','Consumption'].plot(figsize=(12,6)) 　使用groupby按变量season分组，并计算每个季节的用电量均值。 opsd.groupby('season')['Consumption'].mean().plot() 　使用groupby进行重采样，将数据按是星期几进行分组，并计算每组的用电量均值。这里使用lambda函数传入weekday进行分组。 opsd.groupby(lambda x:x.weekday)['Consumption'].mean().plot() 　使用resample对风能发电数据进行降采样。按每个月重采样，并计算每月的均值。 wind = opsd['Wind'].resample('M').mean() wind.plot(figsize=(12,6)) 　数据差分分析周期性 　在分析周期性的过程中，很重要的一点就是要消除数据的趋势性，常见的消除数据趋势的方法就是差分：计算连续数据点间的差异（这里特指一阶差分）。例如，t时刻的差分值：$\\Delta d_t=d_t - d_{t-1}$。可以使用diff方法实现差分操作。 例如，计算太阳能发电的差分序列并绘图： opsd['Solar'].diff().plot(figsize=(12,6)) 　也可以通过移动时间序列自行计算差分值。 移动序列可以使用shift方法。shift方法可以沿着时间轴将数据前移或后移，保持索引不变。 opsd['Solar'].tail() Output: Date 2017-12-27 16.530 2017-12-28 14.162 2017-12-29 29.854 2017-12-30 7.467 2017-12-31 19.980 Freq: D, Name: Solar, dtype: float64 opsd['Solar'].shift(1).tail() Output: Date 2017-12-27 30.923 2017-12-28 16.530 2017-12-29 14.162 2017-12-30 29.854 2017-12-31 7.467 Freq: D, Name: Solar, dtype: float64 　两个序列相减即可得到原始数据的一阶差分序列。 dif = opsd['Solar']-opsd['Solar'].shift(1) dif.plot(figsize=(12,6)) 　也可以通过设定shift方法中的参数freq移动索引而数据保持不变，例如指定时间移动一天。 opsd['Solar'].shift(1,freq='d').tail() Output: Date 2017-12-28 16.530 2017-12-29 14.162 2017-12-30 29.854 2017-12-31 7.467 2018-01-01 19.980 Freq: D, Name: Solar, dtype: float64 ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:3:4","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"滚动窗口 　与降采样类似，滚动窗口将数据拆分为时间窗口，并且对每个窗口中的数据使用诸如mean，median等函数进行聚合。但是，与降采样不同，滚动窗口以与数据相同的频率重叠和“滚动”，因此变换的时间序列与原始时间序列的频率相同。 例如，设定窗口为7天，且以数据中心为基准点，则每一个数据对应的窗口将包含前面三天与后面三天。具体来看，2017-07-06对应的窗口就是2017-07-03到2017-07-09。 opsd['Wind'].rolling(7).mean().plot(figsize=(12,6)) 　 opsd['Wind'].rolling(30).mean().plot(figsize=(12,6)) 　当窗口范围中存在缺失值时，窗口将会返回为缺失值，可以设定min_periods为360，只需要对应窗口中有360个以上数据就可以，这样可以容忍一小部分的缺失数据。 opsd['Wind'].rolling(window=365,min_periods=360).mean().plot(figsize=(12,6)) 　","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:3:5","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"K-means clustering algorithm 　一个简单的算法伪代码描述如下： $$ \\begin{aligned} \\hline \u00261:\\ 选择K个点作为初始质心。\\ \u00262:\\ repeat \\ \u00263:\\ \\quad 将每个点指派到最近的质心，形成K个簇。\\ \u00264:\\ \\quad 重新计算每个簇的质心。\\ \u00265:\\ until 质心不发生变化。\\ \\hline \\end{aligned} $$ 相似度使用欧氏距离(Euclidean Distance)度量，给定两个样本$X=(x_1,x_2,…,x_n)$与$Y=(y_1,y_2,…,y_n)$，$X$和$Y$两个向量间的欧氏距离表示为： $$ \\begin{aligned} dist_{ed}(X,Y)=\\Vert X-Y \\Vert ^2=\\sqrt[2]{(x_1-y_1)^2+…+(x_n-y_n)^2} \\end{aligned} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:4:0","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"Python实现 　距离计算函数point_dist。 def point_dist(x,c): return np.linalg.norm(x-c) iterrows 遍历方式实现 def k_means(X,k): centers = X.sample(k).values #从数据集随机选择 K 个样本作为初始化的类中心，k 行 d 列 X_labels = np.zeros(len(X)) #样本的类别 error = 10e10 while(error \u003e 1e-6): for i,x in X.iterrows():#指派样本类标签 X_labels[i] = np.argmin([point_dist(x,centers[i,:]) for i in range(k)]) centers_pre = centers centers = X.groupby(X_labels).mean().values #更新样本均值，即类中心 error = np.linalg.norm(centers_pre - centers)#计算error return X_labels, centers apply 遍历方式实现 def k_means(X,k): #初始化 K 个中心，从原始数据中选择样本 centers = X.sample(k).values X_labels = np.zeros(len(X)) #样本的类别 error = 10e10 while(error \u003e 1e-6): X_labels = X.apply(lambda r : np.argmin([point_dist(r,centers[i,:]) for i in range(k)]),axis=1) centers_pre = centers centers = X.groupby(X_labels).mean().values #更新样本均值，即类中心 error = np.linalg.norm(centers_pre - centers)#计算error return X_labels, centers 矩阵运算方式实现 　数据集表示成 $n \\times d$ 矩阵 $\\mathbf{X}$，其中 $n$ 为样本数量，$d$ 为样本的维度。 $k$ 个聚类中心表示成 $k \\times d$ 矩阵 $\\mathbf{C}$，$\\mathbf{C}$ 每一行表示一个聚类中心。样本到 $k$ 个中心的距离表示成 $n \\times k$ 矩阵 $\\mathbf{D}$。 　已知聚类中心，计算样本到中心距离，并将样本划分到距离最小的类的流程如下图所示。 　　使用 Numpy 实现上述计算流程的代码为： for i in range(k): D[:,i] = np.sqrt(np.sum(np.square(X - C[i,:]),axis=1)) labels = np.argmin(D,axis=1) 　得到样本的类标签后，聚类中心的更新流程为：1）根据类标签对样本进行分组；2）将聚类中心更新为每一组样本的均值。Python 实现的代码为： C = X.groupby(labels).mean().values 　完整实现代码： def k_means(X,k): C = X.sample(k).values #从数据集随机选择 K 个样本作为初始化的类中心，k 行 d 列 X_labels = np.zeros(len(X)) #记录样本的类别 error = 10e10 #停止迭代的阈值 while(error \u003e 1e-6): D = np.zeros((len(X),k)) #样本到每一个中心的距离，n 行 k 列 for i in range(k): D[:,i] = np.sqrt(np.sum(np.square(X - C[i,:]),axis=1)) labels = np.argmin(D,axis=1) C_pre = C temp_C = X.groupby(labels).mean() #更新样本均值，即类中心 C = np.zeros((k,X.shape[1])) for i in temp_C.index: C[i,:] = temp_C.loc[i,:].values if C.shape == C_pre.shape: error = np.linalg.norm(C_pre - C)#计算error else: print(C.shape, C_pre.shape) return labels, C ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:4:1","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"Logistic regression ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:5:0","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"线性回归 $$ \\begin{aligned} h_\\theta(x)\u0026=\\theta^Tx \\ \u0026=\\sum_{i=0}^n{\\theta_i x_i} \\ \u0026=\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + … + \\theta_n x_n \\end{aligned} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:5:1","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"sigmoid $$ \\begin{aligned} g(z)=\\frac{1}{1+e^{-z}} \\end{aligned} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:5:2","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"逻辑回归公式 　线性回归公式带入Sigmoid即得： $$ \\begin{aligned} h_\\theta(x)=\\frac{1}{1+e^{-{\\theta^Tx}}} \\end{aligned} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:5:3","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"损失函数 　对数形式的似然函数如下： $$ \\begin{aligned} logL(\\theta)=\\sum_{i=1}^n{log(p(x_i;\\theta))} \\end{aligned} $$ 用sigmoid函数表示0-1中取1的概率，损失函数可以定义为： $$ \\begin{aligned} y\u0026=0时，Cost(h_\\theta(x),y)=-log(1-h_\\theta(x)) \\ y\u0026=1时，Cost(h_\\theta(x),y)=-log(h_\\theta(x)) \\end{aligned} $$ 损失函数的要求是预测结果与真实结果越相近，函数值越小，故在前面加上负号。取对数和上面提到的最大似然函数有关，不影响原函数的单调性，且会放大概率之间的差异，更好的区分各个样本的类别。 故逻辑回归的损失函数如下： $$ \\begin{aligned} J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^m{[y^{(i)}logh_\\theta(x^{(i)})+(1-y^{(i)})log(1-h_\\theta(x^{(i)}))]} \\end{aligned} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:5:4","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"梯度下降 　要求出最优参数$\\theta$，需要最小化$J(\\theta)$，更新参数： $$ \\begin{aligned} \\theta_j := \\theta_j-\\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} \\end{aligned} $$ sigmoid函数求导： $$ \\begin{aligned} \\frac{\\partial g(z)}{\\partial z}=g(z)(1-g(z)) \\end{aligned} $$ 对g(\\theta^Tx)求导： $$ \\begin{aligned} \\frac{\\partial g(\\theta^Tx)}{\\partial z}=g(\\theta^Tx)(1-g(\\theta^Tx))x_j^{(i)} \\end{aligned} $$ 损失函数求导： $$ \\begin{aligned} \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\u0026= …\\ \u0026=\\frac{1}{m}\\sum_{i}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\end{aligned} $$ 得到逻辑回归的梯度下降更新公式： $$ \\begin{aligned} \\theta_j := \\theta_j-\\alpha \\frac{1}{m}\\sum_{i}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\end{aligned} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:5:5","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"伪代码描述 $$ \\begin{aligned} \\hline \u00261:\\ 初始化回归系数。\\ \u00262:\\ repeat \\ \u00263:\\ \\quad 计算梯度\\frac{\\partial J(\\theta)}{\\partial \\theta}。\\ \u00264:\\ \\quad \\theta:=\\theta+\\alpha * \\frac{\\partial J(\\theta)}{\\partial \\theta}。\\ \u00265:\\ until 收敛 \\ or \\ max_loop。\\ \u00266:\\ return\\ \\theta \\ \\hline \\end{aligned} $$ ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:5:6","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"Python实现 class LR: def __init__(self, alpha=0.01, max_iter=100): self.alpha = alpha self.max_iter = max_iter def fit(self, X, y): X = np.mat(X) # (rows,cols) m, n = np.shape(X) y = np.mat(y).T # (rows,cols) self.weight = np.ones((n, 1)) for i in range(self.max_iter): h = self.sigmoid(X * self.weight) error = y - h self.weight = self.weight + self.alpha * X.T * error ```r ","date":"May 25, 2021","objectID":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/:5:7","tags":null,"title":"大数据处理技术复习要点总结","uri":"/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93-pandas/"},{"categories":null,"content":"时间序列回归赛题，一个简单的方案分享+指标MAPE翻车记录，B榜Rank53。magic number yyds~ ","date":"May 18, 2021","objectID":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/:0:0","tags":null,"title":"2021招商银行FinTech精英训练营 数据赛道","uri":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/"},{"categories":null,"content":"赛题任务 　本次竞赛给出的数据包含日期、节假日信息、时间段、岗位（含2种岗位A、B）、业务类型和业务量数据。 任务1：预测未来31天各岗位每天的业务量总量 任务2：预测未来31天各岗位每天每半小时粒度的业务总量 A榜：提供2018年1月1日到2020年10月31日的训练数据（train_v1），选手提交2020年11月1日到2020年11月30日的预测结果。 B榜：提供2018年1月1日到2020年11月30日的训练数据（train_v2），选手提交2020年12月1日到2020年12月31日的预测结果。 　本次比赛的线上评价指标为MAPE。 $$ \\begin{aligned} MAPE = \\frac{1}{N} \\sum_{i=1}^{N} \\left| \\frac{Y_i - \\hat{Y_i}}{Y_i + 1} \\right| \\times 100%\\ \\end{aligned} $$ ","date":"May 18, 2021","objectID":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/:1:0","tags":null,"title":"2021招商银行FinTech精英训练营 数据赛道","uri":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/"},{"categories":null,"content":"解决方案 ","date":"May 18, 2021","objectID":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/:2:0","tags":null,"title":"2021招商银行FinTech精英训练营 数据赛道","uri":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/"},{"categories":null,"content":"任务1 　简单观察数据可发现，A、B岗位业务量差距较大，故A、B岗位分开建模。 对于日业务量，我均采用LightGBM回归模型进行预测。 考虑到特殊时期对业务量的影响（特别是2020年上半年的Covid-19疫情），仅采用2018年3月1日至2018年11月30日的数据作为训练集，采用2018年12月1日至2018年12月30日的数据作为验证集（B榜，A榜划分类似，向前推一个月即可）。 特征工程方面，所做的工作并不太多，特征包括日期特征（day_of_week、day_of_month…）、节假日特征（节假日类型、距离下个工作日的天数、距离下个节假日的天数…）等。 后处理是本题上分的一个关键点。观察数据，可以大致推断出接近年底的业务量是一个逐渐升高的趋势，将模型所预测的结果拼接到原数据集后再对整体走势做可视化分析，可以对模型预测结果的合理性做出大致判断。最开始，我尝试对预测的所有结果都乘一个系数（大约1.25左右，具体根据训练集和使用的特征等的不同会有一定的差异），获得了比较大的收益，随后我又对这个系数更加细化，月上旬、中旬、下旬分别乘不同的系数（逐渐递增），也获得了一定的提升，继续细化这个粒度（按周、按日）应该还会有提升，不过我并没有做更多这方面的尝试。 PS：关于后处理还有一些比较不寻常的方法，比如老肥将每一条预测结果都加上大小为666的偏移量，同样取得了较好的线上分数… ","date":"May 18, 2021","objectID":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/:2:1","tags":null,"title":"2021招商银行FinTech精英训练营 数据赛道","uri":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/"},{"categories":null,"content":"任务2 　任务2同样采用LightGBM回归模型，训练数据与任务1相同，特征方面主要就增加了periods。由于与任务1相比，任务2的误差较大，所以我将任务2的训练从直接预测业务量改为了预测当前时间段的业务量占当天全部业务量的比例，利用到了任务1的预测结果来调整任务2，这样做还一个好处是，任务1、2基本是同增同减的状态。 ","date":"May 18, 2021","objectID":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/:2:2","tags":null,"title":"2021招商银行FinTech精英训练营 数据赛道","uri":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/"},{"categories":null,"content":"关于指标MAPE 　本次比赛中，我一开始就错误的将MAPE当作Lgb的metric，后面一直都忽略了这点，导致任务2的预测结果问题很大，特别是业务量较少（接近0）时，对指标的影响非常大。当我任务1优化到0.059时，任务2的MAPE仍为0.20，最终B榜也仅位于第53名，将metric调整为MSE即可。 当实际值为零时，MAPE会采用未定义的值，例如在需求预测中可能会发生这种情况。此外，当实际值非常接近零时，它将采用极值。 MAPE是不对称的，它对负误差（当预测值高于实际值时）要比对正误差施加更大的罚款。解释如下：对于过低的预测，百分比误差不能超过100％。虽然没有太高的预测上限。因此，MAPE将偏向于预测不足而不是过度预测的模型。 MAPE假定变量的度量单位具有有意义的零值。因此，尽管预测需求并使用MAPE是有意义的，但当预测温度以摄氏度（不仅是那个）表示时，却没有意义，因为温度具有任意零点。 MAPE并非到处都是可微的，在将其用作优化标准时可能会导致问题。 ","date":"May 18, 2021","objectID":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/:3:0","tags":null,"title":"2021招商银行FinTech精英训练营 数据赛道","uri":"/2021%E6%8B%9B%E5%95%86%E9%93%B6%E8%A1%8Cfintech%E7%B2%BE%E8%8B%B1%E8%AE%AD%E7%BB%83%E8%90%A5-%E6%95%B0%E6%8D%AE%E8%B5%9B%E9%81%93/"},{"categories":null,"content":"本文参考《计算机信息安全技术》（付永钢著）对计算机数据安全课程中的主要内容进行总结。 第1章 计算机信息安全技术概述 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:0:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"信息安全模型 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:1:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"通信安全模型 　通信一方通过公开信道将消息传送给另一方，要保护信息传输的机密性、真实性等特性，就涉及通信安全。通信的发送方要对信息进行相关的安全变换，可以是加密、签名，接收方接收后，再进行相关的逆变换，如解密、验证、签名等。双方进行的安全变换通常需要使用一些秘密信息，如加密密钥、解密密钥等。根据上述安全模型，设计安全服务需要完成以下4个基本任务。 （1）设计一个算法，执行安全相关的转换，算法应具有足够的安全强度。 （2）生成该算法所使用的秘密信息，也就是密钥。 （3）设计秘密信息的分布与共享的方法，也就是密钥的分配方案。 （4）设定通信双方使用的安全协议，该协议利用密码算法和密钥实现安全服务。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:1:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"信息访问安全模型 　还有一些与安全相关的情形不完全适用于上述模型，William Stallings给出了如图所示的信息访问安全模型。该模型希望保护信息系统不受有害的访问。有害的访问分为两种：一种有害的访问是由黑客发起的，他们有时并没有恶意，只是满足于闯入计算机系统，展示自己的技术水平或利用计算机技术进行获利；另一种有害的访问来源于恶意软件，如病毒、木马、蠕虫等。对付有害攻击所需要的安全服务包含鉴别和访问控制两类。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:1:2","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"动态安全模型 　PPDR模型由4个主要部分组成：安全策略（Policy）、防护（Protection）、检测（Detection）和响应（Response）。PPDR模型是在整体的安全策略的控制和指导下，综合运用防护工具（如防火墙、身份认证、加密等）的同时，利用检测工具（如漏洞评估、入侵检测系统）了解和评估系统的安全状态，通过适当的安全响应将系统调整到一个比较安全的状态。防护、检测和响应组成了一个完整的、动态的安全循环。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:1:3","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"APPDRR模型 　网络安全的动态特性在PPDR模型中得到了一定程度的体现，其中主要是通过入侵的检测和响应完成网络安全的动态防护。但PPDR模型不能描述网络安全的动态螺旋上升过程。为了使PPDR模型能够贴切地描述网络安全的本质规律，人们对PPDR模型进行了修正和补充，在此基础上提出了 APPDRR模型，如图1.5所示。APPDRR模型认为网络安全由风险评估（Assessment）、安全策略（Policy）、系统防护（Protection）、动态检测（Detection）、实时响应（Reaction）和灾难恢复（Restoration）6个部分组成。 第2章 密码技术 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:1:4","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"传统密码体制 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:2:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"代换密码 移位密码/凯撒密码 　设$P = C = Z_{26} $，对$ 0 ≤ k ≤ 25$，定义： $$ \\begin{aligned} e_k(x) \u0026= (x+k)\\ mod\\ 26 \\ d(y) \u0026= (y-k)\\ mod\\ 26 \\end{aligned} $$ 其中$ x,y ∈ Z_{26} $。 　凯撒(Caesar)密码是$ k=3 $的情况，即向右移动源字母表中的三个字母。 　eg. 若明文为：”please confirm receipt“，则密文为”SOHDVH FRQILUP UHFHLSW“。 　代换字母表如下所示。 $$ \\begin{array}{c|ccccccccccccc} \\searrow \u0026 A \u0026 B \u0026 C \u0026 D \u0026 E \u0026 F \u0026 G \u0026 H \u0026 I \u0026 J \u0026 K \u0026 L \u0026 M \\ \\hline \\ \u0026 D \u0026 E \u0026 F \u0026 G \u0026 H \u0026 I \u0026 J \u0026 K \u0026 L \u0026 M \u0026 N \u0026 O \u0026 P \\ \\hline \\searrow \u0026 N \u0026 O \u0026 P \u0026 Q \u0026 R \u0026 S \u0026 T \u0026 U \u0026 V \u0026 W \u0026 X \u0026 Y \u0026 Z \\ \\hline \\ \u0026 Q \u0026 R \u0026 S \u0026 T \u0026 U \u0026 V \u0026 W \u0026 X \u0026 Y \u0026 Z \u0026 A \u0026 B \u0026 C \\end{array} $$ 仿射密码 　设$ P=C=Z_{26} $，且$K={(a,b)∈Z_{26} × Z_{26} | gcd(a,26)=1}$，对$k=(a,b)∈K$ ，定义： $$ \\begin{aligned} e_k(x) \u0026= (ax+b)\\ mod\\ 26 \\ d_k(y) \u0026= a^{-1}(y-b)\\ mod\\ 26 \\end{aligned} $$ 其中$ (x,y) ∈ Z_{26} $。 　eg.假定$ k=(7,3),7^{-1}\\ mod\\ 26=15$，加密函数为$ e_k(x)=7x+3 $，则相应的解密函数为$ d_k(y)=$$15(y-3)=15y-19 $，其中所有的运算都是在$Z_{26}$中。容易验证，$d_k(e_k(x))=$ $d_k(7x+3)=$ $15(7x+3)-19=$ $x+45-19=x$。 　关于$a^{-1}$：$a$在$Z_m$群的乘法逆元，其值可通过费马小定理求出，以下给出仿射密码中$a$与$a^{-1}$的对应表。 $$ \\begin{array} {c|cccccccccccc} a \u0026 1 \u0026 3 \u0026 5 \u0026 7 \u0026 9 \u0026 11 \u0026 15 \u0026 17 \u0026 19 \u002621 \u0026 23 \u0026 25 \\ \\hline a^{-1} \u0026 1 \u0026 9 \u0026 21 \u0026 15 \u0026 3 \u0026 19 \u0026 7 \u0026 23 \u0026 11 \u0026 5 \u0026 17 \u002625 \\end{array} $$ ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:2:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"传统密码的分析 统计分析法 　通过对大量材料的汇编统计，获得26个字母的概率分布。 $$ \\begin{array} {cc|cc|cc|cc} 字母 \u0026 概率 \u0026 字母 \u0026 概率 \u0026 字母 \u0026 概率 \u0026 字母 \u0026 概率 \\ \\hline A \u0026 0.082 \u0026 H \u0026 0.061 \u0026 O \u0026 0.075 \u0026 V \u0026 0.010 \\ B \u0026 0.015 \u0026 I \u0026 0.070 \u0026 P \u0026 0.019 \u0026 W \u0026 0.023 \\ C \u0026 0.028 \u0026 J \u0026 0.002 \u0026 Q \u0026 0.001 \u0026 X \u0026 0.001 \\ D \u0026 0.043 \u0026 K \u0026 0.008 \u0026 R \u0026 0.060 \u0026 Y \u0026 0.020 \\ E \u0026 0.127 \u0026 L \u0026 0.040 \u0026 S \u0026 0.063 \u0026 Z \u0026 0.001 \\ F \u0026 0.022 \u0026 M \u0026 0.024 \u0026 T \u0026 0.091 \\ G \u0026 0.020 \u0026 N \u0026 0.067 \u0026 U \u0026 0.028 \\end{array} $$ 基于以上概率分布，可以把26个字母分为以下5组。 （1）E出现的概率最高，大约为0.12； （2）T、A、O、I、N、S、H、R每个出现的概率为0.06~0.09；　（3）D、L每个出现的概率大约为0.04；　（4）C、U、M、W、F、G、Y、P、B每个出现的概率为0.015~0.023；　（5）V、K、J、Ⅹ、Q、Z出现的概率最低，每个出现的概率都少于0.01。 对单表代换密码和置换密码进行分析时，可以利用该语言的统计规律性进行分析，较容易得到正确的解密结果。 eg.假设从仿射密码获得的密文为：“FMXVEDKAPHFERBNDKRXRSREFMORUDSDKDVSHVUFEDKAPRKDLYEVLRHHR”。 密文字母出现的频率是R（8次），D（7次），E（5次），H（5次），K（5次），F（4次），S（4次），V（4次）。可以假定R是e的加密，且D是t的加密，因为e和t分别是两个最常见的字母。数值化后，有$e_k(4)=17$，且$e_k(19)=3$。代入加密函数$e_k(x)=ax+b$，可得到一个含两个未知量的线性方程组： $$ \\left{ \\begin{aligned} 4a+b \u0026= 17 \\ 19a+b \u0026= 3 \\end{aligned} \\right. $$ 　这个系统有唯一的解$a=6,b=19$（在$Z_{26}$上）。但这是一个非法的密钥，因为$gcd(a,26)=2\u003e1$，所以上面的假设有误。 下一个猜想可能R是e的加密，E是t的加密，得$a=13$，又是不可能的。继续假定R是e的加密，且K是t的加密。于是产生了$a=3,b=5$，这至少是一个合法的密钥。接下来计算相应于$k=(3,5)$的解密函数，然后解密密文看是否得到了有意义的英文串。容易证明这是一个有效的密钥。 最后的明文是: algorithms are quite general definitions of arithmetic processes ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:2:2","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"现代对称密码体制 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:3:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"DES 　// TODO ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:3:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"非对称密码体制 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:4:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"RSA 　RSA中，公开密钥和私人密钥是一对大素数（100~200位十进制数或更大）的函数。在使用RSA公钥体制之前，每个参与者必须产生一对密钥。 （1）密钥产生 ①随机选择两个不同的大素数$p$和$q$，计算乘积$n=p×q$。 ②计算其欧拉函数值$\\Phi(x)=(p-1)(q-1)$。 ③随机选取加密密钥$k$，使$k$与$\\Phi(n)$互素，即$gcd(k,\\Phi(n))=1$。可以先设$k$为一个初值，并且$k\u003c\\Phi(n)$，然后采用试探法求出满足条件的$k$，可以令$sk=k(或pk=k)$。 ④利用欧几里得扩展算法计算$sk$的逆元，即解密密钥$pk$，以满足： $$ \\begin{aligned} sk · pk = 1\\ mod\\ \\Phi(n) \\end{aligned} $$ 即： $$ \\begin{aligned} pk = sk^{-1}\\ mod\\ \\Phi(n) \\end{aligned} $$ 　（2）加密 对消息$m$进行加密时，首先将它分解为比$n$小的数据分组$m_i$，即$m=m_1m_2\\cdots m_i\\cdots$。然后每块明文自乘$sk$次幂，再按模$n$求余数，即可得到密文。 密文为： $$ \\begin{aligned} C_i=m_i^{sk}\\ mod\\ n \\end{aligned} $$ 密文序列为： $$ \\begin{aligned} C=C_1C_2\\cdots C_i \\cdots \\end{aligned} $$ （3）解密 与加密算法基本相同，将每块密文自乘$pk$次幂，再按模$n$求余数，即可得到明文。 明文为： $$ \\begin{aligned} m_i=C_i^{pk}\\ mod\\ n \\end{aligned} $$ 明文序列为： $$ \\begin{aligned} m=m_1m_2\\cdots m_i\\cdots \\end{aligned} $$ 　eg.RSA的加密和解密过程。 （1）选择两个素数$p=47,q=61$。 （2）计算$n=p·q=2867$。 （3）计算$\\Phi(n)=(p-1)(q-1)=2760$。 （4）选择一个$sk=167$，它小于$\\Phi(n)$且与$\\Phi(n)=2760$互为素数。 （5）求出$pk$，使得$sk · pk=1\\ mod\\ 2760$，易得$pk=1223$，因为$1223×167=204241=74×2760+1$。 （6）结果得到的公开密钥为$KU={1223,2867}$，私人密钥为$KR={167,2867}$。 明文输入$m=123\\ 456\\ 789$。 首先将明文分成3组： $$ \\begin{aligned} m_1=123\\ m_2=456\\ m_3=789 \\end{aligned} $$ 用私钥$sk$进行加密： $$ \\begin{aligned} C_1=m_1^{167}\\ mod\\ 2867 = 1770\\ C_2=m_2^{167}\\ mod\\ 2867 = 1321\\ C_3=m_3^{167}\\ mod\\ 2867 = 1297 \\end{aligned} $$ 得到密文： $$ \\begin{aligned} C=1770\\ 1321\\ 1297 \\end{aligned} $$ 用公钥$pk$解密： $$ \\begin{aligned} m_1=C_1^{1223}\\ mod\\ 2867 = 123\\ m_2=C_2^{1223}\\ mod\\ 2867 = 456\\ m_3=C_3^{1223}\\ mod\\ 2867 = 789 \\end{aligned} $$ 第3章 信息认证技术 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:4:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"哈希函数 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:5:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"MD5 　算法简述：MD5以512位分组来处理输入的信息，且每一分组又被划分为16个32位子分组，经过了一系列的处理后，算法的输出由4个32位分组组成，将这4个32为分组级联后将生成一个128位的散列值。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:5:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"消息认证技术 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:6:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"消息认证方法 　消息认证主要使用密码技术来实现。在实际使用中，通过消息认证函数$f$产生用于鉴别的消息认证码，将其用于某个身份认证协议，发送方和接收方通过消息认证码对其进行相应的认证。 基于加密方法的消息认证 基于对称加密方式的消息认证过程 　假设$K$是通信双方共同拥有的会话密钥，发送方A只需使用$K$对消息$M$进行加密，将密文$C$发送给接收方B即可。由于密钥$K$只有A和B共同拥有，因此能够保证消息的机密性。此外，由于A是除B外唯一拥有密钥和产生正确密文$M$的一方，若B使用$K$对密文$C$进行解密还原出正确的消息$M$，就可以知道消息$M$的内容没有遭到篡改，同时也保证消息来自A。 添加校验码的消息认证过程 　然而，在实际使用中，简单的加密并不能达到真正消息认证的目的。消息$M$对接收方B来说是未知的，因此当B对密文进行解密后，如何判断$M$的合法性。如果$M$本身具有某种结构，如文本文章，那么B只需对解密后的消息进行结构上的分析即可判断$M$的合法性。但是，在实际通信中，消息$M$可能是随机的二进制位序列，如可执行代码、声音文件等，即使B解密后仍无法判断消息$M$是否是合法的。 　解决这一问题的方法是发送方在对消息M进行加密前，首先对消息通过校验函数$F(·)$产生一个校验码，将校验码附加在消息M之上，再进行加密。 基于公钥加密的消息认证过程 　在公开密钥加密体制中，发送方A可以使用自己的私钥$K_{AS}$对消息$M$进行加密，由于只有对应A的公钥$K_{AP}$才能正确解密出消息M，因此采用该方法可以对消息$M$的来源进行认证。同时，该方法和前面所讲的对称加密方法一样，在实际应用中需要在消息M加密之前附加一定的校验码来提高认证的能力。 　　由于解密时使用的是A的公钥$K_{AP}$，因此该方法不能保证消息的机密性，要保证消息的机密性，必须使用接收方B的公钥$K_{BP}$。A可以先使用自己的私钥$K_{AP}$对消息进行加密，然后再使用接收方B的公钥$K_{BP}$进行加密，则同时既保证了机密性，又提供了消息认证的能力。 基于哈希函数的消息认证 使用哈希函数的消息认证过程 　哈希函数由于其单向性和抗碰撞性，因此常用来做消息认证。哈希函数以一个变长的消息$M$作为输入，产生一个具有固定长度的散列值$H(M)$，也称为消息摘要。散列值是原始消息的函数，原始信息任何内容的变化都将导致散列值的改变，因此可用于检测信息的完整性。 　简单的消息认证方法可以用通信双方的共享密钥$K$对散列值$H(M)$进行加密，将加密后的结果$C=E_K(H(M))$以附件的方式附着在消息$M$上进行传输，接收方收到消息后，只需对$C$进行解密，即可获得散列值$H(M)$，然后使用哈希函数对消息$M$计算另一个散列值$H(M)$，通过比较$H(M)$与$H\\prime(M)$二者是否匹配，即可完成对消息进行的认证。 保证机密性的哈希函数消息认证过程 　若需要保证消息的机密性，可将散列值附加在消息上，并使用双方的会话密钥$K$对其进行加密，得到加密后的密文$C=E_K(M‖H(M)$，并对其进行传输。由于哈希函数的散列值具有对原始消息进行差错检测的能力，因此接收方可以通过这种方式来验证消息是否遭到篡改。因为只有使用通信双方所拥有的会话密钥$K$才能对密文进行解密，因此只要密钥不泄露就可验证消息来自正确的发送方，同时也保证了消息的机密性。 混合加密认证 　采用公钥加密的方法同样可以用于消息认证。该方法是发送方A使用自己的私钥$K_{AS}$对散列值$H(M)$进行加密，将加密后的密文$C=E_{KAS}(H(M))$附在原始消息$M$上进行传输。接收方B只需使用A的公钥对密文进行解密，得到散列值$H(M)$后就能对消息进行认证。 　同样，如果保证消息的机密性，可使用接收方B的公钥$K_{BP}$对消息$M$和加密后的密文$C=E_{KAS}(H(M))$进行加密，得到新的密文$X=E_{KBP}(M‖E_{KAS}(H(M))$。由于使用了接收方B的公钥进行加密，因此只有正确的接收方B才能对密文进行正确解密，从而保证了消息的机密性的同时，也提供了认证的能力。 　采用公钥进行非对称加密能提供很好的机密性，而且与对称加密相比，密钥的管理相对容易。但由于非对称加密算法产生的密文不紧凑，加密速度慢，不适合加密数据量较大的消息，因此在实际使用中，常常将对称加密与公钥加密合起来一起使用。具体方法是使用一个对称密钥$K$对消息$M$和加密后的密文$C=E_{KAS}(H(M))$进行加密，再使用接收方B的公钥$K_{BP}$对密钥$K$进行加密，将两个加密结果进行传输。由于使用密钥$K$对消息进行了加密，同时使用了接收方的公钥$K_{BP}$对密钥$K$进行加密，因此只有正确的接收方B才能获得对称密钥$K$，保证了消息的机密性和认证功能。同时，由于对称加密的速度较快，因此在保证了安全性的基础上提高了运算的速度。 基于消息认证码（MAC）的消息认证 基于消息认证码的认证过程 　使用消息认证码进行消息认证，其基本思想与使用哈希函数类似，同样都是对消息产生个定长的输出，用于鉴别消息的完整性。然而使用哈希函数的时候往往需要对散列值进行加密，如果在不需要保证消息机密性的条件下，使用加密会影响速度。消息认证码在进行定长输出的时候，使用了一个密钥来和消息一起产生定长的输出，这个定长的输出就是消息认证码。 　使用过程：假设通信双方A、B拥有会话密钥$K$，用于产生MAC的函数为$C$。当发送方A要向接收方B发送消息M时，先计算出消息$M$的MAC值，即MAC=$C_K(M)$，然后将MAC值附加在消息$M$上一起发送给B。接收方B收到消息后，使用与发送方相同的会话密钥$K$计算出消息$M$的MAC值，然后与发送方A发送过来的MAC值进行比较，若二者匹配，则消息合法。由于共享密钥$K$只有A和B共享，攻击者想篡改消息$M$，但没有密钥$K$，那么计算出来的MAC值将与原先的MAC值不同，因此接收方B就能通过比较MAC值来判断消息的合法性。 　","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:6:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"数字签名 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:7:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"数字签名的实现 直接数字签名 　直接数字签名过程可以总结为以下步骤。 （1）发送方首先对被发送文件采用哈希函数进行运算，得到一个固定长度的数字串，称为报文摘要。 （2）发送方生成发送文件的报文摘要，用自己的私钥对摘要进行加密，形成发送方的数字签名$S$。 （3）这个数字签名将作为报文的附件和报文$M$一起发送给接收方。 （4）接收方接收到报文后，用同样的哈希算法计算出新的报文摘要，再用发送方的公钥对报文附件的数字签名进行解密，比较两个报文摘要，如果值相同，接收方就能确认该数是发送方。 仲裁数字签名 　在仲裁数字签名中，假设用户A与B要进行通信，每个从A发往B的签名报文首先都先发送给仲裁者C，C检验该报文及其签名的出处和内容，然后对报文注明日期，同时指明该报文已通过仲裁者的检验。仲裁者的引入解决了直接签名方案中所面临的问题，即发送方的否认行为。在这种方案中，仲裁者的地位十分关键和敏感，它必须是一个所有通信方都能充分信任的仲裁机构，也就是说仲裁者C必须是一个可信的系统。 $$ \\begin{aligned} A \\longrightarrow C \\longrightarrow B \\end{aligned} $$ 方案1：采用对称加密算法的数字签名 　设C是可信第三方，它能同时与A、B通信。它与A有共享密钥$K_A$，与B有共享密钥$K_B$。 （1）A产生报文$M$并计算其散列值$H(M)$，然后将附加了数字签名的报文发送给仲裁者C，并用$K_A$加密，数字签名由A的标识符$ID_A$ 和报文的散列值$H(M)$构成。 （2）仲裁者C对数字签名进行解密，验证其散列值是有效散列值。 （3）验证后，C向B发送一个报文，用$K_S$加密，该报文包括A的标识符$ID_A$、A发出的原始报文$M$、A的数字签名和时间戳$T$。 （4）B解密恢复出报文和签名。 时间戳$T$的作用是让B能够判断$M$是否是过时的报文。 上述方案可表述为： （1）$A \\longrightarrow C:M‖E_{KA}(ID_A‖H(M))$ （2）$C \\longrightarrow B:E_{KB}(ID_A‖M‖E_{KA}(ID_A‖H(M‖T))$ 在这种方案中，B不能直接验证A的签名，签名是用来解决争端的。B可以认定报文$M$来自A是因为$M$经过了C的验证，这种方案中通信双方A、B对C是高度信任的，即A可以相信C不会泄露$K_A$，因此不会产生伪造的签名。B也相信C发送的报文$M$是经过验证的，确实来自A。此外，A、B还必须相信C能公平地解决争端。 这种方案的缺陷在于报文$M$的内容是以明文的形式传送给仲裁者C，任何攻击者都能获取该消息。 方案2：使用对称密码算法，密文传输 　方案2是在方案1的基础上加强了数据的机密性。在此方案中，通信双方A、B使用共享密钥$K_S$来加密所要传送的报文$M$。A向C传送的报文中包含A的标识符$ID_A$、使用$K_S$加密原始报文$M$后的密文及数字签名，其中数字签名是由$ID_A$和加密报文的散列值构成的。仲裁者C经过检验，将收到的报文添加时间戳后，加密发送给接收方B。整个交互过程可以表述如下。 （1）$A \\longrightarrow C:ID_A‖E_{KS}(M)‖E_{KA}(ID_A‖H(E_{KS}(M)))$ （2）$C \\longrightarrow B:E_{KB}(ID_A‖E_{KS}(M)‖E_{KA}(ID_A‖H(E_{KS}(M))‖T)$ 在这种方案中，尽管仲裁者C无法读取消息报文$M$中的内容，但他仍能防止A或B中任何一方的欺诈。但两种方案都存在的问题是：仲裁者C可能与发送方勾结来否认签名报文，或者与接收方共同伪造发送方的签名。 方案3：使用公开密钥算法，密文传输 　针对上述两种方案的缺陷，采用公开密钥方案就能够迎刃而解。使用公开密钥进行数字签名时，A对报文$M$进行两次加密：先用其私钥$K_{AS}$对消息$M$进行加密，再用B的公钥$K_{BP}$加密，得到加密后的签名；A再用$K_{AS}$对其标识符$ID_A$和上述加密后的签名进行加密，然后连同$ID_A$一起发送给C。经过双重加密后，报文$M$只有B才能阅读，对C来说是安全的，但C能通过外层的解密，从而证实报文确实是来自A的（因为只有A有私钥$K_{AS}$）。C通过验证A的公/私钥对（$K_{AP}$和$K_{AS}$）的有效性完成对报文的验证。然后C再用自己的私钥$K_{CS}$对A的标识符IDA、双重加密后的M及时间戳进行加密后发送给B。整个交互过程可以表述如下： （1）$A \\longrightarrow C:ID_A‖(E_{KAS}(ID_A‖E_{KBP}(E_{KAS}(M)))$ （2）$C \\longrightarrow B:E_{KCS}(ID_A‖K_{KBP}(E_{KAS}(M))‖T)$ 采用公开密钥的数字签名方案具有许多优点：首先，通信前，通信各方没有任何共享信息，从而避免了联合欺诈；其次，A发给B的消息对其他人是保密的，包括C；最后，即使A的私钥$K_{AS}$已泄密或被盗，但C的私钥$K_{CS}$没有泄密，那么时间戳不正确的消息是不能被发送的。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:7:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"身份认证 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:8:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"基于对称密钥的身份认证 基于对称密钥的双向身份认证 Needham-Schroeder协议 　Needham-Schroeder协议利用KDC进行密钥分配，同时具备了身份认证的功能。假设通信双方A、B和KDC分别共享密钥$K_A$和$K_B$。 （1）$A \\longrightarrow KDC:ID_A‖ID_B‖N_1$ （2）$KDC \\longrightarrow A:E_{Ka}(K_S‖ID_B‖N_1‖E_{Kb}(K_S‖ID_A))$ （3）$A \\longrightarrow B:E_{KB}(K_S‖ID_A)$ （4）$B \\longrightarrow A:E_{KS}(N_2)$ （5）$A \\longrightarrow B:E_{KS}(f(N_2))$ 该协议的目的是要保证将会话密钥Ks安全地分配给A和B。 第1步，A将他的身份信息$ID_A$、B的身份信息$ID_B$及一个作为临时交互值的随机数$N_1$组成的消息发给KDC，表明A要与B认证并通信。 第2步，KDC产生A、B之间的会话密钥$K_S$，用KDC与B的共享密钥$K_B$对会话密钥$K_S$和A的身份信息$ID_A$进行加密，然后用它和A的共享密钥$K_A$对随机数$N_1$、B的身份信息$ID_B$、会话密钥$K_S$和已加密的信息进行加密，然后将它发送给A。 第3步，A将消息解密并获得$K_S$，比较$N_1$和第一步所发送的$N_1$是否一致，然后将KDC发来的用$K_B$加密的消息发送给B。 第4步，B对消息进行解密并获得$K_S$，然后产生另一随机数$N_2$，用$K_S$加密并发送给A。 第5步，A对消息解密，并用函数$f$产生新的结果，并用$K_S$加密，然后发给B。 第6步，B对消息解密，并验证它是否是$f$产生的结果。 在这个过程中，第4、5步可以防止某些重放攻击。例如，若攻击者窃听到第3步中的报文并进行重放，重放报文中的$K_S$是一个过期的会话密钥，若没有第4、5步的交互过程，B将试图使用这个过期密钥，从而产生混乱。 尽管如此，该协议仍然存在漏洞，容易受到重放攻击。例如，攻击者Ⅹ可能从某些途径获得一个过期的会话密钥。X就可以冒充A重放第3步的报文，欺骗B使用过期的会话密钥，除非B明确记得以前与A通信所使用的所有会话密钥，否则B无法确定是否是重放的消息。 Denning协议 　Denning协议对Needham-Schroeder协议进行了修改，引入了时间戳机制，整个过程如下： （1）$A \\longrightarrow KDC:ID_A‖ID_B$ （2）$KDC \\longrightarrow A:E_{Ka}(K_S‖ID_B‖T‖E_{Kb}(K_S‖ID_A‖T))$ （3）$A \\longrightarrow B:E_{KB}(K_S‖ID_A‖T)$ （4）$B \\longrightarrow A:E_{KS}(N_1)$ （5）$A \\longrightarrow B:E_{KS}(f(N_1))$ 时间戳$T$使A和B确信会话密钥$K_S$是最新产生的，这样A和B都知道此次交换的是一个新的会话密钥。A和B通过验证下列式子来验证密钥的及时性： $$ \\begin{aligned} \\vert c-T \\vert \u003c\\Delta t_1 + \\Delta t_2 \\end{aligned} $$ 其中，$c$是本地时钟的时间值，$T$是报文携带的时间戳，$\\Delta t_1$是KDC时钟与本地时钟的正常偏差，$\\Delta t_2$是网络的正常时延值，满足该公式的时间戳被认为是合法的。由于是使用与KDC的共享密钥对时间戳进行加密，因此即使攻击者知道旧的会话密钥，也不能成功地重放消息，因为B可以根据消息的及时性检测出来。 与Needham-Schroeder协议相比，Denning协议的安全性更高，但同时也带来了新的问题，即如何安全准确地通过网络进行时钟同步。因此，该协议也存在着一定的危险，由于时钟同步机制的出错或受到破坏，通信各方的时钟不同步，协议将容易遭到重放攻击。例如，发送方的时钟快于接收方的时钟，攻击者可以窃听到发送端的报文，由于报文中的时间戳快于接收方的本地时间，攻击者可以等到接收方时钟等于报文时间戳时重放该报文，这种重放可能导致不可预知的结果，这样的攻击称为抑制-重放攻击。　解决抑制-重放攻击的一种方法是要求通信各方必须根据KDC的时钟周期性地校验时钟。另一种方法是基于随机数的临时交互值的认证协议，它不要求时钟同步，并且接收的临时交互值对发送方而言是不可预知的，从而不易受到抑制-重放攻击。 Neuman-Stubblebine协议 　Neuman-Stubblebine协议提出目的是为了试图解决抑制-重放攻击，同时解决Needham-Schroeder协议中出现的问题： （1）$A \\longrightarrow B:ID_A‖N_1$ （2）$B \\longrightarrow KDC:ID_B‖N_2‖E_{Kb}(ID_A‖N_1‖T)$ （3）$KDC \\longrightarrow A:E_{KA}(ID_B‖N_1‖K_S‖T)‖E_{KB}(ID_A‖K_S‖T)‖N_2$ （4）$A \\longrightarrow B:E_{KB}(ID_A‖K_S‖T)‖E_{KS}(N_2)$ 第1步，A发起认证。A产生临时交互值$N_1$，连同自己的身份信息$ID_A$以明文的形式发送给B，$N_1$的作用是在进行密钥分发时将返回给A，A通过验证$N_1$的值来确认消息的时效性。 第2步，B向KDC申请会话密钥。B将A的身份信息$ID_A$、临时交互值$N_1$及时间戳$T$用他和KDC的共享密钥$K_B$加密，把加密结果、自己的身份信息$ID_B$和新的临时交互值$N_2$起发送给KDC。其中用$K_B$加密的数据$E_{KB}(ID_A‖N_1‖T)$的作用是请求KDC向A发布一个可信的“票据”，指定了“票据”的接收者、有效期，以及A发送的临时交互值N1。 第3步，KDC产生会话密钥$K_S$，然后产生两个消息。第一个消息是由B的身份信息$ID_B$、A的临时交互值$N_1$、会话密钥$K_S$和时间戳组成，并用他与A的共享密钥$K_A$加密；第二个消息是由A的身份信息$ID_A$、会话密钥$K_S$和时间戳组成，并用他与B的共享密钥$K_B$加密。将这两个消息连同B的临时交互值$N_2$一起发送给A。时间戳$T$给出了会话密钥的使用时限，$ID_B$用于证实B已经收到初始报文，$N_1$能够检测重放攻击。 第4步，A用KDC与B的共享密钥$K_B$加密的消息和加密后的$N_2$发送给B。B从加密消息中得到共享密钥并解密出$N_2$，通过比较$N_2$来鉴别消息是来自A还是一次重放攻击。 这个协议为A、B双方建立会话提供了一种安全有效的会话密钥交换方式。在协议中，时间戳$T$只是相对B的本地时钟，也只有B对其进行校验，因此不需要时钟的同步。同时，A可以保存用于鉴别B的消息，可以减少与KDC的多次交互。假设A、B完成了上面的协议和通信，然后终止连接，A要和B再次建立新的会话时，只要A保存了原有的消息，并在密钥的有效期限内，不必依赖KDC，就能够在3步之内重新进行身份认证。 （1）$A \\longrightarrow B:E_{KB}[ID_A‖K_S‖T]‖N_1 \\prime$ （2）$B \\longrightarrow A:N_2 \\prime ‖E_{KS}(N_1)$ （3）$A \\longrightarrow B:E_{KS}(N_2)$ B在第1步收到消息后可以验证密钥有没有过期，新产生的N1、N2用来检测是否有重放攻击。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:8:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"基于公钥的身份认证 基于公钥的双向身份认证 Denning-Sacco协议 　在公开密钥加密的身份认证中，也需要有一个类似的中心系统来分发通信各方的公开密钥证书。因为在没有认证中心或密钥分配中心的情况下，要使通信各方都能拥有对方的当前公钥是不切实际的。 Denning-Sacco协议是一种使用时间戳机制的公钥分配和认证方法。假设通信双方分别为A和B，AS为认证服务器。 （1）$A \\longrightarrow AS:ID_A‖ID_B$ （2）$AS \\longrightarrow A:E_{KSAS}(ID_A‖K_{PA}‖T)‖E_{KSAS}(ID_B‖K_{PB}‖T)$ （3）$A \\longrightarrow B:E_{KSAS}(ID_A‖K_{PA}‖T)‖E_{KSAS}(ID_B‖K_{PB}‖T)‖E_{KPB}(E_{KSA}(K_S‖T)$ 其中，$K_{PA}、K_{SA}、K_{PB}、K_{SB}$分别为A和B的公钥和私钥。$K_{PAS}$和$K_{SAS}$分别为AS的公钥和私钥。在这个协议中，认证中心系统不负责密钥的分配，而是提供公钥证书，所以称为认证服务器(AS)。会话密钥$K_S$的选择和加密完全由A来完成，因此不存在被AS泄露的危险。同时使用了时间戳机制，可以防止重放攻击对密钥安全性的威胁。 这个协议简洁明了，但不足之处仍然是需要严格的时钟同步才能保证协议的安全。 Woo-Lam协议 　Woo-Lam协议使用随机数作为临时交互值来代替时间戳，它是一种以KDC为中心的认证协议。 （1）$A \\longrightarrow KDC:ID_A‖ID_B$ （2）$KDC \\longrightarrow A:E_{KSK}(ID_B‖K_{PB})$ （3）$A \\longrightarrow B:E_{KPB}(N_1‖ID_A)$ （4）$B \\longrightarrow KDC:ID_B‖ID_A‖E_{KPK}(N_1)$ （5）$KDC \\longrightarrow B:E_{KSK}(ID_A‖K_{PA})‖E_{KPB}(E_{KSK}(N_1‖K_S‖ID_B))$ （6）$B \\longrightarrow A:E_{KPA}(E_{KSK}(N_1‖K_S‖ID_B)‖N_2)$ （7）$A \\longrightarrow B:E_{KS}(N_2)$ 其中，$K_{PK}$和$K_{SK}$分别是KDC的公钥和私钥。在协议刚开始，A向KDC发送一个要和B建立安全连接的请求，KDC将B的公钥证书副本返回给A，A通过B的公钥告诉B想与他通信，同时将临时交互值$N_1$发给B。然后，B向KDC请求A的公钥证书和会话密钥，由于B发送消息中包含A的临时交互值，因此KDC可以用临时交互值对会话密钥加戳，其中临时交互值受KDC的公钥保护。接着，KDC将A的公钥证书的副本和消息${N_1，K_S，ID_B}$一起返回给B。这条消息说明，$K_S$是KDC为B产生的且与$N_1$有关的密钥。$N_1$使A确信$K_S$是新会话密钥。用KDC的私钥对三元组${N_1，K_S，ID_B}$加密，使得B可以验证该三元组确实来自KDC。由于是用B的公钥对该三元组加密，因此其他各方均不能利用该三元组与A建立假冒连接。在第6步，B用A的公钥对$E_{KSA}(N_1‖K_S‖ID_B)$和B产生的随机数$N_2$加密后发送给A，A先解密得出会话密钥$K$，然后用$K_S$对$N_2$加密发送给B，这样可以使B确信A已经获得正确的会话密钥。 相比 Denning-Sacco协议，这个协议对抵抗攻击的能力更强，但也存在着某些安全隐患。改进的方法是在第5步和第6步中加入A的身份信息$ID_A$，将会话密钥与双方的身份信息绑定在一起。将$ID_A$和$N_1$绑定在一起唯一标识了A的连接请求。具体过程如下： （1）$A \\longrightarrow KDC:ID_A‖ID_B$ （2）$KDC \\longrightarrow A:E_{KSK}(ID_B‖K_{PB})$ （3）$A \\longrightarrow B:E_{KPB}(N_1‖ID_A)$ （4）$B \\longrightarrow KDC:ID_B‖ID_A‖E_{KPK}(N_1)$ （5）$KDC \\longrightarrow B:E_{KSK}(ID_A‖K_{PA})‖E_{KPB}(E_{KSK}(N_1‖K_S‖ID_A‖ID_B))$ （6）$B \\longrightarrow A:E_{KPA}(E_{KSK}(N_1‖K_S‖ID_A‖ID_B)‖N_2)$ （7）$A \\longrightarrow B:E_{KS}(N_2)$ 第4章 计算机病毒 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:8:2","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"计算机病毒的特征及分类 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:9:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"计算机病毒的特征 传染性 　传染性是病毒的基本特征，是判断一个程序是否为计算机病毒的最重要的特征。病毒能通过自我复制来传染正常文件，达到破坏计算机正常运行的目的。但它的传染是有条件的，也就是病毒程序必须被执行之后才具有传染性，才能传染其他文件。病毒一旦进入计算机系统，就会开始寻找机会感染其他文件。 计算机病毒的主要传播渠道有硬盘、光盘、可移动存储器、网页、电子邮件和FTP下载等。 破坏性 　任何计算机病毒感染了系统后，都会对系统产生不同程度的影响。病毒都是可执行程序或代码，当病毒代码运行时就会降低系统的工作效率，占用系统资源。病毒发作时的破坏程度取决于病毒设计者。轻则占用系统资源，影响计算机运行速度，降低计算机工作效率，使用户不能正常使用计算机；重则毁坏系统，破坏用户计算机中的数据并使之无法恢复，甚至破坏计算机硬件，给用户带来巨大的损失。 隐蔽性 　计算机病毒具有很强的隐蔽性，它一般都是具有很高编程技巧的、短小精悍的代码，通常附在正常的程序之中或藏在磁盘隐秘的地方。没有经过代码分析是很难将病毒程序和正常程序区分开的。有些病毒采用了极其高明的手段来隐藏自已，如使用隐藏文件、注册表内的相似字符等，而且有的病毒在感染了系统之后，计算机系统仍能正常工作，用户不会感到有任何异常，普通用户无法在正常的情况下发现病毒。 寄生性 　一般情况下，计算机病毒都不会独立存在，而是寄生于其他程序中，当执行这个程序时，病毒代码就会被执行。病毒寄生在其他程序中的同时，也进行感染扩散，病毒潜伏寄生的时间越长，感染的范围也就越大，对用户造成的影响也就越大。在未满足触发条件或正常程序未启动之前，用户是不易发觉病毒的存在的。 可触发性 　大部分病毒感染系统之后一般不会马上发作，而是隐藏在系统中，就像定时炸弹一样，只有在满足特定条件时才被触发。潜伏机制是计算机病毒内部的一种机制，在不满足触发条件时，病毒只会感染而不做破坏，只有在触发条件满足的情况下才会表现出来。例如黑色星期五病毒，不到预定时间，用户就不会觉察出异常。一旦遇到13日并且是星期五，病毒就会被激活并且对系统进行破坏。当然，还有著名的CIH病毒，它是在每月的26日发作。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:9:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"计算机病毒制作与反病毒技术 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:10:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"病毒的检测 特征代码法 　特征代码技术是根据病毒程序的特征，如感染标记、特征程序段内容、文件长度变化、文件校验和变化等对病毒进行分类处理，而后在程序运行中凡有类似的特征点出现，则认定是病毒，是早期病毒检测技术的主要方法，也是大多数反病毒软件的静态扫描方法。一般认为，特征代码法是检测已知病毒的最简单、开销最小的方法。 特征代码法的工作原理是对每种病毒样本抽取特征代码，根据该特征代码进行病毒检测。主要依据原则为：抽取的代码比较特殊，不大可能与普通正常程序代码吻合。抽取的代码要有适当的长度，一方面维持特征代码的唯一性，也就是说一定要具有代表性，使用所选的特征代码都能够正确地检查出它所代表的病毒。如果病毒特征代码选择得不准确，就会带来误报（发现的不是病毒）或漏报（真正病毒没有发现）。另一方面不要有太大的时间和空间的开销。一般是在保持唯一性的前提下，尽量使特征代码长度短些，以减少时间和空间的开销。用每一种病毒代码中含有的特定字符或字符串对被检测的对象进行扫描，如果在被检测对象内部发现某种特定字符或字符串，则表明发现了该字符或字符串代表的病毒前面介绍传染机制时提到的感染标记就是一种识别病毒的特定字符。实现这种扫描的软件称为特征扫描器。根据特征代码法的工作原理，特征扫描器由病毒特征代码库和扫描引擎两部分组成。病毒特征代码库包含了经过特别选定的各种病毒的反映其特征的字符或字符串。扫描引擎利用病毒特征代码库对检测对象进行匹配性扫描，一日有匹配便发出报警显然，病毒特征代码库中的病毒特征代码越多。 扫描引擎能识别的病毒也就越多特征代码法的优点是检测速度快，误报警率低，能够准确地查出病毒并确定病毒的种类和名称，为消除病毒提供确切的信息。缺点是不能检测出未知病毒、变种病毒和隐蔽性病毒，需要定期更新病毒资料库，具有滞后性，同时，搜集已知病毒的特征代码费用开销大。 校验和法 　校验和法的工作原理是计算正常文件内容的校验和，将该校验和写入文件中或写入别的文件中保存。在文件使用过程中，定期地或每次使用文件前，检查文件当前内容算出的校验和与原来保存的校验和是否一致，如果不一致便发出染毒报警。 运用校验和法检测病毒一般采用以下3种方式。 （1）在检测病毒工具中纳入校验和法，对被查对象文件计算其正常状态的校验和，将校验和值写入被查文件中或检测工具中，然后进行比较。 （2）在应用程序中放入校验和自动检查功能，将文件正常状态的校验和写人文件本身中，每当应用程序启动时，比较当前校验和与原校验和的值，实现应用程序的自检测。 （3）将校验和检査程序常驻内存，每当应用程序开始运行时，自动比较检查应用程序内容或别的文件中预先保存的校验和。 　校验和法既能发现已知病毒，也能发现未知病毒，但是，它不能识别病毒种类，不能报出病毒名称。由于病毒感染并非文件内容改变的唯一性原因，文件内容的改变有可能是正常程序引起的，如软件版本更新、变更口令及修改运行参数等，因此校验和法常常有虚假报警，而且此法也会影响文件的运行速度。另外，校验和法对某些隐蔽性极好的病毒无效。这种病毒进驻内存后，会自动剥去染毒程序中的病毒代码，使校验和法受骗，对一个有毒文件算出正常校验和。因此，校验和法的优点是方法简单，能发现未知病毒，被查文件的细微变化也能发现；其缺点是必须预先记录正常状态的校验和，会有虚假报警，不能识别病毒名称不能对付某些隐蔽性极好的病毒。 行为监测法 　行为监测法是常用的行为判定技术，其工作原理是利用病毒的特有行为特征进行检测，旦发现病毒行为则立即报警。经过对病毒多年的观察和研究，人们发现病毒的一些行为是病毒共有的，而且比较特殊。在正常程序中，这些行为比较罕见，如一般引导型病毒都会占用INT 13H；病毒常驻内存后，为防止操作系统将其覆盖，必须修改系统内存总量；对COM、EXE文件必须执行写入操作；染毒程度运行时，先运行病毒，后执行宿主程序，两者切换等许多特征行为。行为监测法就是引入一些人工智能技术，通过分析检查对象的逻辑结构，将其分为多个模块，分别引入虚拟机中执行并监测，从而查出使用特定触发条件的病毒。 行为监测法的优点在于不仅可以发现已知病毒，而且可以相当准确地预报未知的多数病毒。但也有其缺点，即可能虚假报警和不能识别病毒名称，而且实现起来有一定难度。 软件模拟法 　变种病毒每次感染都变化其病毒代码，对付这种病毒，特征代码法失效，因为变种病毒代码实施密码化，而且每次所用的密钥不同，把染毒的代码相互比较也无法找出相同的可能作为特征的稳定代码。虽然行为监测法可以检测出变种病毒，但在检测出病毒后，因为病毒的种类不知道，也无法做杀毒处理。 软件模拟法是新的病毒检测工具所使用的方法之一。该工具开始运行时，使用特征代码法检测病毒，如果发现有隐蔽性病毒或变种病毒的嫌疑时，启动软件模拟模块。软件模拟法模拟CPU的执行，在其设计的虚拟机下执行病毒的变体引擎解码程序，安全地将变种病毒解开，监视病毒的运行，使其露出本来的面目，再加以扫描。待病毒自身的密码译码以后，再运用特征代码法来识别病毒的种类。 　总地来说，特征代码法查杀已知病毒比较安全彻底，实施比较简单，常用于静态扫描模块中；其他几种方法适用于查杀未知病毒和变种病毒，但误报率高，实施难度大，在常驻内存的动态监测模块中发挥重要作用。 第5章 网络攻击与防范技术 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:10:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"网络攻击概述和分类 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:11:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"网络攻击的步骤概览 　（1）目标探测。攻击者在攻击之前的首要任务，就是明确攻击目标是单个主机还是整个网段，并了解目标的具体网络信息等。 （2）端口扫描。通过端口扫描可以搜集到目标主机的各种有用信息，包括端口是否开放，能否匿名登录，等等。 （3）网络监听。黑客可以借助网络监听技术对其他用户进行攻击，同时也可以截获用户名、口令等有用信息。 （4）实施攻击。采用有效的方式对目标主机进行攻击，如缓冲区溢出、DoS等。 （5）撤退。留下后门，消除攻击的痕迹。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:11:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"拒绝服务攻击 　DoS（Denial of service，拒绝服务）攻击是一种既简单又有效的攻击方式。它是针对系统的可用性发起的攻击，通过某些手段使得目标系统或网络不能提供正常的服务。该攻击主要是利用了TCP/IP中存在的设计缺陷，或者操作系统及网络设备的网络协议栈存在的实现缺陷。 一些商业及政府网站都曾经遭受拒绝服务攻击。在2000年2月发生的一次针对某些高利润的站点（如雅虎、易趣等）的拒绝服务攻击持续了近两天，使这些公司遭受了很大的损失，事后这些攻击确定为分布式的拒绝服务攻击。 从攻击技术来看，υoS攻击表现为带宽消耗、系统资源消耗、程序实现上的缺陷、系统策略的修改等几种。带宽消耗是通过网络发送大量信息，用足够的传输信息消耗掉有限的带宽资源。系统资源消耗是向系统发送大量信息，针对操作系统中有限的资源，如进程数、磁盘、CPU、内存、文件句柄等。利用程序实现上的缺陷，对异常行为的不正确处理，通过发送些非法数据包使系统死机或重启，如 Ping of Death。修改或篡改系统策略也可以使得它不能提供正常的服务。 从攻击目标来看，有通用类型的DoS攻击和系统相关的攻击。通用类型的DoS攻击往往是与具体系统无关的，如针对协议设计缺陷的攻击。系统相关的攻击往往与具体的实现有关。最终，所有的攻击都是与系统相关的，因为有些系统可以针对协议的缺陷提供一些补救措施，从而免受此类攻击。 一些典型的DoS攻击有 Ping of Death、Teardrop、UDP Flooding、Land、SYN Flooding和Smurf等。 第6章 防火墙技术 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:12:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"防火墙的体系结构 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:13:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"堡垒主机体系结构 　堡垒主机体系结构在某些地方也称为筛选路由器体系结构。堡垒主机是内部网在 Internet上的代表。堡垒主机是任何外来访问者都可以连接、访问的。通过该堡垒主机，防火墙内的系统可以对外操作，外部网用户也可以获取防火墙内的服务。 堡垒主机是一种被强化的可以防御攻击的计算机，被暴露于因特网之上，作为进入内部网络的一个检查点（checkpoint），以达到把整个网络的安全问题集中在某个主机上解决。正是由于这个原因，防火墙的建造者和防火墙的管理者应尽力给予其保护，特别是在防火墙的安装和初始化的过程中应予以仔细保护。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:13:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"双宿主主机体系结构 　双宿主主机的防火墙系统由一台装有两个网卡的堡垒主机构成。两个网卡分别与外部网及内部网相连。堡垒主机上运行防火墙软件，可以转发数据、提供服务等。堡垒主机将防止在外部网络和内部系统之间建立任何直接的连接，可以确保数据包不能直接从外部网络到达内部网络。 双宿主主机有两个接口，具有以下特点。 （1）两个端口之间不能进行直接的IP数据包的转发。 （2）防火墙内部的系统可以与双宿主主机进行通信，同时防火墙外部的系统也可以与双宿主主机进行通信，但二者之间不能直接进行通信。 这种体系结构的优点是结构非常简单，易于实现，并且具有高度的安全性，可以完全阻止内部网络与外部网络通信。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:13:2","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"屏蔽主机体系结构 　双宿主主机体系结构是由一台同时连接在内外部网络之间的双宿主主机提供安全保障的，而屏蔽主机体系结构则不同，在屏蔽主机体系结构提供安全保护的主机仅仅与内部网相连。另外，主机过滤还有一台单独的过滤路由器。包过滤路由器应避免用户直接与代理服务器相连。 这种结构的堡垒主机位于内部网络，而过滤路由器按以下规则过滤数据包：任何外部网（如 Internet）的主机都只能与内部网的堡垒主机建立连接，甚至只有提供某些类型服务的外部网主机才被允许与堡垒主机建立连接。任何外部系统对内部网络的操作都必须经过堡垒主机，同时堡垒主机本身就要求有较全面的安全维护。包过滤系统也允许堡垒主机与外部网进行一些“可以接受（即符合站点的安全规则）”的连接。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:13:3","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"屏蔽子网体系结构 　屏蔽子网体系结构也称为屏蔽子网网关体系结构，就是在屏蔽主机体系结构中的内部网和外部网之间再增加一个被隔离的子网，这个子网由堡垒主机、应用级网关等公用服务器组成，习惯上将这个子网称为“非军事区”（De Militarised Zone，DMZ）。在屏蔽主机体系结构中，堡垒主机最易受到攻击，尽管可以对它提供最大限度的保护，但因其为入侵者首先能攻击到的机器，所以它仍然是整个系统最容易出问题的环节。 用边界网络来隔离堡垒主机与内部网，能减轻入侵者在攻破堡垒主机后带给内部网的压力。人侵者即使攻破堡垒主机也不可能对内部网进行任意操作，而只可能进行部分操作。 在最简单的屏蔽子网体系结构中，有两台都与边界网络相连的过滤路由器，一台位于边界网络与内部网络之间，而另一台位于边界网络与外部网络之间。在这种结构下，入侵者要攻击到内部网必须通过两台路由器的安全控制，即使入侵者通过了堡垒主机，它还必须通过内部路由器才能抵达内部网，因此整个网络安全机制就不会因一个站点攻破而全部瘫痪。 第7章 入侵检测技术 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:13:4","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"入侵检测系统的特点和分类 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:14:0","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"入侵检测系统的分类 基于主机的入侵检测系统 　基于主机的入侵检测系统通常安装在需要重点检测的主机上，主要是对该主机的网络实时连接及系统审计日志进行智能分析和判断。 由于基于主机的入侵检测系统必须安装在需要保护的设备上，这必定降低该设备的工作效率。另外，全面部署主机入侵检测系统代价较大，任何企业都无法将所有主机用主机入侵检测系统保护，只能选择其中的一部分。此时，那些未安装主机入侵检测系统的机器将成为保护的盲点，入侵者可利用这些机器达到攻击目标。因此，随着网络使用的频繁程度越来越高，基于主机入侵检测系统将无法适应这种局面，它只能作为网络入侵检测的一个有力补充。 基于网络的入侵检测系统 　NIDS在混杂模式下监视网段中传输的各种数据包，并对这些数据包的内容、源地址、目的地址等进行分析和检测。如果发现入侵行为或可疑事件，人侵检测系统就会发出警报，甚至切断网络连接。它通常安装在网络上比较重要的网段，也可以说容易出问题的网段，利用网络侦听技术，通过对网络上的数据流进行捕捉、分析，以判断是否存在入侵。它以网络上传输的信息包为主要研究对象，保护网络的运行。 基于网络的IDS成本低，只需要在网络的关键点进行部署即可，其次对那些基于协议入侵的行为有很好的防范作用，并且对攻击进行实时响应，而与主机操作系统无关。但是随着网络上传送的数据包的日益庞大，对每个数据包进行捕获分析已经不太现实了，这将严重增加系统的负荷，丟包现象将逐渐增多，从而影响NIDS的性能。 　基于对上述两种IDS的分析，分布式入侵检测系统已经是现在和将来入侵检测系统应用发展的必然趋势。 分布式入侵检测系统 　典型的DIDS是管理端/传感器结构。NIDS作为传感器放置在网络的各个地方，并向中央管理平台汇报情况。攻击日志定时地传送到管理平台并保存在中央数据库中，新的攻击特征库能发送到各个传感器上。每个传感器能根据所在网络的实际需要配置不同的规则集，报警信息能发到管理平台的消息系统，用各种方式通知IDS管理员。 对DIDS来说，传感器可以使用NIDS或 HIDS，或者同时使用，而且传感器有的工作在混杂模式，有的工作在非混杂模式，然而无论什么情况，DIDS都有一个显著的特征，即分布在网络不同位置的传感器都向中央管理平台传送报警和日志信息。 ","date":"May 17, 2021","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/:14:1","tags":null,"title":"计算机数据安全复习要点总结","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%A4%8D%E4%B9%A0%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"Python + Echarts = pyecharts，记一次经济管理类的案例分析比赛。 ","date":"May 9, 2021","objectID":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/:0:0","tags":null,"title":"Pyecharts数据可视化（以ZBG财经求职力挑战赛为例）","uri":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/"},{"categories":null,"content":"赛题任务 　题目1： 分析小米公司手机业务目前所处的宏观经营环境以及产业环境。 题目2： 为小米公司制定未来三年手机业务发展策略，帮助小米公司： －　维持在低端手机市场的占有率 －　突破高端市场，实现更高的高端手机出货量 ","date":"May 9, 2021","objectID":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/:1:0","tags":null,"title":"Pyecharts数据可视化（以ZBG财经求职力挑战赛为例）","uri":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/"},{"categories":null,"content":"pyecharts自适应显示 获取浏览器窗口长宽 设置显示区域长款百分比 设置居中参数 设置自适应（根据显示区域调整刷新） 　step1. 修改.\\Lib\\site-packages\\pyecharts\\render\\templates\\ macro {%- macro render_chart_content(c) -%} \u003cdiv id=\"{{ c.chart_id }}\" class=\"chart-container\" style=\"width:95%; height:95%; margin:auto; top:30px\"\u003e\u003c/div\u003e \u003cscript\u003e var chart_{{ c.chart_id }} = echarts.init( document.getElementById('{{ c.chart_id }}'), '{{ c.theme }}', {renderer: '{{ c.renderer }}'}); {% for js in c.js_functions.items %} {{ js }} {% endfor %} var option_{{ c.chart_id }} = {{ c.json_contents }}; chart_{{ c.chart_id }}.setOption(option_{{ c.chart_id }}); {% if c._is_geo_chart %} var bmap = chart_{{ c.chart_id }}.getModel().getComponent('bmap').getBMap(); {% if c.bmap_js_functions %} {% for fn in c.bmap_js_functions.items %} {{ fn }} {% endfor %} {% endif %} {% endif %} {% if c.width.endswith('%') %} window.addEventListener('resize', function(){ chart_{{ c.chart_id }}.resize(); }) {% endif %} \u003c/script\u003e \u003cscript\u003e var x=window.innerWidth; function resizeFresh(){ if(x!=window.innerWidth) location.reload(); } \u003c/script\u003e {%- endmacro %} 　step2. 修改.\\Lib\\site-packages\\pyecharts\\render\\templates\\ simple_chart.html {% import 'macro' as macro %} \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003e{{ chart.page_title }}\u003c/title\u003e \u003cmeta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=1.0,minimum-scale=1.0,user-scalable=yes\"\u003e {{ macro.render_chart_dependencies(chart) }} \u003cstyle type=\"text/css\"\u003e html,body{ height:100%; width:100% } \u003c/style\u003e \u003c/head\u003e \u003cbody onresize=\"resizeFresh()\"\u003e {{ macro.render_chart_content(chart) }} \u003c/body\u003e \u003c/html\u003e ","date":"May 9, 2021","objectID":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/:2:0","tags":null,"title":"Pyecharts数据可视化（以ZBG财经求职力挑战赛为例）","uri":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/"},{"categories":null,"content":"可视化分析[pyecharts] 　pyecharts相关配置： !jupyter trust Visualization.ipynb import warnings warnings.filterwarnings('ignore') from pyecharts.globals import CurrentConfig, NotebookType, OnlineHostType #http://127.0.0.1:8000/assets/ CurrentConfig.ONLINE_HOST = 'https://assets.pyecharts.org/assets/' CurrentConfig.NOTEBOOK_TYPE = NotebookType.JUPYTER_LAB CurrentConfig.ONLINE_HOST ","date":"May 9, 2021","objectID":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/:3:0","tags":null,"title":"Pyecharts数据可视化（以ZBG财经求职力挑战赛为例）","uri":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/"},{"categories":null,"content":"全球手机出货量/市场份额数据可视化 　剔除部分有缺失的数据： GSMS = pd.read_csv('Global_Smartphone_Market_Share.csv').iloc[:,0:5] print('deleted:',set(GSMS.iloc[np.where(GSMS.isnull())[0],0].tolist())) GSMS = GSMS[~GSMS.Vendor.isin(GSMS.iloc[np.where(GSMS.isnull())[0],0].tolist())] display(GSMS) 　deleted: {‘Lenovo’, ‘Realme’, ‘LG’} 2018Q1 - 2021Q1 全球智能手机出货量/市场份额 出货量（按年份）柱状图 from pyecharts.charts import Bar grouped_df_year = GSMS[GSMS.Year \u003c 2021].groupby(['Vendor','Year']).agg({'Shipment_Volumes':'sum','Market_Share':'sum'}).reset_index() grouped_df_year.Shipment_Volumes = round(grouped_df_year.Shipment_Volumes,1) bar = Bar(init_opts=opts.InitOpts(theme=ThemeType.LIGHT,\\ width='1100px',\\ height='500px'))\\ .add_xaxis(grouped_df_year.Vendor.unique().tolist())\\ .set_global_opts(title_opts=opts.TitleOpts(title='2018-2020全球年出货量'),\\ legend_opts=opts.LegendOpts(type_='plain',orient='horizontal')) for y in grouped_df_year.Year.unique(): bar = bar.add_yaxis(str(y) + '年全球出货量（百万）',grouped_df_year[grouped_df_year.Year == y].Shipment_Volumes.tolist()) bar.render_notebook() Awesome-pyecharts html,body{ height:100%; width:100% } var chart_aaf3926ed4944c62aeb73f2b1424ec8e = echarts.init( document.getElementById('aaf3926ed4944c62aeb73f2b1424ec8e'), 'light', {renderer: 'canvas'}); var option_aaf3926ed4944c62aeb73f2b1424ec8e = { \"animation\": true, \"animationThreshold\": 2000, \"animationDuration\": 1000, \"animationEasing\": \"cubicOut\", \"animationDelay\": 0, \"animationDurationUpdate\": 300, \"animationEasingUpdate\": \"cubicOut\", \"animationDelayUpdate\": 0, \"series\": [ { \"type\": \"bar\", \"name\": \"2018\\u5e74\\u5168\\u7403\\u51fa\\u8d27\\u91cf\\uff08\\u767e\\u4e07\\uff09\", \"legendHoverLink\": true, \"data\": [ 206.3, 205.2, 119.0, 291.8, 102.4, 119.0 ], \"showBackground\": false, \"barMinHeight\": 0, \"barCategoryGap\": \"20%\", \"barGap\": \"30%\", \"large\": false, \"largeThreshold\": 400, \"seriesLayoutBy\": \"column\", \"datasetIndex\": 0, \"clip\": true, \"zlevel\": 0, \"z\": 2, \"label\": { \"show\": true, \"position\": \"top\", \"margin\": 8 } }, { \"type\": \"bar\", \"name\": \"2019\\u5e74\\u5168\\u7403\\u51fa\\u8d27\\u91cf\\uff08\\u767e\\u4e07\\uff09\", \"legendHoverLink\": true, \"data\": [ 195.6, 238.7, 120.0, 296.9, 113.7, 124.7 ], \"showBackground\": false, \"barMinHeight\": 0, \"barCategoryGap\": \"20%\", \"barGap\": \"30%\", \"large\": false, \"largeThreshold\": 400, \"seriesLayoutBy\": \"column\", \"datasetIndex\": 0, \"clip\": true, \"zlevel\": 0, \"z\": 2, \"label\": { \"show\": true, \"position\": \"top\", \"margin\": 8 } }, { \"type\": \"bar\", \"name\": \"2020\\u5e74\\u5168\\u7403\\u51fa\\u8d27\\u91cf\\uff08\\u767e\\u4e07\\uff09\", \"legendHoverLink\": true, \"data\": [ 201.1, 187.7, 111.8, 255.7, 108.5, 145.4 ], \"showBackground\": false, \"barMinHeight\": 0, \"barCategoryGap\": \"20%\", \"barGap\": \"30%\", \"large\": false, \"largeThreshold\": 400, \"seriesLayoutBy\": \"column\", \"datasetIndex\": 0, \"clip\": true, \"zlevel\": 0, \"z\": 2, \"label\": { \"show\": true, \"position\": \"top\", \"margin\": 8 } } ], \"legend\": [ { \"data\": [ \"2018\\u5e74\\u5168\\u7403\\u51fa\\u8d27\\u91cf\\uff08\\u767e\\u4e07\\uff09\", \"2019\\u5e74\\u5168\\u7403\\u51fa\\u8d27\\u91cf\\uff08\\u767e\\u4e07\\uff09\", \"2020\\u5e74\\u5168\\u7403\\u51fa\\u8d27\\u91cf\\uff08\\u767e\\u4e07\\uff09\" ], \"selected\": { \"2018\\u5e74\\u5168\\u7403\\u51fa\\u8d27\\u91cf\\uff08\\u767e\\u4e07\\uff09\": true, \"2019\\u5e74\\u5168\\u7403\\u51fa\\u8d27\\u91cf\\uff08\\u767e\\u4e07\\uff09\": true, \"2020\\u5e74\\u5168\\u7403\\u51fa\\u8d27\\u91cf\\uff08\\u767e\\u4e07\\uff09\": true }, \"type\": \"plain\", \"show\": true, \"orient\": \"horizontal\", \"padding\": 5, \"itemGap\": 10, \"itemWidth\": 25, \"itemHeight\": 14 } ], \"tooltip\": { \"show\": true, \"trigger\": \"item\", \"triggerOn\": \"mousemove|click\", \"axisPointer\": { \"type\": \"line\" }, \"showContent\": true, \"alwaysShowContent\": false, \"showDelay\": 0, \"hideDelay\": 100, \"textStyle\": { \"fontSize\": 14 }, \"borderWidth\": 0, \"padding\": 5 }, \"xAxis\": [ { \"show\": true, \"scale\": false, \"nameLocation\": \"end\", \"nameGap\": 15, \"gridIndex\": 0, \"inverse\": false, \"offset\": 0, \"splitNumber\": 5, \"minInterval\": 0, \"splitLine\": { \"show\": false, \"lineStyle\": { \"show\": true, \"width\": 1, \"opacity\": 1, \"curveness\": 0, \"type\": \"solid\" } }, \"d","date":"May 9, 2021","objectID":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/:3:1","tags":null,"title":"Pyecharts数据可视化（以ZBG财经求职力挑战赛为例）","uri":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/"},{"categories":null,"content":"国内手机市场份额数据可视化 CSMS = pd.read_csv('China_Smartphone_Market_Share.csv').iloc[:,0:4] CSMS.Market_Share = CSMS.Market_Share.str[:-1].astype(int) 2017Q1 - 2021Q1 国内智能手机市场份额 市场份额（按季度）折线图 from pyecharts.charts import Line line = Line(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width='1200px', height='550px'))\\ .add_xaxis((CSMS.Year.astype(str) + CSMS.Quarterly.astype(str)).drop_duplicates(keep='first').tolist())\\ .set_global_opts(title_opts=opts.TitleOpts(title=''),\\ legend_opts=opts.LegendOpts(type_='scroll',pos_top=10, orient='horizontal'))#horizontal vertical for v in grouped_df_year.Vendor.unique(): line = line.add_yaxis(str(v) + '季度全球份额（%）',np.round(100 * CSMS[CSMS.Vendor == v].Market_Share, 0).tolist()) line.render_notebook() Awesome-pyecharts html,body{ height:100%; width:100% } var chart_622d0adc2696444983cb91188184e257 = echarts.init( document.getElementById('622d0adc2696444983cb91188184e257'), 'light', {renderer: 'canvas'}); var option_622d0adc2696444983cb91188184e257 = { \"animation\": true, \"animationThreshold\": 2000, \"animationDuration\": 1000, \"animationEasing\": \"cubicOut\", \"animationDelay\": 0, \"animationDurationUpdate\": 300, \"animationEasingUpdate\": \"cubicOut\", \"animationDelayUpdate\": 0, \"series\": [ { \"type\": \"line\", \"name\": \"Apple\\u5b63\\u5ea6\\u5168\\u7403\\u4efd\\u989d\\uff08%\\uff09\", \"connectNulls\": false, \"symbolSize\": 4, \"showSymbol\": true, \"smooth\": false, \"clip\": true, \"step\": false, \"data\": [ [ \"2017Q1\", 10 ], [ \"2017Q2\", 8 ], [ \"2017Q3\", 10 ], [ \"2017Q4\", 15 ], [ \"2018Q1\", 13 ], [ \"2018Q2\", 8 ], [ \"2018Q3\", 9 ], [ \"2018Q4\", 12 ], [ \"2019Q1\", 9 ], [ \"2019Q2\", 6 ], [ \"2019Q3\", 8 ], [ \"2019Q4\", 14 ], [ \"2020Q1\", 9 ], [ \"2020Q2\", 8 ], [ \"2020Q3\", 8 ], [ \"2020Q4\", 8 ], [ \"2021Q1\", 13 ] ], \"hoverAnimation\": true, \"label\": { \"show\": true, \"position\": \"top\", \"margin\": 8 }, \"lineStyle\": { \"show\": true, \"width\": 1, \"opacity\": 1, \"curveness\": 0, \"type\": \"solid\" }, \"areaStyle\": { \"opacity\": 0 }, \"zlevel\": 0, \"z\": 0 }, { \"type\": \"line\", \"name\": \"Huawei\\u5b63\\u5ea6\\u5168\\u7403\\u4efd\\u989d\\uff08%\\uff09\", \"connectNulls\": false, \"symbolSize\": 4, \"showSymbol\": true, \"smooth\": false, \"clip\": true, \"step\": false, \"data\": [ [ \"2017Q1\", 20 ], [ \"2017Q2\", 20 ], [ \"2017Q3\", 19 ], [ \"2017Q4\", 20 ], [ \"2018Q1\", 22 ], [ \"2018Q2\", 26 ], [ \"2018Q3\", 23 ], [ \"2018Q4\", 28 ], [ \"2019Q1\", 34 ], [ \"2019Q2\", 35 ], [ \"2019Q3\", 40 ], [ \"2019Q4\", 35 ], [ \"2020Q1\", 41 ], [ \"2020Q2\", 46 ], [ \"2020Q3\", 43 ], [ \"2020Q4\", 30 ], [ \"2021Q1\", 16 ] ], \"hoverAnimation\": true, \"label\": { \"show\": true, \"position\": \"top\", \"margin\": 8 }, \"lineStyle\": { \"show\": true, \"width\": 1, \"opacity\": 1, \"curveness\": 0, \"type\": \"solid\" }, \"areaStyle\": { \"opacity\": 0 }, \"zlevel\": 0, \"z\": 0 }, { \"type\": \"line\", \"name\": \"Oppo\\u5b63\\u5ea6\\u5168\\u7403\\u4efd\\u989d\\uff08%\\uff09\", \"connectNulls\": false, \"symbolSize\": 4, \"showSymbol\": true, \"smooth\": false, \"clip\": true, \"step\": false, \"data\": [ [ \"2017Q1\", 17 ], [ \"2017Q2\", 19 ], [ \"2017Q3\", 19 ], [ \"2017Q4\", 17 ], [ \"2018Q1\", 18 ], [ \"2018Q2\", 18 ], [ \"2018Q3\", 21 ], [ \"2018Q4\", 19 ], [ \"2019Q1\", 18 ], [ \"2019Q2\", 19 ], [ \"2019Q3\", 18 ], [ \"2019Q4\", 16 ], [ \"2020Q1\", 15 ], [ \"2020Q2\", 16 ], [ \"2020Q3\", 16 ], [ \"2020Q4\", 16 ], [ \"2021Q1\", 22 ] ], \"hoverAnimation\": true, \"label\": { \"show\": true, \"position\": \"top\", \"margin\": 8 }, \"lineStyle\": { \"show\": true, \"width\": 1, \"opacity\": 1, \"curveness\": 0, \"type\": \"solid\" }, \"areaStyle\": { \"opacity\": 0 }, \"zlevel\": 0, \"z\": 0 }, { \"type\": \"line\", \"name\": \"Samsung\\u5b63\\u5ea6\\u5168\\u7403\\u4efd\\u989d\\uff08%\\uff09\", \"connectNulls\": false, \"symbolSize\": 4, \"showSymbol\": true, \"smooth\": false, \"clip\": true, \"step\": false, \"data\": [], \"hoverAnimation\": true, \"label\": { \"show\": true, \"position\": \"top\", \"margin\": 8 }, \"lineStyle\": { \"show\": true, \"width\": 1, \"opacity\": 1, \"curveness\": 0, \"type\": \"solid\" }, \"areaStyle\": { \"opacity\": 0 }, \"zlevel\": 0, \"z\": 0 }, { \"type\": \"line\", \"name\": \"Vivo\\u5b63\\u5ea6\\u5168\\u7403\\u4efd\\u989d\\uff08%\\uff09\", \"connectNulls\": false, \"symbolSize\": 4, \"showSymbol\": true, \"smo","date":"May 9, 2021","objectID":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/:3:2","tags":null,"title":"Pyecharts数据可视化（以ZBG财经求职力挑战赛为例）","uri":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/"},{"categories":null,"content":"小米公司财报情况 FR = pd.read_csv('Financial_Report_Xiaomi.csv') FR = FR.sort_values(by='年度') FR ","date":"May 9, 2021","objectID":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/:3:3","tags":null,"title":"Pyecharts数据可视化（以ZBG财经求职力挑战赛为例）","uri":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/"},{"categories":null,"content":"全球市场Top国家/地区可视化 Global_top5 = pd.read_csv('Global_Top5.csv') from pyecharts.charts import Map, Geo value = Global_top5['rank'].tolist() attr = Global_top5['country'].tolist() map = Map( init_opts=opts.InitOpts(width=\"1900px\", height=\"900px\", bg_color=\"#ADD8E6\", page_title=\"-\",theme=ThemeType.LIGHT)) map.add(\"Rank\",[list(z) for z in zip(attr, value)],is_map_symbol_show=False, maptype=\"world\",label_opts=opts.LabelOpts(is_show=False),) map.set_global_opts(title_opts = opts.TitleOpts(title='全球销量Top5国家和地区（不完全统计，至2021/05）'), legend_opts=opts.LegendOpts(is_show=False), visualmap_opts = opts.VisualMapOpts(min_=1,max_=5,range_color=map.colors)) map.render('map.html') - html,body{ height:100%; width:100% } var chart_738b6258e1184f95a31b7f9acb9cf69a = echarts.init( document.getElementById('738b6258e1184f95a31b7f9acb9cf69a'), 'light', {renderer: 'canvas'}); var option_738b6258e1184f95a31b7f9acb9cf69a = { \"backgroundColor\": \"#ADD8E6\", \"animation\": true, \"animationThreshold\": 2000, \"animationDuration\": 1000, \"animationEasing\": \"cubicOut\", \"animationDelay\": 0, \"animationDurationUpdate\": 300, \"animationEasingUpdate\": \"cubicOut\", \"animationDelayUpdate\": 0, \"series\": [ { \"type\": \"map\", \"name\": \"Rank\", \"label\": { \"show\": false, \"position\": \"top\", \"margin\": 8 }, \"mapType\": \"world\", \"data\": [ { \"name\": \"Belarus\", \"value\": 1 }, { \"name\": \"Greece\", \"value\": 1 }, { \"name\": \"India\", \"value\": 1 }, { \"name\": \"Myanmar\", \"value\": 1 }, { \"name\": \"Poland\", \"value\": 1 }, { \"name\": \"Spain\", \"value\": 1 }, { \"name\": \"Ukraine\", \"value\": 1 }, { \"name\": \"Croatia\", \"value\": 1 }, { \"name\": \"France\", \"value\": 2 }, { \"name\": \"Latvia\", \"value\": 2 }, { \"name\": \"Nepal\", \"value\": 1 }, { \"name\": \"Russia\", \"value\": 1 }, { \"name\": \"Slovakia\", \"value\": 2 }, { \"name\": \"Austria\", \"value\": 3 }, { \"name\": \"Cambodia\", \"value\": 3 }, { \"name\": \"Hungary\", \"value\": 3 }, { \"name\": \"Israel\", \"value\": 3 }, { \"name\": \"Laos\", \"value\": 3 }, { \"name\": \"Lithuania\", \"value\": 3 }, { \"name\": \"Nigeria\", \"value\": 3 }, { \"name\": \"Peru\", \"value\": 3 }, { \"name\": \"Portugal\", \"value\": 3 }, { \"name\": \"Qatar\", \"value\": 3 }, { \"name\": \"Sweden\", \"value\": 3 }, { \"name\": \"Turkey\", \"value\": 3 }, { \"name\": \"China\", \"value\": 4 }, { \"name\": \"Colombia\", \"value\": 4 }, { \"name\": \"Czech Republic\", \"value\": 4 }, { \"name\": \"Egypt\", \"value\": 4 }, { \"name\": \"Germany\", \"value\": 4 }, { \"name\": \"Indonesia\", \"value\": 4 }, { \"name\": \"Italy\", \"value\": 4 }, { \"name\": \"Kenya\", \"value\": 4 }, { \"name\": \"Kuwait\", \"value\": 4 }, { \"name\": \"Netherlands\", \"value\": 4 }, { \"name\": \"Romania\", \"value\": 4 }, { \"name\": \"Saudi Arabia\", \"value\": 4 }, { \"name\": \"Slovenia\", \"value\": 4 }, { \"name\": \"South Korea\", \"value\": 4 }, { \"name\": \"United Arab Emirates\", \"value\": 4 }, { \"name\": \"Brazil\", \"value\": 5 }, { \"name\": \"Chile\", \"value\": 5 }, { \"name\": \"Estonia\", \"value\": 5 }, { \"name\": \"Malaysia\", \"value\": 5 }, { \"name\": \"Mexico\", \"value\": 5 }, { \"name\": \"Singapore\", \"value\": 5 }, { \"name\": \"Sri Lanka\", \"value\": 5 }, { \"name\": \"Switzerland\", \"value\": 5 } ], \"roam\": true, \"aspectScale\": 0.75, \"nameProperty\": \"name\", \"selectedMode\": false, \"zoom\": 1, \"mapValueCalculation\": \"sum\", \"showLegendSymbol\": false, \"emphasis\": {} } ], \"legend\": [ { \"data\": [ \"Rank\" ], \"selected\": { \"Rank\": true }, \"show\": false, \"padding\": 5, \"itemGap\": 10, \"itemWidth\": 25, \"itemHeight\": 14 } ], \"tooltip\": { \"show\": true, \"trigger\": \"item\", \"triggerOn\": \"mousemove|click\", \"axisPointer\": { \"type\": \"line\" }, \"showContent\": true, \"alwaysShowContent\": false, \"showDelay\": 0, \"hideDelay\": 100, \"textStyle\": { \"fontSize\": 14 }, \"borderWidth\": 0, \"padding\": 5 }, \"title\": [ { \"text\": \"\\u5168\\u7403\\u9500\\u91cfTop5\\u56fd\\u5bb6\\u548c\\u5730\\u533a\\uff08\\u4e0d\\u5b8c\\u5168\\u7edf\\u8ba1\\uff0c\\u81f32021/05\\uff09\", \"padding\": 5, \"itemGap\": 10 } ], \"visualMap\": { \"show\": true, \"type\": \"continuous\", \"min\": 1, \"max\": 5, \"inRange\": { \"color\": [ \"#c23531\", \"#2f4554\", \"#61a0a8\", \"#d48265\", \"#749f83\", \"#ca8622\", \"#bda29a\", \"#6e7074\", \"#546570\", \"#c4ccd3\", \"#f05b72\", \"#ef5b9c\", \"#f47920\", \"#905a3d\", \"#f","date":"May 9, 2021","objectID":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/:3:4","tags":null,"title":"Pyecharts数据可视化（以ZBG财经求职力挑战赛为例）","uri":"/pyecharts%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A5zbg%E8%B4%A2%E7%BB%8F%E6%B1%82%E8%81%8C%E5%8A%9B%E6%8C%91%E6%88%98%E8%B5%9B%E4%B8%BA%E4%BE%8B/"},{"categories":null,"content":"性能优化赛题，k-d树方案。初赛Rank28，复赛Rank16。 ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:0:0","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"赛题介绍 ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:1:0","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"赛题任务 　通过筛选个人基本信息、个人防疫信息、亮码位置、亮码时间等数据，判定直接密接人员，间接密接人员，判定疫情传播风险等级，辅助决策疫情防控力度。 ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:1:1","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"评分标准 　准确率分数使用macro F1计算。 　直接密接人员：与确诊患者亮码时间差的绝对值在5分钟内，距离在10米以内。 间接密接人员：与直接密接人员的亮码时间差的绝对值在5分钟内，距离在10米以内。 如果既是直接密接人员又是间接密接人员，统一归类为直接密接人员。 　距离计算参考函数如下： from math import radians, cos, sin, asin, sqrt def geodistance(lng1, lat1, lng2, lat2): lng1, lat1, lng2, lat2 = map(radians, [float(lng1), float(lat1), float(lng2), float(lat2)]) dlon = lng2-lng1 dlat = lat2-lat1 a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2 distance = 2 * asin(sqrt(a)) * 6371.393 * 1000 distance = round(distance, 5) return distance ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:1:2","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"数据集描述 　个人轨迹数据（df_travel.csv）： id：String，人员唯一ID usetime：Date，亮码时间 lng：Float，亮码位置经度（小数点5位，GCJ02坐标系） lat：Float，亮码位置纬度（小数点5位，GCJ02坐标系） 　确诊患者亮码记录（confirm.csv）： 亮码时间：Date，亮码时间； lng：Float，亮码位置经度（小数点5位，GCJ02坐标系） lat：Float，亮码位置纬度（小数点5位，GCJ02坐标系） 备注：String，确诊患者的具体行为 只有一名确诊患者 ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:1:3","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"解决思路 　整体上来看，方案比较常规，决赛还未开始，对于这题有没有一些特殊的方法，还需要等待答辩结束。 位于Rank5的江离重楼大佬在复赛结束后就分享了自己的代码和思路 为每条轨迹记录添加唯一索引，先根据确诊人员信息和条件判断出直接密接的记录，根据这些记录筛选每个id在接触时间以后的所有记录，最后再根据这些记录和条件判断间接密接人员，先初筛，后细筛。 ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:2:0","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"直接密接人员 　轨迹数据的规模为200万+条，确诊人员记录约为50条，规模并不大，所以直接考虑计算所有点对之间的Euclidean Distance / CityBlock Distance，筛选出亮码时间差在300秒以内以及经纬度距离在0.00025内的点对，再根据经纬度计算精确距离差，筛选出直接密接人员。 在复赛阶段对这个方案又做了一些小优化，在线下环境成绩有所提升。由于确诊人员记录数量极少，所以根据这些点的经纬度及时间可以先大幅缩小搜索范围，即先使用集合运算挑选出处在可能范围内的人员轨迹记录，再做如上操作，代码如下。 def gen_idx_direct(candidate, target): set_target_time = set([j for i in target.time for j in range(i - 300,i + 301)]) set_target_lng = set(np.around([j for i in target.lng for j in np.arange(i - 0.00025,i + 0.00025,0.00001)], 5)) set_target_lat = set(np.around([j for i in target.lat for j in np.arange(i - 0.00025,i + 0.00025,0.00001)], 5)) candidate_ = candidate[( candidate.time.isin(list(set_target_time))) \u0026 ( np.round(candidate.lng, 5).isin(list(set_target_lng))) \u0026 ( np.round(candidate.lat, 5).isin(list(set_target_lat)))].reset_index(drop=True) time_diff = np.where( abs(cdist(candidate_[['time','temp']], target[['time','temp']], metric='cityblock')) \u003c= 300, 1, 0) distance = np.where( abs(cdist(candidate_[['lng', 'lat']], target[['lng', 'lat']])) \u003c= 0.00025, 1, 0) result_mat = time_diff * distance c_idx = np.where(result_mat == 1)[0] t_idx = np.where(result_mat == 1)[1] distance = geodistance(candidate_.iloc[c_idx, 3], candidate_.iloc[c_idx, 2], target.iloc[t_idx, 2], target.iloc[t_idx, 1]) c_result = c_idx[np.where(distance \u003c= 10)[0]] # t_result = t_idx[np.where(distance \u003c= 10)[0]] return candidate_.loc[list(set(c_result)), 'idx'].tolist() 　对距离计算函数进行了修改，使用numpy，改为矩阵并行计算。 import numexpr as ne def geodistance(lng1, lat1, lng2, lat2): lng1 = np.radians(np.array(lng1)) lat1 = np.radians(np.array(lat1)) lng2 = np.radians(np.array(lng2)) lat2 = np.radians(np.array(lat2)) return np.round(ne.evaluate(\"2 * arcsin(sqrt(sin((lat2 - lat1) / 2) ** 2 + cos(lat1) * cos(lat2) * sin((lng2 - lng1) / 2) ** 2)) * 6371.393 * 1000\"), 5) ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:2:1","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"间接密接人员 　关于间接密接人员的搜索，尝试了两种方案，一种是使用KD树，另一种是将经纬度以一定的尺度网格化（0.0001），对于直接密接人员的记录，搜索其附近的九个格子。 我所使用的是KD树的方案，然而比赛结束后看到Rank5 江离.重楼大佬在群里的分享，也是使用的网格化搜索的方案，不过语言方面使用的是C++，这才意识到针对计算密集型程序Python和C++巨大的效率差距，初赛阶段看到以Python作为入口语言，就默认用Python实现了，复赛阶段也一直没向这个方向进行优化，最后只排到了Rank16，这也是做这次比赛的遗憾之处吧~ K-D Tree 　Scipy中提供了KDTree的接口，scipy.spatial.cKDTree，其底层使用C语言实现，效率更高。 def gen_idx_indirect_kd(candidate, target): candidate.reset_index(inplace=True, drop=True) target.reset_index(inplace=True, drop=True) kd_time_diff = cKDTree(candidate[['time']]) time_diff_idx = kd_time_diff.query_ball_point(target[['time']].values.tolist(), r = 300, p = 1) kd_distance = cKDTree(candidate[['lng','lat']]) distance_idx = kd_distance.query_ball_point(target[['lng','lat']].values.tolist(), r = 0.00025, p = 2) intersection = [] for i in range(len(distance_idx)): intersection.append(list(set(distance_idx[i]).intersection(set(time_diff_idx[i])))) c_idx = [] t_idx = [] for i in range(len(intersection)): c_idx.extend(intersection[i]) t_idx.extend([i] * len(intersection[i])) distance = geodistance(candidate.iloc[c_idx, 3], candidate.iloc[c_idx, 2], target.iloc[t_idx, 3], target.iloc[t_idx, 2]) c_result = [c_idx[i] for i in (np.where((distance \u003c= 10))[0]).tolist()] return candidate.iloc[list(set(c_result)), 0].tolist() 网格化搜索 　网格化搜索实现起来相对比较简单，其思想类似于GeoHash，即将二位的经纬度坐标点映射到一维，但GeoHash在这里并不适合，一方面是效率过低，另一方面，和直接将经纬度点映射到0,1,…,n的效果相同。 ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:2:2","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"关于效率 　复赛结束时，线上成绩约为30s，并不算优秀。 除计算外，I/O方面的优化也是本题的上分点之一。 关于效率的计算，比较奇怪的是，线上评测成绩的抖动幅度似乎不小，我个人第一次和第二次提交的代码几乎相同，但线上成绩提升了近30%，除此之外，主办方所的线上环境只开放了CPU的一个核心，但经过实验，多进程对该题是work的，能带来大概25%的提升。但如果时间效率足够高的话，多进程显然就不太合适了，进程创建和切换所带来的开销已经不能忽略不计了。 ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:3:0","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"关于准确率 　初赛使用该方案的macro F1为1.0，但是对于复赛阶段的数据为0.999179，针对复赛的数据如何达到1.0还需要等决赛答辩后学习思路。 补充：经验证，将密接的亮码时间判定从300秒改为310秒即可达到1.0的准确率，逻辑比较迷。 不过这场比赛在密接的判定上确实比较模糊，有些复杂情况难以判定，主办方在一些问题上也没有给出明确的答复，需要多次尝试来进行验证。 ","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:4:0","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"个人实现完整代码 　由纯Python实现，和C/C++等语言的实现相比，时间效率并不算高，仅供参考。 import pandas as pd import numpy as np from datetime import datetime from scipy.spatial.distance import cdist from scipy.spatial import cKDTree import numexpr as ne import os import multiprocessing import sys def geodistance(lng1, lat1, lng2, lat2): lng1 = np.radians(np.array(lng1)) lat1 = np.radians(np.array(lat1)) lng2 = np.radians(np.array(lng2)) lat2 = np.radians(np.array(lat2)) return np.round(ne.evaluate(\"2 * arcsin(sqrt(sin((lat2 - lat1) / 2) ** 2 + cos(lat1) * cos(lat2) * sin((lng2 - lng1) / 2) ** 2)) * 6371.393 * 1000\"), 5) def gen_idx_direct(candidate, target): set_target_time = set([j for i in target.time for j in range(i - 300,i + 301)]) set_target_lng = set(np.around([j for i in target.lng for j in np.arange(i - 0.00025,i + 0.00025,0.00001)], 5)) set_target_lat = set(np.around([j for i in target.lat for j in np.arange(i - 0.00025,i + 0.00025,0.00001)], 5)) candidate_ = candidate[( candidate.time.isin(list(set_target_time))) \u0026 ( np.round(candidate.lng, 5).isin(list(set_target_lng))) \u0026 ( np.round(candidate.lat, 5).isin(list(set_target_lat)))].reset_index(drop=True) time_diff = np.where( abs(cdist(candidate_[['time','temp']], target[['time','temp']], metric='cityblock')) \u003c= 300, 1, 0) distance = np.where( abs(cdist(candidate_[['lng', 'lat']], target[['lng', 'lat']])) \u003c= 0.00025, 1, 0) result_mat = time_diff * distance c_idx = np.where(result_mat == 1)[0] t_idx = np.where(result_mat == 1)[1] distance = geodistance(candidate_.iloc[c_idx, 3], candidate_.iloc[c_idx, 2], target.iloc[t_idx, 2], target.iloc[t_idx, 1]) c_result = c_idx[np.where(distance \u003c= 10)[0]] t_result = t_idx[np.where(distance \u003c= 10)[0]] return candidate_.iloc[list(set(c_result)), 4].tolist(), pd.concat([candidate_.iloc[c_result,[0,6]].reset_index(drop=True), (target.iloc[t_result,6]).reset_index(drop=True)],axis=1,ignore_index=True) def gen_idx_indirect_kd(candidate, target): candidate.reset_index(inplace=True, drop=True) target.reset_index(inplace=True, drop=True) kd_time_diff = cKDTree(candidate[['time']]) time_diff_idx = kd_time_diff.query_ball_point(target[['time']].values.tolist(), r = 300, p = 1) kd_distance = cKDTree(candidate[['lng','lat']]) distance_idx = kd_distance.query_ball_point(target[['lng','lat']].values.tolist(), r = 0.00025, p = 1) intersection = [] for i in range(len(distance_idx)): intersection.append(list(set(distance_idx[i]).intersection(set(time_diff_idx[i])))) c_idx = [] t_idx = [] for i in range(len(intersection)): c_idx.extend(intersection[i]) t_idx.extend([i] * len(intersection[i])) distance = geodistance(candidate.iloc[c_idx, 3], candidate.iloc[c_idx, 2], target.iloc[t_idx, 3], target.iloc[t_idx, 2]) c_result = [c_idx[i] for i in (np.where((distance \u003c= 10))[0]).tolist()] return candidate.iloc[list(set(c_result)), 0].tolist() def main(dirname, savePath): confirmPath = os.path.join(dirname, \"confirm.csv\") travelPath = os.path.join(dirname, \"df_travel.csv\") confirmed = pd.read_csv(confirmPath) df_travel = pd.read_csv(travelPath) confirmed['亮码时间'] = pd.to_datetime(confirmed['亮码时间'],format='%Y-%m-%d%H:%M:%S') df_travel['usetime'] = pd.to_datetime(df_travel['usetime'],format='%Y-%m-%d%H:%M:%S') df_travel_length = len(df_travel) confirmed['idx'] = range(len(confirmed)) df_travel['idx'] = range(df_travel_length) confirmed['temp'] = 0 df_travel['temp'] = 0 confirmed['time'] = (pd.to_timedelta(confirmed['亮码时间'] - datetime(2020, 10, 30)).dt.total_seconds()).astype(int) df_travel['time'] = (pd.to_timedelta(df_travel['usetime'] - datetime(2020, 10, 30)).dt.total_seconds()).astype(int) direct_idx, df_direct_min_time_ = gen_idx_direct(df_travel, confirmed) df_direct_min_time_.columns = ['id','ctime_direct', 'ctime_confirm'] df_direct = df_travel[df_travel['idx'].isin(direct_idx)] df_travel = pd.merge(df_travel, df_direct_min_time_.groupby('id').agg({'ctime_direct':min}), on='id', how='left') df_travel.ctime_direct.fillna(-1,inplace=True) df_travel['direct'] = 0 df_travel.loc[(df_travel['t","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:5:0","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"Rank5实现（江离.重楼） 　转自群聊。 #include \u003ccstdio\u003e#include \u003ccmath\u003e#include \u003calgorithm\u003e#include \u003csys/mman.h\u003e#include \u003cunistd.h\u003e#include \u003cfcntl.h\u003e#include \u003ccstring\u003e #define MAX 15000005 using namespace std; double radians(double a) { return a / 180.0 * 3.141592653589793; } double sqr(double a) { return a * a; } int touchCnt = 0; struct MyHashSet { struct Node { long long value; int nxt; } myHash[MAX]; const int MOD = (1 \u003c\u003c 19) - 1; int myHashCnt = MOD + 1; void insert(long long value) { int now = (value \u0026 MOD); while (myHash[now].nxt) { if (myHash[now].value == value) { return; } now = myHash[now].nxt; } myHash[now].value = value; myHash[now].nxt = myHashCnt++; } bool has(long long value) { int now = (value \u0026 MOD); while (myHash[now].nxt) { if (myHash[now].value == value) { return true; } now = myHash[now].nxt; } return false; } } idHashSet; struct MyHashMap { struct Node { long long value; int realValue; int nxt; } myHash[MAX]; const int MOD = (1 \u003c\u003c 16) - 1; int myHashCnt = MOD + 1; void insert(long long value, int realValue) { int now = (value \u0026 MOD); while (myHash[now].nxt) { if (myHash[now].value == value) { myHash[now].realValue = realValue; return; } now = myHash[now].nxt; } myHash[now].realValue = realValue; myHash[now].value = value; myHash[now].nxt = myHashCnt++; } int find(long long value) { int now = (value \u0026 MOD); while (myHash[now].nxt) { if (myHash[now].value == value) { return myHash[now].realValue; } now = myHash[now].nxt; } return -1; } } startTime, level; struct Record { char *pos; long long idHash = 0; int time; int lat, lng; bool isxg = false; bool operator \u003c (const Record \u0026b) { return time \u003c b.time; } bool IsTouch(const Record \u0026b) { touchCnt++; if (abs(lng - b.lng) \u003e 50 || fabs(lat - b.lat) \u003e 50) { return false; } double lng1 = radians((double)lng / 100000); double lat1 = radians((double)lat / 100000); double lng2 = radians((double)b.lng / 100000); double lat2 = radians((double)b.lat / 100000); double dlon = lng2 - lng1; double dlat = lat2 - lat1; double a = sqr(sin(dlat / 2)) + cos(lat1) * cos(lat2) * sqr(sin(dlon / 2)); double distance = 2 * asin(sqrt(a)) * 6371.393 * 1000; return distance \u003c 10 + 1e-9; } double getDist(const Record \u0026b) { double lng1 = radians((double)lng / 100000); double lat1 = radians((double)lat / 100000); double lng2 = radians((double)b.lng / 100000); double lat2 = radians((double)b.lat / 100000); double dlon = lng2 - lng1; double dlat = lat2 - lat1; double a = sqr(sin(dlat / 2)) + cos(lat1) * cos(lat2) * sqr(sin(dlon / 2)); double distance = 2 * asin(sqrt(a)) * 6371.393 * 1000; return distance; } }; struct MyBucket { struct Node { int x, y; }; Node nodes[MAX]; int cnt = 2000000; void insert(int key, int id) { cnt++; nodes[cnt].x = id; if (nodes[key].x == 0) { nodes[key].x = nodes[key].y = cnt; } else { nodes[nodes[key].y].y = cnt; nodes[key].y = cnt; } } void pop(int key) { nodes[key].x = nodes[nodes[key].x].y; } } /*latids, lngids*/ ids; Record temp[MAX], records[MAX]; int recordSize = 0; const int MAXY = 3000; int days[MAXY][15]; void InitDays() { int cur = 0; for (int y = 2000; y \u003c MAXY; y++) { for (int m = 1; m \u003c= 12; m++) { days[y][m] = cur; if (m == 1 || m == 3 || m == 5 || m == 7 || m == 8 || m == 10 || m == 12) { cur += 31; } else if (m == 4 || m == 6 || m == 9 || m == 11) { cur += 30; } else { if ((y % 100 != 0 \u0026\u0026 y % 4 == 0) || (y % 400 == 0)) { cur += 29; } else { cur += 28; } } } } } int gettime(struct tm \u0026tm) { return (((days[tm.tm_year][tm.tm_mon] + tm.tm_mday) * 24 + tm.tm_hour) * 60 + tm.tm_min) * 60 + tm.tm_sec; } char *buffer; void ReadRecords(Record* records, Record *result, char *recordFile, char *travelFile) { auto sst = clock(); //records.clear(); /*Record cur; FILE *fi = fopen(\"../data/record\", \"r\"); while (cur.ReadRecord(fi)) { records.push_back(cur); } fclose(fi); fi = fopen(\"../data/travel\", \"r\"); while (cur.ReadTravel(fi)) { records.push_back(cur); level[cur.id] = 0; } fclose(fi);*/ /*FILE *fi = fopen(recordFile, \"rb\"); fseek(fi, 0L, SEEK_END); int len = ftell(fi); fse","date":"April 3, 2021","objectID":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/:6:0","tags":null,"title":"山东省第二届数据应用创新创业大赛——疫情密切接触人员追踪","uri":"/%E5%B1%B1%E4%B8%9C%E7%9C%81%E7%AC%AC%E4%BA%8C%E5%B1%8A%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E5%A4%A7%E8%B5%9B%E7%96%AB%E6%83%85%E5%AF%86%E5%88%87%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%91%98%E8%BF%BD%E8%B8%AA/"},{"categories":null,"content":"NLP赛题，政务表格文件分类。初赛Rank13，复赛Rank33（20+）。 首次接触NLP，本题上分重在数据的正确提取与预处理。 ","date":"December 3, 2020","objectID":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/:0:0","tags":null,"title":"中移集成（雄安产业研究院）首届OneCity编程大赛","uri":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/"},{"categories":null,"content":"赛题任务 　选手需要建立模型，针对政务表格文件实现自动化分类。允许使用一些常见的开源预训练模型，如bert。 数据智能分类按照行业领域，将政务数据分为以下20个基础大类，分别是：生态环境、资源能源、信息产业、医疗卫生、文化休闲、财税金融、经济管理、教育科技、交通运输、工业、农业畜牧业、政法监察、城乡建设、商业贸易、旅游服务、气象水文测绘地震地理、外交外事、文秘行政、民政社区、劳动人事。 ","date":"December 3, 2020","objectID":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/:1:0","tags":null,"title":"中移集成（雄安产业研究院）首届OneCity编程大赛","uri":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/"},{"categories":null,"content":"初赛方案 　参赛时赛事日程已过半，提交次数较少，仅考虑了一些简单的方案。 初赛阶段，文件标题基本完整，首先仅使用标题进行训练，预训练模型使用了RoBERTa-wwm-ext，使用五折CV。 读取文件content后，针对content单独训练bert，最后将title和content的raw_output按0.7、0.3加权平均，线上accuracy 0.985，Rank 13。 ","date":"December 3, 2020","objectID":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/:2:0","tags":null,"title":"中移集成（雄安产业研究院）首届OneCity编程大赛","uri":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/"},{"categories":null,"content":"决赛方案 　舍弃初赛方案——Bert训练标题+TextCNN训练Content，直接使用TextCNN训练标题+Content拼接后的内容，并且最终acc指标受文本长度影响较大。 训练前做了一定量的数据预处理工作，包括关键字提取、地理位置提取等，其中省市提取使用了cpca。 由于花了大量的时间用于文件读取上，导致预处理不够深入，而预处理也是本题的一个关键上分点，此外还可以对网络增加例如文件长度等特征输入。复赛线上rank33，后补位至20+。 ","date":"December 3, 2020","objectID":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/:3:0","tags":null,"title":"中移集成（雄安产业研究院）首届OneCity编程大赛","uri":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/"},{"categories":null,"content":"完整代码 　仅供参考。 #!/usr/bin/env python # coding: utf-8 # In[1]: import warnings warnings.simplefilter('ignore') get_ipython().run_line_magic('matplotlib', 'inline') import matplotlib.pyplot as plt #!pip install seaborn #!pip install --user pandarallel #!pip install --user toolkit4nlp import seaborn as sns import numpy as np import pandas as pd from pandarallel import pandarallel pandarallel.initialize(progress_bar=True) # In[2]: import glob from xlrd import XLRDError import os, sys from tqdm import tqdm import pandas as pd import numpy as np from toolkit4nlp.utils import DataGenerator, pad_sequences from toolkit4nlp.models import build_transformer_model, Model from toolkit4nlp.layers import * from toolkit4nlp.tokenizers import Tokenizer from toolkit4nlp.optimizers import * from sklearn.metrics import accuracy_score train_paths = glob.glob('中移编程大赛-初赛数据-开放/train/*') #test_paths = glob.glob('/home/featurize/data/中移编程大赛-复赛数据-开放/test2/*') example_sub = pd.read_csv('中移编程大赛-复赛数据-开放/submit_example_test2.csv') test_paths = example_sub['filename'].tolist() df_label = pd.read_csv('中移编程大赛-初赛数据-开放/answer_train.csv') file2label = {} for i, item in df_label.iterrows(): file2label[os.path.split(item['filename'])[-1]] = item['label'] all_labels = set(file2label.values()) id2label = {i: label for i, label in enumerate(all_labels)} label2id = {label: i for i, label in enumerate(all_labels)} def read_file(path): df = None columns = [] content = [] # get label fname = os.path.split(path)[-1] label = file2label.get(fname, None) try: df = pd.read_excel(path) except: try: df = pd.read_csv(path, error_bad_lines=False, encoding='utf8') except: pass if df is not None and len(df) \u003e 0: df = df.astype(str) columns = list(df.columns) #content = df.to_numpy()[0].tolist() for i in range(len(df.to_numpy())): content = content + df.to_numpy()[i].tolist()# + df.to_numpy()[1].tolist() + df.to_numpy()[2].tolist() if(i==10): break #print(content) return [label, fname, columns, content, fname] def load_train_data(paths): data = [] for path in tqdm(paths): data.append(read_file(path)) return data def load_test_data(paths): data = [] for path in tqdm(paths): data.append(read_file('中移编程大赛-复赛数据-开放/' + path)) return data train_data = load_train_data(train_paths) test_data = load_test_data(test_paths) # In[3]: only_title = [t for t in train_data if not t[2]] has_content = [t for t in train_data if t[2]] np.random.shuffle(has_content) half = int(len(has_content) * 0.5) np.random.shuffle(has_content) half = int(len(has_content) * 0.5) remove_title = [[t[0], None] + t[2:] for t in has_content[:half]] new_has_content = remove_title + has_content[half:] train_data = only_title + new_has_content def clean_title(x): try: temp = x.replace('train/', '').replace('test1/', '').replace('.xls', '').replace('.csv', '').replace('.xlsx','').replace('_', ' ').replace('test2/', '') return temp except: return \"\" import copy #temp = copy.deepcopy(train_data) for i in tqdm(train_data): i[1] = clean_title(i[1]) i[2] = ' '.join(i[2]) i[3] = ' '.join(i[3]) i[2]= ''.join(re.findall(r\"[\\u4e00-\\u9fa5\\s]\",i[2])) i[3]= ''.join(re.findall(r\"[\\u4e00-\\u9fa5\\s]\",i[3])) # In[6]: for i in tqdm(test_data): i[1] = clean_title(i[1]) i[2] = ' '.join(i[2]) i[3] = ' '.join(i[3]) i[1]= ''.join(re.findall(r\"[\\u4e00-\\u9fa5\\s]\",i[1])) i[2]= ''.join(re.findall(r\"[\\u4e00-\\u9fa5\\s]\",i[2])) i[3]= ''.join(re.findall(r\"[\\u4e00-\\u9fa5\\s]\",i[3])) # In[ ]: # In[7]: train = pd.DataFrame(train_data) train.columns = ['label','title','columns','content','filename'] # In[8]: train['all'] = (train['title'] + train['columns'] + train['content']) #train = train[(train['all'] != '' )] test=pd.DataFrame(test_data) test.columns = ['label','title','columns','content','filename'] # In[11]: test['all'] = (test['title'] + test['columns'] + test['content']) import cpca def remove_loc(info): #info ='铁岭市清河区市广东省名牌产品工业类称号信息' info_ = [info] df = cpca.transform(info_) if(df['省'][0] != None): info = info.replace(df['省'][0],'') if(df['市'][0] != None): i","date":"December 3, 2020","objectID":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/:4:0","tags":null,"title":"中移集成（雄安产业研究院）首届OneCity编程大赛","uri":"/%E4%B8%AD%E7%A7%BB%E9%9B%86%E6%88%90%E9%9B%84%E5%AE%89%E4%BA%A7%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2%E9%A6%96%E5%B1%8Aonecity%E7%BC%96%E7%A8%8B%E5%A4%A7%E8%B5%9B/"},{"categories":null,"content":"表格类数据挖掘+图像分类赛题，赛程极短。初赛阶段出现了标签leak。个人赛道初赛Rank4，决赛Rank13。 ","date":"October 10, 2020","objectID":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/:0:0","tags":null,"title":"智算之道——2020人工智能应用挑战赛","uri":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"空值填充 　以众数填充为例。 for column in list(all_data.columns[all_data.isnull().sum() \u003e 0]): mode_val = all_data[column].mode()[0] all_data[column].fillna(mode_val, inplace=True) 　注意可能有多个众数，一般取第一个（mode()[0]），否则填充后的DataFrame仍存在空值。 ","date":"October 10, 2020","objectID":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/:1:0","tags":null,"title":"智算之道——2020人工智能应用挑战赛","uri":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"focal loss ——tensorflow实现 def focal_loss(logits, labels, gamma=2): softmax = tf.reshape(tf.nn.softmax(logits), [-1]) labels = tf.range(0, tf.shape(logits)[0]) * tf.shape(logits)[1] + labels prob = tf.gather(softmax, labels) weight = tf.pow(tf.subtract(1., prob), gamma) loss = -tf.reduce_mean(tf.multiply(weight, tf.log(prob))) return loss ","date":"October 10, 2020","objectID":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/:2:0","tags":null,"title":"智算之道——2020人工智能应用挑战赛","uri":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"初赛解决方案 　原始特征 + 交叉特征 + 整体(train+test)空值填充，lgb 5折 + catboost，Averaging加权0.4 / 0.6，线上auc 0.8581，个人rank4，初赛出现了标签leak，与前排差距较大，达到了2个百。 ","date":"October 10, 2020","objectID":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/:3:0","tags":null,"title":"智算之道——2020人工智能应用挑战赛","uri":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"Function call stack: train_function 　在tensorflow2.x下调用tf.combat1没有关闭eager_execution()，加入如下代码解决： tf.compat.v1.disable_eager_execution() ","date":"October 10, 2020","objectID":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/:4:0","tags":null,"title":"智算之道——2020人工智能应用挑战赛","uri":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"fit_generator 　从tensorflow 2.1.0开始已不推荐使用fit_generator，fit替代之。 # generator def generator(batch_size): j = 1 while True: x_train = np.zeros((batch_size, 128, 128, 3)) for i in range(batch_size): img_path= './' img = cv2.imread(img_path) img = cv2.resize(img,(128,128)) x_train[i] = img labels = y_train[(j-1)*batch_size:j*batch_size] j=j+1 yield x_train, labels # fit_generator fit_generator(self, generator, steps_per_epoch, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0 ) ","date":"October 10, 2020","objectID":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/:5:0","tags":null,"title":"智算之道——2020人工智能应用挑战赛","uri":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"决赛解决方案 　基线模型为EfficientNET-b5，使用20%的数据预热后，冻结除Dense外的所有层并使用全量数据调整网络。Fixing the train-test resolution discrepancy。 调用模型对测试集分类结果进行推断时，对测试集做了TTA，包括随机裁切、左右翻转等（考虑天气图像的特殊性，未做上下翻转）。Test-Time Augmentation (TTA) Tutorial ","date":"October 10, 2020","objectID":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/:6:0","tags":null,"title":"智算之道——2020人工智能应用挑战赛","uri":"/%E6%99%BA%E7%AE%97%E4%B9%8B%E9%81%932020%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E6%8C%91%E6%88%98%E8%B5%9B/"},{"categories":null,"content":"CTR + 细粒度图像检索赛题，记录一下比赛过程中遇到的问题。 赛道A ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:0:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.7.16 　7.20放赛题数据，先拿kaggle五年前的Click-Through Rate Prediction试水。 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:1:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"分块读取全部数据 loop = True chunkSize = 1000000 chunks = [] index = 0 while loop: try: print(index) chunk = train_data.get_chunk(chunkSize) chunks.append(chunk) index += 1 except StopIteration: loop = False print(\"Iteration is stopped.\") for i in tqdm(chunks): train_data = pd.concat(chunks, ignore_index=True) ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:1:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"随机读取一定比例的数据 for chunk in pd.read_csv(train_data, chunksize=chunksize): chunks += 1 train = pd.concat([train, chunk.sample(frac=.05, replace=False, random_state=42)], axis=0) print('Processing Chunk ' + str(chunks)) ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:1:2","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"条件筛选修改 df['column_d'].loc[df['column_c'] == 0] = 0 # df['column_d'][df['column_c'] == 0] = 0 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:1:3","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"lightgbm 梯度提升决策树 def kfold_lightgbm(train, test, features, target, seed=42, is_shuffle=True): train_pred = np.zeros((train.shape[0],)) test_pred = np.zeros((test.shape[0],)) n_splits = 5 fold = KFold(n_splits=n_splits, shuffle=is_shuffle, random_state=seed) kf_way = fold.split(train[features]) params = { 'learning_rate': 0.003, 'boosting_type': 'gbdt', 'objective': 'regression', 'num_leaves': 36, 'metric': 'mse', 'feature_fraction': 0.6, 'bagging_fraction': 0.7, 'bagging_freq': 6, 'seed': 42, 'bagging_seed': 1, 'feature_fraction_seed': 7, 'min_data_in_leaf': 7, 'nthread': 8, 'verbose': 1, } fold_importance_df = pd.DataFrame() for n_fold, (train_idx, valid_idx) in enumerate(kf_way, start=1): train_x, train_y = train[features].iloc[train_idx], train[target].iloc[train_idx] valid_x, valid_y = train[features].iloc[valid_idx], train[target].iloc[valid_idx] n_train = lgb.Dataset(train_x, label=train_y) n_valid = lgb.Dataset(valid_x, label=valid_y) clf = lgb.train( params= params, train_set= n_train, num_boost_round= 10000, valid_sets= [n_valid], early_stopping_rounds= 150, verbose_eval= 100 ) train_pred[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration) test_pred += clf.predict(test[features], num_iteration=clf.best_iteration) / fold.n_splits fold_importance_df[\"Feature\"] = features fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain') fold_importance_df[\"fold\"] = n_splits test[TARGET] = test_pred return test[['id', TARGET]], fold_importance_df ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:1:4","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"特征编码 if cat_features: ce_oe = ce.OrdinalEncoder(cols=cat_features, handle_unknown='impute') ce_oe.fit(train) train = ce_oe.transform(train) test = ce_oe.transform(test) ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:1:5","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.7.20 　下午官网放了赛题数据，随机抽了5%的数据放进GBDT跑了一下，目测效果并不是很好，CTR标签分布很不均匀，训练集标签为1的样本大概只占到了3%。 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:2:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"结果出现负值 　GBDT是加法模型，下一轮都是上一轮预测值和实际值的残差作为label继续拟合，将结果相加，最后可能会出现负值，特别是例如CTR场景下大部分标签都为0的场景下更容易出现这种情况。 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:2:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.7.21 　丢了几个缺失比较大的特征，对数据做了简单随机采样之后跑lgb5折交了一发，线上分数能到0.7，比预想中的要好，还有一定的提升空间，下一步打算从模型角度切入。 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:3:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.7.22 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:4:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"error:Only one class present in y_true 　DeepFM训练过程报错：Only one class present in y_true. ROC AUC score is not defined in that case. 定义的AUROC函数如下： def auroc(y_true, y_pred): return tf.compat.v1.py_func(roc_auc_score, (y_true, y_pred), tf.double) 　AUC（ROC 曲线下的面积）需要足够数量的任一类才能有意义，而CTR样本中本身就存在着非常严重的正负样本不平衡的问题。 目前解决方案如下： # AUC for a binary classifier def auc(y_true, y_pred): ptas = tf.stack([binary_PTA(y_true, y_pred, k) for k in np.linspace(0, 1, 1000)], axis=0) pfas = tf.stack([binary_PFA(y_true, y_pred, k) for k in np.linspace(0, 1, 1000)], axis=0) pfas = tf.concat([tf.ones((1,)), pfas], axis=0) binSizes = -(pfas[1:] - pfas[:-1]) s = ptas * binSizes return K.sum(s, axis=0) # ----------------------------------------------------------------------------- # PFA, prob false alert for binary classifier def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)): y_pred = K.cast(y_pred \u003e= threshold, 'float32') # N = total number of negative labels N = K.sum(1 - y_true) # FP = total number of false alerts, alerts from the negative class labels FP = K.sum(y_pred - y_pred * y_true) return FP / N # ----------------------------------------------------------------------------- # P_TA prob true alerts for binary classifier def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)): y_pred = K.cast(y_pred \u003e= threshold, 'float32') # P = total number of positive labels P = K.sum(y_true) # TP = total number of correct alerts, alerts from the positive class labels TP = K.sum(y_pred * y_true) return TP / P 　也可在整个训练过程完成后，在vaild_set上计算auc。 pred_ans_val = model.predict(vaild_model_input, batch_size=512) print('val_auc', roc_auc_score(vaild[target].values, pred_ans_val)) ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:4:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.7.24 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:5:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"DeepFM参数调整 　* Regression This implementation also supports regression task. To use DeepFM for regression, you can set loss_type as mse. Accordingly, you should use eval_metric for regression, e.g., mse or mae.* DeepFM中task参数调整为regression后，loss也需随之进行更改。 model = DeepFM( linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns, task='regression', l2_reg_embedding=1e-5 ) model.compile( 'adam', 'mse', metrics=['accuracy'] ) ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:5:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.7.29 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:6:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"onehot编码 　OneHotEncoder 的输入为 2-D array，data[feat] 返回的 Series 为 1-D array。 for feat in cat_features: ohe = OneHotEncoder() data[feat] = ohe.fit_transform(data[[feat]]) 　将data[feat]改为data[[feat]] ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:6:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.8.14 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:7:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"Error:Input contains NaN 　报错ValueError: Input contains NaN, infinity or a value too large for dtype(‘float32’). for index in tr_x.columns: if(df[index].isna().T.any()): print(index,df[index].isna()) # ------ print(df[df.isnull().T.any()]) 　若检查dataframe无空值后仍然报错。可尝试检查dataframe索引是否连续。 df.reset_index(drop=True) ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:7:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.8.15 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:8:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"pandas apply设置进度条 　apply速度较慢，可设置进度条实时显示处理进度。 import pandas as pd from tqdm import tqdm tqdm.pandas(desc='pandas bar') test['B'] = test.progress_apply(lambda x:func(x['A']), axis=1) 赛道B ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:8:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.7.28 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:9:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"Resnet50预训练权重文件 　.h5文件已上传至百度网盘，链接放在此处。 resnet50_weights_tf_dim_ordering_tf_kernels.h5，提取码: pdcg 放在C://users//(yourusername)//.keras//models文件下。 另外，可以通过该网站下载Github上的release内容。 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:9:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"plt.imshow与cv2.imshow显示色差 　使用plt.imshow和cv2.imshow对同一幅图显示时，可能会出现色差，这是由于opencv的接口为BGR，而matplotlib.pyplot接口使用的是RGB。 img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB) plt.imshow(img) plt.show() 　或通过以下方法也可实现： b,g,r = cv2.split(cv2.imread(img_path)) img = cv2.merge([r,g,b]) ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:9:2","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.8.7 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:10:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"余弦相似度 　余弦相似性通过测量两个向量的夹角的余弦值来度量它们之间的相似性。0度角的余弦值是1，而其他任何角度的余弦值都不大于1；并且其最小值是-1。从而两个向量之间的角度的余弦值确定两个向量是否大致指向相同的方向。两个向量有相同的指向时，余弦相似度的值为1；两个向量夹角为90°时，余弦相似度的值为0；两个向量指向完全相反的方向时，余弦相似度的值为-1。该结果仅与向量方向相关。余弦相似度通常用于正空间，因此给出的值为-1到1之间。 给定两个属性向量，A和B，其余弦相似性θ由点积和向量长度给出： 对于两个向量的余弦距离（余弦距离 = 1 - 余弦相似度）的基本计算，Python代码如下： def cosin_distance(vec_1, vec_2): dot_product = 0.0 normA = 0.0 normB = 0.0 for a, b in zip(vec_1, vec_2): dot_product += a * b normA += a ** 2 normB += b ** 2 if normA == 0.0 or normB == 0.0: return None else: return dot_product / ((normA * normB) ** 0.5) ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:10:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.8.8 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:11:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"大规模数据下使用faiss计算余弦相似度(待完善) d = 2048 # dimension nb = gallery_features.shape[0] # database size nq = query_features.shape[0] # nb of queries xb = gallery_features.astype('float32') xq = query_features.astype('float32') nlist = 1000 #聚类中心的个数 k = 10 # topk搜索 quantizer = faiss.IndexFlatL2(d) # the other index index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2) # here we specify METRIC_L2, by default it performs inner-product search assert not index.is_trained index.train(xb) assert index.is_trained index.add(xb) # add may be a bit slower as well D, I = index.search(xq, k) # actual search index.nprobe = 10 # default nprobe is 1, try a few more D, I = index.search(xq, k) 　此处参考官方样例。 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:11:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"2020.8.11 ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:12:0","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"Keras添加网络结构报错 model = Sequential() model.add(load_model('/mnt/resnet.model').get_output_at(0)) 　TypeError: The added layer must be an instance of class Layer. 可能是混合使用了keras.Sequential()和tf.keras.Sequential()；Keras的layer中有input和output属性，错误地使用该部分的成员函数时也可能导致该问题。 修改如下： model = Sequential() model.add(load_model('/mnt/resnet.model').get_layer(index=0)) ","date":"July 16, 2020","objectID":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/:12:1","tags":null,"title":"2020 DIGIX全球校园AI算法精英大赛","uri":"/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97-2020-digix%E5%85%A8%E7%90%83%E6%A0%A1%E5%9B%ADai%E7%AE%97%E6%B3%95%E7%B2%BE%E8%8B%B1%E5%A4%A7%E8%B5%9B%E8%B5%9B%E9%A2%98a/"},{"categories":null,"content":"Hexo 是一个快速、简洁且高效的博客框架，且支持 Markdown 语法。 • 本地环境配置：Node.js+Git+Hexo • ECS环境配置：(CentOs 8) Node.js+Git+Pm2+Nginx • 安全组配置：阿里云ECS • 域名：腾讯云域名解析 • Webhook：Github ","date":"July 15, 2020","objectID":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/:0:0","tags":null,"title":"使用Hexo搭建静态页面博客","uri":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"本地环境配置 Node.js 　Node.js官网Node.js，安装目录尽量不要包括空格，命令行下node -v验证是否安装成功。 或通过淘宝npm镜像安装。 Git 安装 　Git官网 Git，命令行git --version验证。 SSH配置 　配置Github用户名 git config --global user.name \"example\" git config --global user.email \"example@email.com\" 　生成秘钥 ssh-keygen -t rsa -b 4096 -C \"example@email.com\" 　~/.ssh文件夹下生成id_rsa.pub公有密钥，依次进入Github——Settings——SSH and GPG keys，添加SSH key，将d_rsa.pub中的内容放入Key中。具体可以参考这篇文章，Linux系统可以参考这篇文章。 Hexo 　npm全局安装 sudo npm install -g hexo-cli 　验证 hexo -version 　新建文件夹用来存放Hexo代码，在该文件夹下执行命令行。 初始化Hexo，生成相关文件。 hexo -init 　安装相关依赖 npm install 　预览效果 hexo g hexo s 　浏览器进入http://localhost:4000/ 发布到Github 　安装git部署工具 npm install hexo-deployer-git --save 　修改_config.yml，repo字段修改为github仓库的SSH链接。 deploy: type: git repo:git@github.com:egname/egrepo.git branch: master 　代码上传至Github hexo clean hexo g hexo d ","date":"July 15, 2020","objectID":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/:0:1","tags":null,"title":"使用Hexo搭建静态页面博客","uri":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"ECS环境配置 　服务器为阿里云ECS云服务器，CentOS 8。 Node.js 　采用yum方式安装 curl -sL https://rpm.nodesource.com/setup_10.x | bash - yum install -y nodejs node -v # 验证 Git sudo yum install git git --version # 验证 SSH配置 git config --global user.name \"example\" git config --global user.email \"example@email.com\" ssh-keygen -t rsa -b 4096 -C \"example@email.com\" 　复制公有密钥，在Github上添加新的SSH key，具体可参考上文本地配置。 cd ~/.ssh cat id_rsa.pub 　从Github仓库中克隆代码。 cd / mkdir www cd www mkdir blog cd blog git clone git@github.com:egname/egrepo.git Nginx 　安装EPEL存储库 sudo yum install epel-release 　安装Nginx sudo yum install nginx 　启动Nginx，设置自启动 sudo systemctl start nginx sudo systemctl enable nginx Nginx配置 　进入etc/nginx文件夹下的nginx.conf vi /etc/nginx/nginx.conf 　修改配置文件 server { listen 80; server_name www.example.com; root /www/blog/example; include /etc/nginx/default.d/*.conf; location / { root /www/blog/example; index index.jsp index.html index.htm; } } 　重启Nginx systemctl restart nginx ","date":"July 15, 2020","objectID":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/:0:2","tags":null,"title":"使用Hexo搭建静态页面博客","uri":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"安全组配置 　以阿里云ECS为例。 进入控制台——网络与安全——安全组，添加入方向规则。 添加端口范围分别为80/80（HTTP），443/443（HTTPS），7777/7777（Webhook），授权对象均为0.0.0.0/0。 ","date":"July 15, 2020","objectID":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/:0:3","tags":null,"title":"使用Hexo搭建静态页面博客","uri":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"域名解析 　以腾讯云为例。 DNS 解析 DNSPod——域名解析列表——选择域名——添加记录——快速添加网站解析——指定服务器主机IP（公网）。 ","date":"July 15, 2020","objectID":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/:0:4","tags":null,"title":"使用Hexo搭建静态页面博客","uri":"/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%8D%9A%E5%AE%A2/"},{"categories":null,"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. ","date":"July 15, 2020","objectID":"/hello-world/:0:0","tags":null,"title":"Hello World","uri":"/hello-world/"},{"categories":null,"content":"Quick Start ","date":"July 15, 2020","objectID":"/hello-world/:1:0","tags":null,"title":"Hello World","uri":"/hello-world/"},{"categories":null,"content":"Create a new post $ hexo new \"My New Post\" More info: Writing ","date":"July 15, 2020","objectID":"/hello-world/:1:1","tags":null,"title":"Hello World","uri":"/hello-world/"},{"categories":null,"content":"Run server $ hexo server More info: Server ","date":"July 15, 2020","objectID":"/hello-world/:1:2","tags":null,"title":"Hello World","uri":"/hello-world/"},{"categories":null,"content":"Generate static files $ hexo generate More info: Generating ","date":"July 15, 2020","objectID":"/hello-world/:1:3","tags":null,"title":"Hello World","uri":"/hello-world/"},{"categories":null,"content":"Deploy to remote sites $ hexo deploy More info: Deployment ","date":"July 15, 2020","objectID":"/hello-world/:1:4","tags":null,"title":"Hello World","uri":"/hello-world/"}]