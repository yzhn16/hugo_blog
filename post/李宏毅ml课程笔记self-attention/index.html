<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" href="/images/favicon.svg">
    
    <link rel="stylesheet" href="/scss/global.min.21bde5c4790756f13e2e070d4373cff76d70cc802499075fa5f879b325f907f2.css">
    
    <link rel="stylesheet" href="/css/prism.css" />
    <link href="https://fonts.googleapis.com/css?family=Merriweather&display=swap" rel="stylesheet">
    

 






	




<title>李宏毅ML课程笔记——Self-attention | yzhn&#39;s Notes</title>
<meta name="description" content="李宏毅2021/2022春机器学习课程——自注意力机制（Self-attention）">
<meta property="og:title" content="李宏毅ML课程笔记——Self-attention | yzhn&#39;s Notes">
<meta property="og:site_name" content="yzhn&#39;s Notes">
<meta property="og:description" content="李宏毅2021/2022春机器学习课程——自注意力机制（Self-attention）">
<meta property="og:url" content="/post/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/">
<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:image" content='/uploads/default.jpg'><meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="李宏毅ML课程笔记——Self-attention | yzhn&#39;s Notes">

	<link rel="canonical" href="/post/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0self-attention/">


	<meta name="twitter:description" content="李宏毅2021/2022春机器学习课程——自注意力机制（Self-attention）">
<meta name="twitter:image" content="/uploads/default.jpg">
<meta property="article:published_time" content="2022-04-23T17:45:00&#43;00:00">
	<meta property="article:updated_time" content="2022-04-23T17:45:00&#43;00:00">



    </head>


<body class="line-numbers">

    
    <script src="/js/initColors.js"></script>

    <div class="layout-styled">

        <Section class="section">
  <div class="nav-container">
    <a class="logo-link" href="/">
      <div id="logo-desktop">
        <svg
        width="192"
        height="23"
        viewBox="0 0 192 23"
        fill="none"
        xmlns="http://www.w3.org/2000/svg"
        className="Logo__Desktop"
      >
        <g clipPath="url(#clip0)">
          <path
            d="M120.941 6.15477H122.453V2.83255L124.114 2.44922V6.15477H126.713V7.30477H124.114V16.377C124.114 17.314 124.54 17.7826 125.435 17.7826C125.925 17.7826 126.478 17.6335 126.904 17.4205L127.181 18.4214C126.606 18.7835 125.861 18.9964 124.86 18.9964C123.539 18.9964 122.432 18.3788 122.432 16.5261V7.30477H120.92V6.15477H120.941Z"
            fill="#7A8085"
          />
          <path
            d="M131.739 7.77334C132.825 6.70852 134.273 5.89926 135.764 5.89926C137.723 5.89926 138.937 6.94278 138.937 9.17889V17.6122L140.555 17.8465V18.7409H137.233V9.58352C137.233 7.9863 136.616 7.30482 135.338 7.30482C134.166 7.30482 132.74 8.0076 131.739 8.90204V17.5909L133.442 17.8039V18.7196H128.416V17.8039L130.078 17.5909V1.29926L128.374 1.04371V0.0214844H131.739V7.77334V7.77334Z"
            fill="#7A8085"
          />
          <path
            d="M141.854 12.4374C141.854 7.6883 143.92 5.89941 146.731 5.89941C149.648 5.89941 151.267 7.64571 151.267 11.9689V12.629H143.6C143.621 16.3772 144.686 17.8253 147.284 17.8253C148.605 17.8253 149.584 17.3994 150.5 16.7818L151.096 17.6124C150.01 18.5068 148.754 18.9966 147.008 18.9966C143.941 18.9753 141.854 17.2929 141.854 12.4374ZM143.621 11.5216H149.521C149.521 8.34849 148.754 6.98552 146.709 6.98552C144.857 6.98552 143.771 8.2633 143.621 11.5216Z"
            fill="#7A8085"
          />
          <path
            d="M162.682 7.85849C163.768 6.70849 165.024 5.87793 166.515 5.87793C168.474 5.87793 169.646 6.92145 169.646 9.15756V17.6335L171.286 17.8677V18.6983H167.963V9.68997C167.963 8.07145 167.388 7.32608 166.089 7.32608C164.918 7.32608 163.789 8.02886 162.81 8.9233V17.6122L164.449 17.8464V18.7409H161.127V9.68997C161.127 8.07145 160.552 7.32608 159.253 7.32608C158.082 7.32608 156.953 8.02886 155.973 8.9233V17.6122L157.677 17.8464V18.7409H152.651V17.8464L154.312 17.6122V7.47515L152.609 7.2196V6.15478H155.654L155.888 7.85849C156.974 6.72978 158.188 5.89923 159.679 5.89923C161.212 5.87793 162.277 6.51682 162.682 7.85849Z"
            fill="#7A8085"
          />
          <path
            d="M171.925 12.4374C171.925 7.6883 173.991 5.89941 176.802 5.89941C179.719 5.89941 181.338 7.64571 181.338 11.9689V12.629H173.671C173.692 16.3772 174.757 17.8253 177.355 17.8253C178.676 17.8253 179.655 17.3994 180.571 16.7818L181.167 17.6124C180.081 18.5068 178.825 18.9966 177.079 18.9966C174.012 18.9753 171.925 17.2929 171.925 12.4374ZM173.692 11.5216H179.591C179.591 8.34849 178.825 6.98552 176.78 6.98552C174.928 6.98552 173.863 8.2633 173.692 11.5216Z"
            fill="#7A8085"
          />
          <path
            d="M183.084 18.0383V15.504H184.234L184.618 17.442C185.278 17.7189 185.789 17.8892 186.811 17.8892C188.664 17.8892 189.558 17.0374 189.558 15.5466C189.558 14.0559 188.834 13.4809 186.79 12.8846C184.831 12.2883 183.382 11.4577 183.382 9.13645C183.382 7.39016 184.639 5.89941 187.195 5.89941C188.664 5.89941 189.835 6.17627 190.687 6.68738V9.15775H189.558L189.132 7.34756C188.579 7.09201 187.961 7.00682 187.258 7.00682C185.789 7.00682 184.852 7.7309 184.852 8.98738C184.852 10.3077 185.576 10.8189 187.365 11.3513C189.431 12.0115 191.156 12.7142 191.156 15.3976C191.156 17.7615 189.431 18.9753 186.79 18.9753C185.235 18.9753 183.957 18.6346 183.084 18.0383Z"
            fill="#7A8085"
          />
          <path class="change-fill"
            d="M38.3122 9.98811C38.3122 8.66774 37.9501 8.15663 36.9492 8.15663C36.1186 8.15663 35.0964 8.62515 34.3936 9.20015V16.9733L35.8418 17.165V18.6344H30.0918V17.165L31.5825 16.9733V8.24182L30.0918 7.92237V6.19737H33.9251L34.2446 7.64552C35.3733 6.55941 36.6298 5.87793 38.1418 5.87793C39.9946 5.87793 41.102 6.92145 41.102 9.07237V16.9733L42.5927 17.165V18.6344H38.3122V9.98811V9.98811Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M62.3982 17.1858V18.6553H56.0732V17.1858L57.564 16.9942V8.2627L56.0732 7.94326V6.21826H59.8427L60.226 8.17752C61.0779 6.85715 62.1427 5.94141 63.6973 5.94141C63.8677 5.94141 64.0594 5.9627 64.1871 6.0053L63.8251 8.94418C63.5483 8.81641 63.2501 8.77381 62.8668 8.77381C61.8871 8.77381 61.1418 9.05067 60.3751 9.71085V16.9516L62.3982 17.1858Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M76.7098 6.19733H78.0941V3.08807L80.5432 2.55566V6.21863H82.9709V8.0927H80.5432V15.6742C80.5432 16.5899 80.8839 16.9946 81.6293 16.9946C82.0978 16.9946 82.5876 16.8455 82.907 16.6751L83.3543 18.3575C82.758 18.6983 81.9061 18.9751 80.6709 18.9751C78.9672 18.9751 78.0941 18.1658 78.0941 16.0362V8.0927H76.7098V6.19733Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M90.4664 17.1648V18.6343H84.6738V17.1648L86.1646 16.9731V8.24167L84.6738 7.92222V6.19722H88.9757V16.9731L90.4664 17.1648ZM85.696 1.76759C85.696 0.787963 86.4627 0 87.4423 0C88.422 0 89.1886 0.766667 89.1886 1.76759C89.1886 2.72593 88.422 3.51389 87.421 3.51389C86.4627 3.51389 85.696 2.72593 85.696 1.76759Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M98.3251 7.90097V6.19727H103.053V7.92227L101.924 8.11393L98.3251 18.6556H95.663L92.064 8.09264L90.9991 7.92227V6.19727H96.2593V7.90097L95.0242 8.09264L96.7279 13.6084C97.0473 14.6519 97.1964 15.5037 97.3668 16.4834H97.388C97.5371 15.525 97.7714 14.5241 98.0482 13.5871L99.6668 8.07134L98.3251 7.90097Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M75.6867 17.1224C74.5793 17.1437 74.3664 16.952 74.3664 15.9724V9.79645C74.3664 6.96404 72.9821 5.87793 70.3201 5.87793C68.3821 5.87793 66.7423 6.45293 65.4219 7.28349L66.2312 9.02978C67.3599 8.45478 68.4673 8.09274 69.7238 8.09274C71.1932 8.09274 71.5552 8.88071 71.5552 10.265V11.0316V11.2233V12.7779V12.8844V16.1214C71.0867 16.6326 70.4052 17.0585 69.4469 17.0585C68.3821 17.0585 67.871 16.5261 67.871 15.0353C67.871 13.3103 68.5951 12.8205 70.4904 12.7779V11.2233C66.6358 11.2659 65.0386 12.4372 65.0386 15.2057C65.0386 17.8465 66.4867 18.9752 68.6589 18.9752C70.2136 18.9752 71.0654 18.315 71.7895 17.5696C72.0451 18.5705 72.833 18.9752 73.8978 18.9752C74.6645 18.9752 75.3886 18.7622 75.8571 18.5066L75.6867 17.1224Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M54.4968 17.1224C53.3894 17.1437 53.1764 16.952 53.1764 15.9724V9.79645C53.1764 6.96404 51.7922 5.87793 49.1301 5.87793C47.1922 5.87793 45.5523 6.45293 44.232 7.28349L45.0412 9.02978C46.1699 8.45478 47.2773 8.09274 48.5338 8.09274C50.0033 8.09274 50.3653 8.88071 50.3653 10.265V11.0316V11.2233V12.7779V12.8844V16.1214C49.8968 16.6326 49.2153 17.0585 48.257 17.0585C47.1922 17.0585 46.681 16.5261 46.681 15.0353C46.681 13.3103 47.4051 12.8205 49.3005 12.7779V11.2233C45.4459 11.2659 43.8486 12.4372 43.8486 15.2057C43.8486 17.8465 45.2968 18.9752 47.469 18.9752C49.0236 18.9752 49.8755 18.315 50.5996 17.5696C50.8551 18.5705 51.6431 18.9752 52.7079 18.9752C53.4746 18.9752 54.1986 18.7622 54.6672 18.5066L54.4968 17.1224Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M107.653 13.055H113.594V11.9476C113.594 7.47534 111.869 5.89941 108.803 5.89941C105.63 5.89941 103.628 7.79478 103.628 12.4161C103.628 17.1013 105.523 18.9966 109.058 18.9966C110.954 18.9966 112.231 18.5068 113.467 17.5272L112.657 16.0577C111.678 16.6753 110.868 17.0587 109.463 17.0587C107.546 17.0587 106.801 16.1855 106.63 14.0133C106.588 13.6939 106.567 13.0976 106.567 12.4587C106.567 12.054 106.567 11.6707 106.588 11.3726V11.3513C106.737 8.51886 107.397 7.60312 108.781 7.60312C110.4 7.60312 110.783 8.58275 110.783 11.3513H107.674V13.055H107.653Z"
            fill="#000"
          />
          <path class="change-fill" d="M17.5907 20.2954H0V23H17.5907V20.2954Z" fill="#000" />
          <path class="change-fill"
            d="M0 7.96484V18.9537L5.38796 15.1843V11.7343L0 7.96484Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M17.5689 10.9463V0L12.1597 3.74815V7.13426L17.5689 10.9463Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M17.5907 18.975L17.5694 12.288L0 0V6.62315L17.5907 18.975Z"
            fill="#000"
          />
        </g>
        <defs>
          <clipPath id="clip0">
            <rect width="191.156" height="23" fill="white" />
          </clipPath>
        </defs>
      </svg>
</div>
<div id="logo-mobile" class="hidden">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
    width="23" height="23" viewBox="0 0 512.000000 512.000000"
    preserveAspectRatio="xMidYMid meet">
   <metadata>
   Created by potrace 1.15, written by Peter Selinger 2001-2017
   </metadata>
   <g transform="translate(0.000000,512.000000) scale(0.100000,-0.100000)"
   fill="" stroke="none">
   <path d="M590 4383 l1 -738 756 -530 c698 -489 1151 -807 2618 -1837 l540
   -380 3 748 c2 590 -1 751 -10 760 -7 7 -308 218 -668 470 -360 251 -1230 859
   -1933 1351 -702 491 -1284 893 -1292 893 -13 0 -15 -92 -15 -737z"/>
   <path d="M3887 4708 l-597 -412 0 -381 0 -381 597 -419 c328 -231 602 -421
   610 -423 11 -3 13 204 13 1212 0 987 -2 1216 -13 1216 -7 0 -282 -186 -610
   -412z"/>
   <path d="M590 2135 c0 -910 3 -1225 11 -1225 10 0 343 231 1049 728 l155 109
   0 389 0 388 -595 418 c-327 229 -601 417 -607 418 -10 0 -13 -251 -13 -1225z"/>
   <path d="M590 320 l0 -310 1960 0 1960 0 0 310 0 310 -1960 0 -1960 0 0 -310z"/>
   </g>
   </svg>
</div>
      <span class="header-hidden">Navigate back to the homepage</span>
    </a>
    <div class="nav-controls">
      <button id="copyButton" class="icon-wrapper">
        <svg
    class="icon-image"
    width="24"
    height="20"
    viewBox="0 0 24 20"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
    >
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M2 5C2 3.34328 3.34328 2 5 2H14C15.6567 2 17 3.34328 17 5V9C17 10.6567 15.6567 12 14 12H10C9.44771 12 9 12.4477 9 13C9 13.5523 9.44771 14 10 14H14C16.7613 14 19 11.7613 19 9V5C19 2.23872 16.7613 0 14 0H5C2.23872 0 0 2.23872 0 5V9C0 10.4938 0.656313 11.8361 1.6935 12.7509C2.10768 13.1163 2.73961 13.0767 3.10494 12.6625C3.47028 12.2483 3.43068 11.6164 3.0165 11.2511C2.39169 10.6999 2 9.89621 2 9V5ZM7 11C7 9.34328 8.34328 8 10 8H14C14.5523 8 15 7.55228 15 7C15 6.44772 14.5523 6 14 6H10C7.23872 6 5 8.23872 5 11V15C5 17.7613 7.23872 20 10 20H19C21.7613 20 24 17.7613 24 15V11C24 9.50621 23.3437 8.16393 22.3065 7.24906C21.8923 6.88372 21.2604 6.92332 20.8951 7.3375C20.5297 7.75168 20.5693 8.38361 20.9835 8.74894C21.6083 9.30007 22 10.1038 22 11V15C22 16.6567 20.6567 18 19 18H10C8.34328 18 7 16.6567 7 15V11Z"
      fill="#000"
    />
</svg>
        <div id="toolTip" class="tool-tip " >
            copied
        </div>
        <input id="copyText" style="opacity: 0;" type="text" class="tool-tip " />
      </button>

      <button id="themeColorButton" class="icon-wrapper"> 
        <div id="sunRays" class="sun-rays"></div>
        <div id="moonOrSun" class="moon-or-sun"></div>
        <div id="moonMask" class="moon-mask"></div>
      </button>
    </div>
</div>
</Section>


<script src="/js/toggleLogos.js"></script>


<script src="/js/toggleColors.js"></script>


<script src="/js/copyUrl.js"></script>

        

<section class="section narrow">

    <section id="articleHero" class="section narrow">
    <div class="article-hero">
        <header class="article-header">
            <h1 class="article-hero-heading">李宏毅ML课程笔记——Self-attention</h1>
            <div class="article-hero-subtitle">
                <div class="article-meta">
                    


    <div class="article-coauthors-container">
        
        <span id="collapsedCoauthors" class="article-coauthors-collapsed">
            <div class="article-coauthors-list" style="width: 0px;">
                
            </div>
            <strong class="article-coauthors-name-container">
                
            </strong>
            <div class="article-coauthors-icon-container">
                <svg
width="17"
height="17"
viewBox="0 0 17 17"
fill="none"
xmlns="http://www.w3.org/2000/svg"
>
    <path style="fill: var(--primary);"
      d="M5.3209 8.86719L8.50026 12.0396L11.6796 8.86719L12.6563 9.84385L8.50026 13.9999L4.34424 9.84385L5.3209 8.86719Z"
    />
    <path style="fill: var(--primary);"
      d="M11.6791 8.13281L8.49974 4.96039L5.32039 8.13281L4.34373 7.15615L8.49974 3.00013L12.6558 7.15615L11.6791 8.13281Z"
    />
</svg>
            </div>
        </span>

        <ul id="uncollapsedCoauthors" class="article-coauthors-list-open hidden">
            <div id="uncollapsedAction" class="article-icon-open-container">
                <svg
width="17"
height="17"
viewBox="0 0 17 17"
fill="none"
xmlns="http://www.w3.org/2000/svg"
>
    <path style="fill: var(--primary);"
      d="M11.6796 14L8.50023 10.8276L5.32088 14L4.34422 13.0233L8.50023 8.86732L12.6563 13.0233L11.6796 14Z"
    />
    <path style="fill: var(--primary);"
      d="M5.32041 3L8.49977 6.17243L11.6791 3L12.6558 3.97666L8.49977 8.13268L4.34375 3.97666L5.32041 3Z"
    />
</svg>
            </div>
            
        </ul>
    </div>



<script src="/js/collapseAuthors.js"></script>
                    April 23, 2022
                    • 5 min read
                </div>
            </div>
        </header>
        
    </div>
</section>


    <aside id="progressBar" class="aside-container">
    <div class="aside-align">
      <div>
        <div class="overlap-container">
        </div>
      </div>
    </div>

    <div class="progress-container" tabIndex={-1}>
        <div class="track-line" aria-hidden="true">
            <div id="progressIndicator" class="progress-line"></div>
        </div>
    </div>
</aside>


    <article  id="articleContent" class="post-content" style="position:relative;">
        <p><a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=38">李宏毅2021/2022春机器学习课程——自注意力机制（Self-attention）</a></p>
<h1 id="自注意力机制self-attention">自注意力机制（Self-Attention）</h1>
<p>考虑两种不同的输入：</p>
<ul>
<li>输入是一个向量</li>
<li><strong>输入是一排向量</strong>（输入的向量个数可能会改变）</li>
</ul>
<h2 id="将一排向量作为输入">将一排向量作为输入</h2>
<h3 id="方法">方法</h3>
<ul>
<li>One-hot Encoding</li>
<li>Word Embedding</li>
</ul>
<h3 id="输入">输入</h3>
<ul>
<li>一段语音窗口</li>
<li>一张图</li>
<li>分子结构</li>
<li>&hellip;</li>
</ul>
<h3 id="输出">输出</h3>
<h4 id="n个向量对应n个标签">N个向量对应N个标签</h4>
<ul>
<li>句子中每个词的词性：I saw a saw -&gt; N V DET N</li>
<li>社交网络中每个人的购买意向：甲 -&gt; buy;乙 -&gt; not</li>
</ul>
<h4 id="n个向量对应一个标签">N个向量对应一个标签</h4>
<ul>
<li>情感分析：this is good -&gt; positive</li>
<li>分子属性分析：一个分子图 -&gt; 亲水性</li>
</ul>
<h4 id="n个向量对应多个标签seq2seq">N个向量对应多个标签（seq2seq）</h4>
<ul>
<li>机器翻译</li>
</ul>
<h2 id="fully-connected-network">Fully-connected Network</h2>
<p>使用全连接网络，设置窗口大小，每次输入邻近的多个词。但限制于窗口大小，无法考虑整个句子的影响，且窗口覆盖整个句子比较困难。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/fc.png" style="zoom:50%;" />
<h2 id="self-attention">Self-attention</h2>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/self-attention.png" style="zoom:50%;" />
<p>例：</p>
<ul>
<li>输入：一排向量${a^1,a^2,a^3,a^4}$</li>
<li>输出：一排向量${b^1,b^2,b^3,b^4}$</li>
</ul>
<p><em>$b^1$、$b^2$、$b^3$、$b^4$分别都是考虑了$a^1$、$a^2$、$a^3$、$a^4$而产生的。</em></p>
<h3 id="如何生成b1">如何生成$b^1$？</h3>
<h4 id="a1与其他向量的相关性alpha的计算方法">$a^1$与其他向量的相关性$\alpha$的计算方法</h4>
<h5 id="dot-product"><strong>Dot-product</strong></h5>
<p>输入两个向量，分别与矩阵$W^q$和$W^k$相乘，再将得到的向量$q$和$k$做点乘。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/dot-product.png" style="zoom:50%;" />
$$
\begin{aligned}
q&=a^1\times W^q \\
k&=a^2\times W^k \\
\alpha &= q\cdot k
\end{aligned}
$$
<h5 id="additive">Additive</h5>
<p>输入两个向量，分别与矩阵$W^q$和$W^k$相乘，将得到的向量$q$和$k$串起来并通过激活函数，最后通过一个变换得到$alpha$。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/additive.png" style="zoom:50%;" />
<h4 id="b1的计算">$b^1$的计算</h4>
<p>本节中的例子中，对于$b^1$，计算步骤如下：</p>
<ul>
<li>step1.计算$q^1$</li>
</ul>
<p>$$
q^1=W^qa^1
$$</p>
<ul>
<li>step2.计算$k^1$、$k^2$、$k^3$、$k^4$</li>
</ul>
<p>$$
k^i=W^ka^i
$$</p>
<ul>
<li>step3.计算$\alpha_{1,1}$、$\alpha_{1,2}$、$\alpha_{1,3}$、$\alpha_{1,4}$</li>
</ul>
<p>$$
\alpha_{1,i}=q^1\cdot k^i \
$$</p>
<ul>
<li>step4.通过Soft-max（也可使用ReLU等）计算$\alpha_{1,1}&rsquo;$、$\alpha_{1,2}&rsquo;$、$\alpha_{1,3}&rsquo;$、$\alpha_{1,4}'$</li>
</ul>
<p>$$
\alpha_{1,i}&rsquo;=\frac{\exp(\alpha_{1,i})}{\sum_j\exp(\alpha_{1,j})}
$$</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/self-attention-1.png" style="zoom:50%;" />
<ul>
<li>
<p>step5.计算$v^1$、$v^2$、$v^3$、$v^4$
$$
v^i=W^va^i
$$</p>
</li>
<li>
<p>step6.计算$b^1$（根据Attenion分数抽取重要信息）
$$
b^1=\sum_j\alpha_{1,j}&lsquo;v^j
$$</p>
</li>
</ul>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/self-attention-2.png" style="zoom:50%;" />
<h3 id="输出向量组b1b2b3b4的完整计算过程">输出向量组${b^1,b^2,b^3,b^4}$的完整计算过程</h3>
<p>整理以上过程，$Q$、$K$、$V$和Attention分数的计算过程如下：</p>
<h4 id="qkv的计算">$Q$、$K$、$V$的计算</h4>
<p>由：
$$
\begin{aligned}
q^i &amp;=W^qa^i \
k^i &amp;=W^ka^i \
v^i &amp;=W^va^i
\end{aligned}
$$
有：
$$
\begin{aligned}
\begin{bmatrix}
q^1 &amp; q^2 &amp; q^3 &amp; q^4
\end{bmatrix}
&amp;=W^q
\begin{bmatrix}
a^1 &amp; a^2 &amp; a^3 &amp; a^4
\end{bmatrix}
\
\begin{bmatrix}
k^1 &amp; k^2 &amp; k^3 &amp; k^4
\end{bmatrix}
&amp;=W^k
\begin{bmatrix}
a^1 &amp; a^2 &amp; a^3 &amp; a^4
\end{bmatrix}
\
\begin{bmatrix}
v^1 &amp; v^2 &amp; v^3 &amp; v^4
\end{bmatrix}
&amp;=W^v
\begin{bmatrix}
a^1 &amp; a^2 &amp; a^3 &amp; a^4
\end{bmatrix}
\end{aligned}
$$
即：
$$
\begin{aligned}
Q&amp;=W^qI \
K&amp;=W^kI \
V&amp;=W^vI
\end{aligned}
$$
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/self-attention-3.png" style="zoom:50%;" /></p>
<h4 id="attention分数的计算">Attention分数的计算</h4>
<h1 id="endbmatrix">由：
$$
\alpha_{1,i}=k^i\cdot q^1 \
$$
有：
$$
\begin{bmatrix}
\alpha_{1,1} \
\alpha_{1,2} \
\alpha_{1,3} \
\alpha_{1,4}
\end{bmatrix}</h1>
<h1 id="endbmatrix-1">\begin{bmatrix}
k^1 \
k^2 \
k^3 \
k^4
\end{bmatrix}
\cdot
q^1
$$
进一步有：
$$
\begin{bmatrix}
\alpha_{1,1} &amp; \alpha_{2,1} &amp; \alpha_{3,1} &amp;\alpha_{4,1} \
\alpha_{1,2} &amp; \alpha_{2,2} &amp; \alpha_{3,2} &amp;\alpha_{4,2} \
\alpha_{1,3} &amp; \alpha_{2,3} &amp; \alpha_{3,3} &amp;\alpha_{4,3} \
\alpha_{1,4} &amp; \alpha_{2,4} &amp; \alpha_{3,4} &amp;\alpha_{4,4} \
\end{bmatrix}</h1>
<p>\begin{bmatrix}
k^1 \
k^2 \
k^3 \
k^4
\end{bmatrix}
\cdot
\begin{bmatrix}
q^1 &amp; q^2 &amp; q^3 &amp;q^4
\end{bmatrix}
$$
即：
$$
A=K^TQ
$$
对$A$进行Soft-max得到$A&rsquo;$：
$$
A&rsquo;=
\begin{bmatrix}
\alpha_{1,1}&rsquo; &amp; \alpha_{2,1}&rsquo; &amp; \alpha_{3,1}&rsquo; &amp;\alpha_{4,1}&rsquo; \
\alpha_{1,2}&rsquo; &amp; \alpha_{2,2}&rsquo; &amp; \alpha_{3,2}&rsquo; &amp;\alpha_{4,2}&rsquo; \
\alpha_{1,3}&rsquo; &amp; \alpha_{2,3}&rsquo; &amp; \alpha_{3,3}&rsquo; &amp;\alpha_{4,3}&rsquo; \
\alpha_{1,4}&rsquo; &amp; \alpha_{2,4}&rsquo; &amp; \alpha_{3,4}&rsquo; &amp;\alpha_{4,4}&rsquo; \
\end{bmatrix}
$$
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/self-attention-4.png" style="zoom:50%;" /></p>
<h1 id="endbmatrix-2">最后将$V$与$A&rsquo;$相乘，得到$b^1$、$b^2$、$b^3$、$b^4$：
$$
\begin{bmatrix}
b^1 &amp; b^2 &amp; b^3 &amp; b^4
\end{bmatrix}</h1>
<p>\begin{bmatrix}
v^1 &amp; v^2 &amp; v^3 &amp; v^4
\end{bmatrix}
\cdot
\begin{bmatrix}
\alpha_{1,1}&rsquo; &amp; \alpha_{2,1}&rsquo; &amp; \alpha_{3,1}&rsquo; &amp;\alpha_{4,1}&rsquo; \
\alpha_{1,2}&rsquo; &amp; \alpha_{2,2}&rsquo; &amp; \alpha_{3,2}&rsquo; &amp;\alpha_{4,2}&rsquo; \
\alpha_{1,3}&rsquo; &amp; \alpha_{2,3}&rsquo; &amp; \alpha_{3,3}&rsquo; &amp;\alpha_{4,3}&rsquo; \
\alpha_{1,4}&rsquo; &amp; \alpha_{2,4}&rsquo; &amp; \alpha_{3,4}&rsquo; &amp;\alpha_{4,4}&rsquo; \
\end{bmatrix}
$$
即得到Self-attention的输出：
$$
O=VA&rsquo;
$$</p>
<h4 id="总结">总结</h4>
<p>$$
\begin{aligned}
&amp;Q=W^qI \
&amp;K=W^kI \
&amp;V=W^vI \
&amp;A=K^TQ \
&amp;A \rightarrow A&rsquo; \
&amp;O=VA'
\end{aligned}
$$</p>
<p>$W^q$、$W^k$、$W^v$是需要学习的参数。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/self-attention-5.png" style="zoom:50%;" />
<h2 id="multi-head-self-attention">Multi-head Self-attention</h2>
<p>多个$q$，对应不同种类的相关性。</p>
<p>例如对于2 head的情况，$a^i$对应的$q^i$、$k^i$、$v^i$具体有$q^{i,1}$、$k^{i,1}$、$v^{i,1}$：
$$
\begin{aligned}
&amp;q^{i,1}=W^{q,1}q^i \
&amp;q^{i,2}=W^{q,2}q^i
\end{aligned}
$$
类似的，$a^j$对应的$q^j$、$k^j$、$v^j$具体有$q^{j,1}$、$k^{j,1}$、$v^{j,1}$：</p>
<p>在使用Dot-product计算Attention分数时，使用对应的$q$和$k$进行计算，$q^{i,1}$分别和$k^{i,1}$、$k^{j,1}$进行计算，在将Attention分数分别和$v^{i,1}$、$v^{j,1}$计算，得到$b^{i,1}$，类似可得到$b^{i,2}$。
$$
b^i=W^O
\begin{bmatrix}
b^{i,1} \
b^{i,2}
\end{bmatrix}
$$
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/multi-head%20self-attention.png" style="zoom:50%;" /></p>
<h2 id="位置编码">位置编码</h2>
<p>Self-attention中，对输入的几个向量所进行的操作是相同的，与位置无关，可能丢失了位置信息。</p>
<p>为每一个位置都设定一个向量$e^i$，将该向量加到$a^i$上。
$$
e^i+a^i\rightarrow q^i,k^i,v^i
$$
向量$e^i$可以通过一个规则设定（人工）或从训练数据中学习出来。</p>
<p>有各种不同的方法产生位置编码：</p>
<ul>
<li>Sinusoidal</li>
<li>Position embedding</li>
<li>FLOATER</li>
<li>RNN</li>
<li>&hellip;</li>
</ul>
<h2 id="self-attention用于语音">Self-attention用于语音</h2>
<p>把声音讯号表示为一排向量，一般一个向量只有10ms的长度，会导致向量个数过多，$A&rsquo;$计算的复杂度是$O(L^2)$，一般使用<strong>Truncated Self-attention</strong>，不看一整句话，只看一小部分。</p>
<h2 id="self-attention用于图像">Self-attention用于图像</h2>
<p>一张图片可以看成是一排向量。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/self-attention%20for%20img.png" style="zoom:50%;" />
<ul>
<li>Self-Attention GAN</li>
<li>Detection Transformer(DETR)</li>
</ul>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/self-attention%20for%20img2.png" style="zoom:50%;" />
<h2 id="self-attention-vs-cnn">Self-attention v.s. CNN</h2>
<p>Self-attention可以看作复杂化的CNN，Self-attention考虑全局。CNN是Self-attention的特例，Self-attention可以通过设定合适的参数，达到和CNN同样的效果。</p>
<ul>
<li>[<a href="https://arxiv.org/abs/1911.03584">1911.03584] On the Relationship between Self-Attention and Convolutional Layers (arxiv.org)</a></li>
</ul>
<h2 id="self-attention-vs-rnn">Self-attention v.s. RNN</h2>
<p>RNN（Recurrent Neural Network）：</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/4/self-attention%20vs%20RNN.png" style="zoom:50%;" />
<p>RNN的缺点很明显，很难去考虑到输入位置较远的向量，并且无法并行计算。</p>
<ul>
<li>[<a href="https://arxiv.org/abs/2006.16236">2006.16236] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention (arxiv.org)</a></li>
</ul>
<h2 id="self-attention用于图">Self-attention用于图</h2>
<p>图中每个结点可以表示为一个向量，边可以用来考虑结点之间的关联性，计算Attention分数时，只需计算相连的结点。</p>
<p>Self-attention用在图上面，是某一种类型的GNN（Graph Neural Network）。</p>
<h2 id="more">More</h2>
<p>Self-Attention的计算量较大，优化效率是一个研究方向。</p>
<ul>
<li>[<a href="https://arxiv.org/abs/2011.04006">2011.04006] Long Range Arena: A Benchmark for Efficient Transformers (arxiv.org)</a></li>
<li>[<a href="https://arxiv.org/abs/2009.06732">2009.06732] Efficient Transformers: A Survey (arxiv.org)</a></li>
</ul>
    </article>


    





    
    
    
        
    




<section id="articleNext" class="section nartrow">
    <h3 class="footer-next-heading">More articles from yzhn&#39;s Notes</h3>
    <div class="footer-spacer"></div>
    <div class="next-articles-grid" numberOfArticles={numberOfArticles}>
        <div class="post-row">
            
                <a href="/post/hexo%E4%B8%ADnext%E4%B8%BB%E9%A2%98%E4%B8%8B%E5%9F%BA%E4%BA%8Efancybox%E7%9A%84%E7%9B%B8%E5%86%8C%E9%A1%B5%E9%9D%A2%E5%AE%9E%E7%8E%B0/" class="article-link"
                 id="article-link-bigger">
                    <div>
                        <div class="image-container">
                            <img src="" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                Hexo中NexT主题下基于Fancybox的相册页面实现
                            </h2>
                            <p class="article-excerpt">
                                
                            </p>
                            <div class="article-metadata">
                                March 5, 2022 · 3 min read
                            </div>
                        </div>
                    </div>
                </a>
            
                <a href="/post/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E6%80%BB%E7%BB%93/" class="article-link"
                >
                    <div>
                        <div class="image-container">
                            <img src="" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                《数字图像处理学》中的基础概念与课后习题总结
                            </h2>
                            <p class="article-excerpt">
                                
                            </p>
                            <div class="article-metadata">
                                March 3, 2022 · 36 min read
                            </div>
                        </div>
                    </div>
                </a>
            
        </div>
    </div>
</section>

</section>


 <script src="/js/progressBar.js"></script>

        
        <div class="footer-gradient"></div>
    <div class="section narrow">
      <div class="footer-hr"></div>
      <div class="footer-container">
        <div class="footer-text">
          © 2022 yzhn&#39;s Notes
        </div>
        <div class="social-icon-outer">
    <div class="social-icon-container">
        
            
                
                <a href="https://github.com/yzhn16/"><svg
class="social-icon-image"
width="14"
height="14"
viewBox="0 0 14 14"
fill="none"
xmlns="http://www.w3.org/2000/svg"
>
<path
  fillRule="evenodd"
  clipRule="evenodd"
  d="M7 0C3.1325 0 0 3.21173 0 7.17706C0 10.3529 2.00375 13.0353 4.78625 13.9863C5.13625 14.0491 5.2675 13.8338 5.2675 13.6454C5.2675 13.4749 5.25875 12.9097 5.25875 12.3087C3.5 12.6406 3.045 11.8691 2.905 11.4653C2.82625 11.259 2.485 10.622 2.1875 10.4516C1.9425 10.317 1.5925 9.98508 2.17875 9.97611C2.73 9.96714 3.12375 10.4964 3.255 10.7118C3.885 11.7973 4.89125 11.4923 5.29375 11.3039C5.355 10.8374 5.53875 10.5234 5.74 10.3439C4.1825 10.1645 2.555 9.54549 2.555 6.80026C2.555 6.01976 2.82625 5.37382 3.2725 4.87143C3.2025 4.692 2.9575 3.95635 3.3425 2.96951C3.3425 2.96951 3.92875 2.78111 5.2675 3.70516C5.8275 3.54367 6.4225 3.46293 7.0175 3.46293C7.6125 3.46293 8.2075 3.54367 8.7675 3.70516C10.1063 2.77214 10.6925 2.96951 10.6925 2.96951C11.0775 3.95635 10.8325 4.692 10.7625 4.87143C11.2087 5.37382 11.48 6.01079 11.48 6.80026C11.48 9.55446 9.84375 10.1645 8.28625 10.3439C8.54 10.5682 8.75875 10.9988 8.75875 11.6717C8.75875 12.6316 8.75 13.4032 8.75 13.6454C8.75 13.8338 8.88125 14.0581 9.23125 13.9863C11.9963 13.0353 14 10.3439 14 7.17706C14 3.21173 10.8675 0 7 0Z"
  fill="#73737D"
/>
</svg></a>
                <span class="hidden">https://github.com/yzhn16/</span>
            
        
    </div>
</div>
    </div>
</div>

    </div>

    
    <script src="/js/prism.js"></script>
</body>

</html>