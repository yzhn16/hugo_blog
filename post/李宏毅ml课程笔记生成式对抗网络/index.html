<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" href="/images/favicon.svg">
    
    <link rel="stylesheet" href="/scss/global.min.21bde5c4790756f13e2e070d4373cff76d70cc802499075fa5f879b325f907f2.css">
    
    <link rel="stylesheet" href="/css/prism.css" />
    <link href="https://fonts.googleapis.com/css?family=Merriweather&display=swap" rel="stylesheet">
    

 






	




<title>李宏毅ML课程笔记——生成式对抗网络（GAN） | yzhn&#39;s Notes</title>
<meta name="description" content="李宏毅2021/2022春机器学习课程——生成式对抗网络">
<meta property="og:title" content="李宏毅ML课程笔记——生成式对抗网络（GAN） | yzhn&#39;s Notes">
<meta property="og:site_name" content="yzhn&#39;s Notes">
<meta property="og:description" content="李宏毅2021/2022春机器学习课程——生成式对抗网络">
<meta property="og:url" content="/post/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/">
<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:image" content='/uploads/default.jpg'><meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="李宏毅ML课程笔记——生成式对抗网络（GAN） | yzhn&#39;s Notes">

	<link rel="canonical" href="/post/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/">


	<meta name="twitter:description" content="李宏毅2021/2022春机器学习课程——生成式对抗网络">
<meta name="twitter:image" content="/uploads/default.jpg">
<meta property="article:published_time" content="2022-05-13T17:45:00&#43;00:00">
	<meta property="article:updated_time" content="2022-05-13T17:45:00&#43;00:00">



    </head>


<body class="line-numbers">

    
    <script src="/js/initColors.js"></script>

    <div class="layout-styled">

        <Section class="section">
  <div class="nav-container">
    <a class="logo-link" href="/">
      <div id="logo-desktop">
        <svg
        width="192"
        height="23"
        viewBox="0 0 192 23"
        fill="none"
        xmlns="http://www.w3.org/2000/svg"
        className="Logo__Desktop"
      >
        <g clipPath="url(#clip0)">
          <path
            d="M120.941 6.15477H122.453V2.83255L124.114 2.44922V6.15477H126.713V7.30477H124.114V16.377C124.114 17.314 124.54 17.7826 125.435 17.7826C125.925 17.7826 126.478 17.6335 126.904 17.4205L127.181 18.4214C126.606 18.7835 125.861 18.9964 124.86 18.9964C123.539 18.9964 122.432 18.3788 122.432 16.5261V7.30477H120.92V6.15477H120.941Z"
            fill="#7A8085"
          />
          <path
            d="M131.739 7.77334C132.825 6.70852 134.273 5.89926 135.764 5.89926C137.723 5.89926 138.937 6.94278 138.937 9.17889V17.6122L140.555 17.8465V18.7409H137.233V9.58352C137.233 7.9863 136.616 7.30482 135.338 7.30482C134.166 7.30482 132.74 8.0076 131.739 8.90204V17.5909L133.442 17.8039V18.7196H128.416V17.8039L130.078 17.5909V1.29926L128.374 1.04371V0.0214844H131.739V7.77334V7.77334Z"
            fill="#7A8085"
          />
          <path
            d="M141.854 12.4374C141.854 7.6883 143.92 5.89941 146.731 5.89941C149.648 5.89941 151.267 7.64571 151.267 11.9689V12.629H143.6C143.621 16.3772 144.686 17.8253 147.284 17.8253C148.605 17.8253 149.584 17.3994 150.5 16.7818L151.096 17.6124C150.01 18.5068 148.754 18.9966 147.008 18.9966C143.941 18.9753 141.854 17.2929 141.854 12.4374ZM143.621 11.5216H149.521C149.521 8.34849 148.754 6.98552 146.709 6.98552C144.857 6.98552 143.771 8.2633 143.621 11.5216Z"
            fill="#7A8085"
          />
          <path
            d="M162.682 7.85849C163.768 6.70849 165.024 5.87793 166.515 5.87793C168.474 5.87793 169.646 6.92145 169.646 9.15756V17.6335L171.286 17.8677V18.6983H167.963V9.68997C167.963 8.07145 167.388 7.32608 166.089 7.32608C164.918 7.32608 163.789 8.02886 162.81 8.9233V17.6122L164.449 17.8464V18.7409H161.127V9.68997C161.127 8.07145 160.552 7.32608 159.253 7.32608C158.082 7.32608 156.953 8.02886 155.973 8.9233V17.6122L157.677 17.8464V18.7409H152.651V17.8464L154.312 17.6122V7.47515L152.609 7.2196V6.15478H155.654L155.888 7.85849C156.974 6.72978 158.188 5.89923 159.679 5.89923C161.212 5.87793 162.277 6.51682 162.682 7.85849Z"
            fill="#7A8085"
          />
          <path
            d="M171.925 12.4374C171.925 7.6883 173.991 5.89941 176.802 5.89941C179.719 5.89941 181.338 7.64571 181.338 11.9689V12.629H173.671C173.692 16.3772 174.757 17.8253 177.355 17.8253C178.676 17.8253 179.655 17.3994 180.571 16.7818L181.167 17.6124C180.081 18.5068 178.825 18.9966 177.079 18.9966C174.012 18.9753 171.925 17.2929 171.925 12.4374ZM173.692 11.5216H179.591C179.591 8.34849 178.825 6.98552 176.78 6.98552C174.928 6.98552 173.863 8.2633 173.692 11.5216Z"
            fill="#7A8085"
          />
          <path
            d="M183.084 18.0383V15.504H184.234L184.618 17.442C185.278 17.7189 185.789 17.8892 186.811 17.8892C188.664 17.8892 189.558 17.0374 189.558 15.5466C189.558 14.0559 188.834 13.4809 186.79 12.8846C184.831 12.2883 183.382 11.4577 183.382 9.13645C183.382 7.39016 184.639 5.89941 187.195 5.89941C188.664 5.89941 189.835 6.17627 190.687 6.68738V9.15775H189.558L189.132 7.34756C188.579 7.09201 187.961 7.00682 187.258 7.00682C185.789 7.00682 184.852 7.7309 184.852 8.98738C184.852 10.3077 185.576 10.8189 187.365 11.3513C189.431 12.0115 191.156 12.7142 191.156 15.3976C191.156 17.7615 189.431 18.9753 186.79 18.9753C185.235 18.9753 183.957 18.6346 183.084 18.0383Z"
            fill="#7A8085"
          />
          <path class="change-fill"
            d="M38.3122 9.98811C38.3122 8.66774 37.9501 8.15663 36.9492 8.15663C36.1186 8.15663 35.0964 8.62515 34.3936 9.20015V16.9733L35.8418 17.165V18.6344H30.0918V17.165L31.5825 16.9733V8.24182L30.0918 7.92237V6.19737H33.9251L34.2446 7.64552C35.3733 6.55941 36.6298 5.87793 38.1418 5.87793C39.9946 5.87793 41.102 6.92145 41.102 9.07237V16.9733L42.5927 17.165V18.6344H38.3122V9.98811V9.98811Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M62.3982 17.1858V18.6553H56.0732V17.1858L57.564 16.9942V8.2627L56.0732 7.94326V6.21826H59.8427L60.226 8.17752C61.0779 6.85715 62.1427 5.94141 63.6973 5.94141C63.8677 5.94141 64.0594 5.9627 64.1871 6.0053L63.8251 8.94418C63.5483 8.81641 63.2501 8.77381 62.8668 8.77381C61.8871 8.77381 61.1418 9.05067 60.3751 9.71085V16.9516L62.3982 17.1858Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M76.7098 6.19733H78.0941V3.08807L80.5432 2.55566V6.21863H82.9709V8.0927H80.5432V15.6742C80.5432 16.5899 80.8839 16.9946 81.6293 16.9946C82.0978 16.9946 82.5876 16.8455 82.907 16.6751L83.3543 18.3575C82.758 18.6983 81.9061 18.9751 80.6709 18.9751C78.9672 18.9751 78.0941 18.1658 78.0941 16.0362V8.0927H76.7098V6.19733Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M90.4664 17.1648V18.6343H84.6738V17.1648L86.1646 16.9731V8.24167L84.6738 7.92222V6.19722H88.9757V16.9731L90.4664 17.1648ZM85.696 1.76759C85.696 0.787963 86.4627 0 87.4423 0C88.422 0 89.1886 0.766667 89.1886 1.76759C89.1886 2.72593 88.422 3.51389 87.421 3.51389C86.4627 3.51389 85.696 2.72593 85.696 1.76759Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M98.3251 7.90097V6.19727H103.053V7.92227L101.924 8.11393L98.3251 18.6556H95.663L92.064 8.09264L90.9991 7.92227V6.19727H96.2593V7.90097L95.0242 8.09264L96.7279 13.6084C97.0473 14.6519 97.1964 15.5037 97.3668 16.4834H97.388C97.5371 15.525 97.7714 14.5241 98.0482 13.5871L99.6668 8.07134L98.3251 7.90097Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M75.6867 17.1224C74.5793 17.1437 74.3664 16.952 74.3664 15.9724V9.79645C74.3664 6.96404 72.9821 5.87793 70.3201 5.87793C68.3821 5.87793 66.7423 6.45293 65.4219 7.28349L66.2312 9.02978C67.3599 8.45478 68.4673 8.09274 69.7238 8.09274C71.1932 8.09274 71.5552 8.88071 71.5552 10.265V11.0316V11.2233V12.7779V12.8844V16.1214C71.0867 16.6326 70.4052 17.0585 69.4469 17.0585C68.3821 17.0585 67.871 16.5261 67.871 15.0353C67.871 13.3103 68.5951 12.8205 70.4904 12.7779V11.2233C66.6358 11.2659 65.0386 12.4372 65.0386 15.2057C65.0386 17.8465 66.4867 18.9752 68.6589 18.9752C70.2136 18.9752 71.0654 18.315 71.7895 17.5696C72.0451 18.5705 72.833 18.9752 73.8978 18.9752C74.6645 18.9752 75.3886 18.7622 75.8571 18.5066L75.6867 17.1224Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M54.4968 17.1224C53.3894 17.1437 53.1764 16.952 53.1764 15.9724V9.79645C53.1764 6.96404 51.7922 5.87793 49.1301 5.87793C47.1922 5.87793 45.5523 6.45293 44.232 7.28349L45.0412 9.02978C46.1699 8.45478 47.2773 8.09274 48.5338 8.09274C50.0033 8.09274 50.3653 8.88071 50.3653 10.265V11.0316V11.2233V12.7779V12.8844V16.1214C49.8968 16.6326 49.2153 17.0585 48.257 17.0585C47.1922 17.0585 46.681 16.5261 46.681 15.0353C46.681 13.3103 47.4051 12.8205 49.3005 12.7779V11.2233C45.4459 11.2659 43.8486 12.4372 43.8486 15.2057C43.8486 17.8465 45.2968 18.9752 47.469 18.9752C49.0236 18.9752 49.8755 18.315 50.5996 17.5696C50.8551 18.5705 51.6431 18.9752 52.7079 18.9752C53.4746 18.9752 54.1986 18.7622 54.6672 18.5066L54.4968 17.1224Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M107.653 13.055H113.594V11.9476C113.594 7.47534 111.869 5.89941 108.803 5.89941C105.63 5.89941 103.628 7.79478 103.628 12.4161C103.628 17.1013 105.523 18.9966 109.058 18.9966C110.954 18.9966 112.231 18.5068 113.467 17.5272L112.657 16.0577C111.678 16.6753 110.868 17.0587 109.463 17.0587C107.546 17.0587 106.801 16.1855 106.63 14.0133C106.588 13.6939 106.567 13.0976 106.567 12.4587C106.567 12.054 106.567 11.6707 106.588 11.3726V11.3513C106.737 8.51886 107.397 7.60312 108.781 7.60312C110.4 7.60312 110.783 8.58275 110.783 11.3513H107.674V13.055H107.653Z"
            fill="#000"
          />
          <path class="change-fill" d="M17.5907 20.2954H0V23H17.5907V20.2954Z" fill="#000" />
          <path class="change-fill"
            d="M0 7.96484V18.9537L5.38796 15.1843V11.7343L0 7.96484Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M17.5689 10.9463V0L12.1597 3.74815V7.13426L17.5689 10.9463Z"
            fill="#000"
          />
          <path class="change-fill"
            d="M17.5907 18.975L17.5694 12.288L0 0V6.62315L17.5907 18.975Z"
            fill="#000"
          />
        </g>
        <defs>
          <clipPath id="clip0">
            <rect width="191.156" height="23" fill="white" />
          </clipPath>
        </defs>
      </svg>
</div>
<div id="logo-mobile" class="hidden">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
    width="23" height="23" viewBox="0 0 512.000000 512.000000"
    preserveAspectRatio="xMidYMid meet">
   <metadata>
   Created by potrace 1.15, written by Peter Selinger 2001-2017
   </metadata>
   <g transform="translate(0.000000,512.000000) scale(0.100000,-0.100000)"
   fill="" stroke="none">
   <path d="M590 4383 l1 -738 756 -530 c698 -489 1151 -807 2618 -1837 l540
   -380 3 748 c2 590 -1 751 -10 760 -7 7 -308 218 -668 470 -360 251 -1230 859
   -1933 1351 -702 491 -1284 893 -1292 893 -13 0 -15 -92 -15 -737z"/>
   <path d="M3887 4708 l-597 -412 0 -381 0 -381 597 -419 c328 -231 602 -421
   610 -423 11 -3 13 204 13 1212 0 987 -2 1216 -13 1216 -7 0 -282 -186 -610
   -412z"/>
   <path d="M590 2135 c0 -910 3 -1225 11 -1225 10 0 343 231 1049 728 l155 109
   0 389 0 388 -595 418 c-327 229 -601 417 -607 418 -10 0 -13 -251 -13 -1225z"/>
   <path d="M590 320 l0 -310 1960 0 1960 0 0 310 0 310 -1960 0 -1960 0 0 -310z"/>
   </g>
   </svg>
</div>
      <span class="header-hidden">Navigate back to the homepage</span>
    </a>
    <div class="nav-controls">
      <button id="copyButton" class="icon-wrapper">
        <svg
    class="icon-image"
    width="24"
    height="20"
    viewBox="0 0 24 20"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
    >
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M2 5C2 3.34328 3.34328 2 5 2H14C15.6567 2 17 3.34328 17 5V9C17 10.6567 15.6567 12 14 12H10C9.44771 12 9 12.4477 9 13C9 13.5523 9.44771 14 10 14H14C16.7613 14 19 11.7613 19 9V5C19 2.23872 16.7613 0 14 0H5C2.23872 0 0 2.23872 0 5V9C0 10.4938 0.656313 11.8361 1.6935 12.7509C2.10768 13.1163 2.73961 13.0767 3.10494 12.6625C3.47028 12.2483 3.43068 11.6164 3.0165 11.2511C2.39169 10.6999 2 9.89621 2 9V5ZM7 11C7 9.34328 8.34328 8 10 8H14C14.5523 8 15 7.55228 15 7C15 6.44772 14.5523 6 14 6H10C7.23872 6 5 8.23872 5 11V15C5 17.7613 7.23872 20 10 20H19C21.7613 20 24 17.7613 24 15V11C24 9.50621 23.3437 8.16393 22.3065 7.24906C21.8923 6.88372 21.2604 6.92332 20.8951 7.3375C20.5297 7.75168 20.5693 8.38361 20.9835 8.74894C21.6083 9.30007 22 10.1038 22 11V15C22 16.6567 20.6567 18 19 18H10C8.34328 18 7 16.6567 7 15V11Z"
      fill="#000"
    />
</svg>
        <div id="toolTip" class="tool-tip " >
            copied
        </div>
        <input id="copyText" style="opacity: 0;" type="text" class="tool-tip " />
      </button>

      <button id="themeColorButton" class="icon-wrapper"> 
        <div id="sunRays" class="sun-rays"></div>
        <div id="moonOrSun" class="moon-or-sun"></div>
        <div id="moonMask" class="moon-mask"></div>
      </button>
    </div>
</div>
</Section>


<script src="/js/toggleLogos.js"></script>


<script src="/js/toggleColors.js"></script>


<script src="/js/copyUrl.js"></script>

        

<section class="section narrow">

    <section id="articleHero" class="section narrow">
    <div class="article-hero">
        <header class="article-header">
            <h1 class="article-hero-heading">李宏毅ML课程笔记——生成式对抗网络（GAN）</h1>
            <div class="article-hero-subtitle">
                <div class="article-meta">
                    


    <div class="article-coauthors-container">
        
        <span id="collapsedCoauthors" class="article-coauthors-collapsed">
            <div class="article-coauthors-list" style="width: 0px;">
                
            </div>
            <strong class="article-coauthors-name-container">
                
            </strong>
            <div class="article-coauthors-icon-container">
                <svg
width="17"
height="17"
viewBox="0 0 17 17"
fill="none"
xmlns="http://www.w3.org/2000/svg"
>
    <path style="fill: var(--primary);"
      d="M5.3209 8.86719L8.50026 12.0396L11.6796 8.86719L12.6563 9.84385L8.50026 13.9999L4.34424 9.84385L5.3209 8.86719Z"
    />
    <path style="fill: var(--primary);"
      d="M11.6791 8.13281L8.49974 4.96039L5.32039 8.13281L4.34373 7.15615L8.49974 3.00013L12.6558 7.15615L11.6791 8.13281Z"
    />
</svg>
            </div>
        </span>

        <ul id="uncollapsedCoauthors" class="article-coauthors-list-open hidden">
            <div id="uncollapsedAction" class="article-icon-open-container">
                <svg
width="17"
height="17"
viewBox="0 0 17 17"
fill="none"
xmlns="http://www.w3.org/2000/svg"
>
    <path style="fill: var(--primary);"
      d="M11.6796 14L8.50023 10.8276L5.32088 14L4.34422 13.0233L8.50023 8.86732L12.6563 13.0233L11.6796 14Z"
    />
    <path style="fill: var(--primary);"
      d="M5.32041 3L8.49977 6.17243L11.6791 3L12.6558 3.97666L8.49977 8.13268L4.34375 3.97666L5.32041 3Z"
    />
</svg>
            </div>
            
        </ul>
    </div>



<script src="/js/collapseAuthors.js"></script>
                    May 13, 2022
                    • 10 min read
                </div>
            </div>
        </header>
        
    </div>
</section>


    <aside id="progressBar" class="aside-container">
    <div class="aside-align">
      <div>
        <div class="overlap-container">
        </div>
      </div>
    </div>

    <div class="progress-container" tabIndex={-1}>
        <div class="track-line" aria-hidden="true">
            <div id="progressIndicator" class="progress-line"></div>
        </div>
    </div>
</aside>


    <article  id="articleContent" class="post-content" style="position:relative;">
        <p><a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=58">李宏毅2021/2022春机器学习课程——生成式对抗网络</a></p>
<h1 id="生成式对抗网络gan">生成式对抗网络（GAN）</h1>
<h2 id="generator">Generator</h2>
<h3 id="network-as-generator">Network as Generator</h3>
<p>输入$x$和一个简单的分布$z$（不固定，从一个分布中采样得到，每次使用网络时都会随机生成。），经过网络输出一个复杂的分布$y$。这样的网络称为<strong>Generator</strong>。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-1/generator.png" style="zoom:50%;" />
<h3 id="why-distribution">Why distribution？</h3>
<p>当任务需要一些“创造力”时（同样的输入有多种可能的输出），需要预测分布。</p>
<ul>
<li>
<p>eg1. <em>Video Prediction</em></p>
<p>输入：吃豆人游戏的历史帧序列</p>
<p>输出：吃豆人游戏新一帧的内容（吃豆人可能向不同的方向移动）</p>
</li>
<li>
<p>eg2. <em>Drawing</em></p>
<p>输入：“Character with red eyes”</p>
<p>输出1：酷拉皮卡</p>
<p>输出2：辉夜</p>
</li>
<li>
<p>eg3. <em>Chatbot</em></p>
<p>输入：“你知道辉夜是谁吗？”</p>
<p>输出1：“她是秀知院学生会&hellip;”</p>
<p>输出2：“她开创了忍者时代&hellip;”</p>
</li>
</ul>
<h2 id="generative-adversarial-networkgan">Generative Adversarial Network（GAN）</h2>
<ul>
<li><a href="https://github.com/hindupuravinash/the-gan-zoo">hindupuravinash/the-gan-zoo: A list of all named GANs! (github.com)</a></li>
</ul>
<h3 id="anime-face-generation">Anime Face Generation</h3>
<p><strong>Unconditional generation</strong></p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-1/unconditional.png" style="zoom:50%;" />
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/24767059">GAN学习指南：从原理入门到制作生成Demo - 知乎 (zhihu.com)</a></li>
</ul>
<h3 id="discriminator">Discriminator</h3>
<p>Discriminator本身也是一个网络，Discriminator拿一张图片作为输入，输出一个数值。数字越大，表示图片越接近真实的图片。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-1/discriminator.png" style="zoom:50%;" />
<h3 id="basic-idea-of-gan">Basic Idea of GAN</h3>
<blockquote>
<p>写作敌人，念做朋友。</p>
</blockquote>
<p>二者关系好比Generator造假钞，Discriminator是抓造假钞的警察，Generator越来越像，Discriminator的辨别能力越来越强。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-1/basic%20idea.png" style="zoom:50%;" />
<h3 id="algorithm">Algorithm</h3>
<p>首先初始化generator $G$和discriminator $D$，在每一次训练中：</p>
<ul>
<li>
<p>Step 1：定住$G$，更新$D$</p>
<p>$D$学习去给真实二次元人物赋予更高的分数，而为生成的二次元人物赋予更低的分数。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-1/step1.png" style="zoom:50%;" />
<p>$D$分辨真正的二次元人物和生成的二次元人物之间的差异，可以当作一个分类或回归任务处理。</p>
</li>
<li>
<p>Step 2：定住$D$，更新$G$</p>
<p>$G$学习去“骗过”$D$，经过调整后，使得生成的图片能在$D$中产生更高的分数。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-1/step2.png" style="zoom:50%;" />
</li>
</ul>
<h2 id="theory-behind-gan">Theory behind GAN</h2>
<h3 id="objective">Objective</h3>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-2/objective.png" style="zoom:50%;" />
<p>$$
G^\ast=\arg\min_G Div(P_G,P_{data})
$$</p>
<p>其中$Div(P_G,P_{data})$是$P_G$与$P_{data}$之间的散度（Divergence），可以看作是两个分布之间某种距离，散度越大，代表两个分布越不像，散度越小，代表两个分布越相近。c.f. $w^\ast,b^\ast=\arg\min_{w,b}L$</p>
<h3 id="sampling">Sampling</h3>
<p>虽然不清楚$P_G$和$P_{data}$的分布，但是可以从其中采样来计算散度。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-2/sampling.png" style="zoom:50%;" />
<h3 id="discriminator-1">Discriminator</h3>
<ul>
<li>[<a href="https://arxiv.org/abs/1406.2661">1406.2661] Generative Adversarial Networks (arxiv.org)</a></li>
</ul>
<p>Discriminator的训练目标是看到真实数据就给出一个高的分数，看到生成数据就给出一个低的分数。</p>
<ul>
<li>
<p><strong>Training</strong>：$D^\ast=\arg\max_DV(D,G)$</p>
</li>
<li>
<p><strong>Objective Function</strong> for $D$：$V(G,D)=E_{y\sim P_{data}}[\log D(y)]+E_{y\sim P_G}[\log(1-D(y))]$</p>
</li>
</ul>
<p>$V(D,G)$是交叉熵的相反数，Discriminator可以等同于一个分类器，最小化交叉熵。而正好$\max_DV(D,G)$就和<strong>JS散度</strong>有关。</p>
<p>最开始，$P_G$和$P_{data}$混在一起，散度很小，Discriminator难以分辨哪些数据是生成数据而哪些数据是真实数据，即Discriminator难以区分小的$max_D{V(D,G)}$。</p>
<p>若$P_G$和$P_{data}$散度很大，$max_DV(D,G)$比较大，DIscriminator则很容易区分生成数据和真实数据。</p>
<p>此时，有：
$$
G^\ast=\arg\min_G\max_DV(G,D)
$$</p>
<h3 id="why-js-divergence">Why JS Divergence？</h3>
<p>除了JS散度，也可以使用例如KL散度等其他散度。如何设计目标函数，得到不同的散度，在f-GAN论文中有详细的证明。</p>
<ul>
<li>[<a href="https://arxiv.org/abs/1606.00709">1606.00709] f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization (arxiv.org)</a></li>
</ul>
<h2 id="tips-for-gan">Tips for GAN</h2>
<h3 id="js散度的问题">JS散度的问题</h3>
<p>在大多数情况下，$P_G$和$P_{data}$重复的部分非常少。</p>
<ul>
<li>
<p>数据本身的特性：数据是高维空间中的低维流形，重叠的部分可以忽略。</p>
<blockquote>
<p>流形学习的观点认为，我们所能观察到的数据实际上是由一个低维流形映射到高维空间上的。由于数据内部特征的限制，一些高维中的数据会产生维度上的冗余，实际上只需要比较低的维度就能唯一地表示。例如单位圆上有无穷多个点，无法用二唯坐标系上的点来表示圆上所有的点，而若使用极坐标，圆心在原点的圆只需一个参数——半径，就可以确定。</p>
</blockquote>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-2/manifold.png" style="zoom:50%;" />
</li>
<li>
<p>采样：即使$P_G$和$P_{data}$有重叠，若采样的点不够多，对Discriminator来说也是没有重叠的。</p>
</li>
</ul>
<p>而以上的问题会导致JS散度出现问题。</p>
<p>在两个分布完全不重叠时，无论两个分布的中心距离有多近，其JS散度都是一个常数$\log2$，无法判断哪个case更好，从而无法更新参数。</p>
<p>参考证明：<a href="https://www.cnblogs.com/MorStar/p/14882813.html">JS散度(Jensen–Shannon divergence) - MorStar - 博客园 (cnblogs.com)</a></p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-2/js%20div%20problem.png" style="zoom:50%;" />
<p>直观来看，如果两个分布不重叠，二分类的准确率几乎可以达到100%。</p>
<h3 id="wasserstein-distance">Wasserstein distance</h3>
<p>考虑两个分布$P$和$Q$，想象一台推土机，$P$是一堆土，$Q$是要堆放的目的地，把$P$挪动到$Q$的平均距离就是Wasserstein distance。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-2/wasserstein%20distance.png" style="zoom:50%;" />
<p>考虑更复杂的情况，移动的方案可能有无穷多种。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-2/wasserstein%20distance2.png" style="zoom:50%;" />
<p>穷举所有的移动方法，看哪一个移动方法可以让平均的距离最小，最小的值就是Wasserstein distance。但计算方法似乎比较复杂，要计算距离还需要求解这样一个最优化问题。</p>
<p>假设现在我们已经可以计算Wasserstein distance，就可以解决JS散度带来的问题。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-2/wasserstein%20distance3.png" style="zoom:50%;" />
<h3 id="wgan">WGAN</h3>
<p>WGAN使用Wasserstein distance取代JS散度。</p>
<p>省略过程，要得到Wasserstein distance，只需解以下这个式子：
$$
\max_{D\in 1-Lipschitz}{E_{y\sim P_{data}}[D(y)]-E_{y\sim P_G}[D(y)]}
$$
$D\in 1-Lipschitz$：$D$需要是一个足够平滑的函数，不能是变动很剧烈的函数，若没有这个限制，单纯让生成数据越小越好，真实数据越大越好，在生成数据和真实数据没有重叠的情况下，会给真实数据无穷大的正值而给生成数据无穷小的负值。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-2/wasserstein%20distance4.png" style="zoom:50%;" />
<h3 id="din-1-lipschitz">$D\in 1-Lipschitz$</h3>
<ul>
<li>
<p>Original WGAN：Weight</p>
<p>强制参数$w$在$c$和$-c$之间，参数更新后若$w\gt c$，则$w=c$，若$w\lt -c$，则$w=-c$。</p>
</li>
<li>
<p>Improved WGAN：Gradient Penalty</p>
<p>在真实数据和生成数据中各取一个样本，两点连线中再取一个样本，要求这个点的梯度接近1。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-2/gradient%20penalty.png" style="zoom:50%;" />
<ul>
<li>[<a href="https://arxiv.org/abs/1704.00028">1704.00028] Improved Training of Wasserstein GANs (arxiv.org)</a></li>
</ul>
</li>
<li>
<p>Spectral Normalization（SNGAN）：让梯度模长在任何地方都小于1</p>
<ul>
<li>[<a href="https://arxiv.org/abs/1802.05957">1802.05957] Spectral Normalization for Generative Adversarial Networks (arxiv.org)</a></li>
</ul>
</li>
</ul>
<h3 id="more-tips">More Tips</h3>
<ul>
<li>Tops from Soumith
<ul>
<li><a href="https://github.com/soumith/ganhacks">soumith/ganhacks: starter from &ldquo;How to Train a GAN?&rdquo; at NIPS2016 (github.com)</a></li>
</ul>
</li>
<li>Tips in DCGAN：Guideline for network architecture design for image generation
<ul>
<li>[<a href="https://arxiv.org/abs/1511.06434">1511.06434] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (arxiv.org)</a></li>
</ul>
</li>
<li>Improved techniques for training GANs
<ul>
<li>[<a href="https://arxiv.org/abs/1606.03498">1606.03498] Improved Techniques for Training GANs (arxiv.org)</a></li>
</ul>
</li>
<li>Tips from BigGAN
<ul>
<li>[<a href="https://arxiv.org/abs/1809.11096">1809.11096] Large Scale GAN Training for High Fidelity Natural Image Synthesis (arxiv.org)</a></li>
</ul>
</li>
</ul>
<p>GAN的训练需要Generator和Discriminator共同配合，若有其中一方不再进步，另一方也会停下来，<em>Generator和Discriminator需要棋逢敌手</em>。</p>
<h2 id="gan-for-sequence-generation">GAN for Sequence Generation</h2>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/GAN%20seq.png" style="zoom:50%;" />
<p>Decoder参数改变后，经过max输出的文字可能不会发生改变，就无法完成参数更新。可以用RL来训练。</p>
<ul>
<li>[<a href="https://arxiv.org/abs/1905.09922">1905.09922] Training language GANs from Scratch (arxiv.org)</a></li>
</ul>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/scratch.png" style="zoom:50%;" />
<h2 id="more-generative-models">More Generative Models</h2>
<ul>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw">GAN（Full version）</a></li>
<li><a href="https://youtu.be/8zomhgKrsmQ">Variational Autoencoder（VAE）</a></li>
<li><a href="https://youtu.be/uXY18nzdSsM">FLOW-based Model</a></li>
</ul>
<h2 id="evaluation-of-generation">Evaluation of Generation</h2>
<h3 id="quality-of-image">Quality of Image</h3>
<p>评价图像质量最直接的做法是找人来看，在Generator研究初期，有人会选几张图说“看，这个结果应该比目前的结果都要好，应该是SOTA。”，这显然不够客观，如何自动地评价生成图像的质量？</p>
<p>一个方法是使用图像分类器，输入一张图片$y$，输出图片属于各个类的概率分布$p(c|y)$，分布越集中，产生的图片可能就越好。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/quality%20of%20img.png" style="zoom:50%;" />
<h3 id="diversity---mode-collapse">Diversity - Mode Collapse</h3>
<p>仅使用以上这种方法评估图像质量时可能会遇到Mode Collapse（模式坍塌）的问题。</p>
<p>训练GAN的过程可能会遇到以下问题：</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/mode%20collapse.png" style="zoom:50%;" />
<p>Generator生成出来的图片可能来来去去都是那几张：</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/mode%20collapse2.png" style="zoom:50%;" />
<p>直觉上看，这样的点是Discriminator的“盲点”，Discriminator没办法看出这样的图片是假的，当Generator学会产生这种图片后，就永远都可以骗过Discriminator。</p>
<h3 id="diversity---mode-dropping">Diversity - Mode Dropping</h3>
<p>Mode Dropping可能比Mode Collapse更难侦测出来，产生出来的数据可能只能贴近已有真实数据的分布，但真实的数据分布的多样性其实是更大的。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/mode%20dropping.png" style="zoom:50%;" />
<p>一个人脸生成的例子：</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/mode%20dropping2.png" style="zoom:50%;" />
<h3 id="diversity">Diversity</h3>
<p>过去判定多样性的做法是将一批图片输入到图片分类器中，计算所有图片的概率分布的均值，若平均的分布非常集中，则代表多样性不够。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/diversity.png" style="zoom:50%;" />
<p>若输入这批图片产生的分布都非常不同，平均后的结果非常平坦，则代表多样性是足够的。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/diversity2.png" style="zoom:50%;" />
<p>Diversity和Quality的评估方式相反，Diversity看的是一批图片的平均，而Quality看的是一张图片。</p>
<p><strong>Inception Score（IS）</strong>：质量越高，多样性越大，则IS越高。</p>
<h3 id="fréchet-inception-distancefid">Fréchet Inception Distance（FID）</h3>
<ul>
<li>[<a href="https://arxiv.org/abs/1706.08500">1706.08500] GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium (arxiv.org)</a></li>
</ul>
<p>取Softmax前的输出向量，假设真实图像和生成图像都是高斯分布，计算这两个高斯分布之间的Fréchet distance，这个距离越小说明真实图像与生成图像越接近，生成图像品质越高。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/FID.png" style="zoom:50%;" />
<p>可能需要大量的图片样本才能做到。</p>
<ul>
<li>[<a href="https://arxiv.org/abs/1711.10337">1711.10337] Are GANs Created Equal? A Large-Scale Study (arxiv.org)</a></li>
</ul>
<h3 id="we-dont-want-memory-gan">We don&rsquo;t want memory GAN</h3>
<p>生成出来的图片有可能和训练集一模一样，这种情况下FID非常小，也有可能仅仅把图片翻转，这样很难侦测出来。</p>
<ul>
<li>[<a href="https://arxiv.org/abs/1511.01844">1511.01844] A note on the evaluation of generative models (arxiv.org)</a></li>
</ul>
<h3 id="more-about-evaluation">More about evaluation</h3>
<ul>
<li>[<a href="https://arxiv.org/abs/1802.03446">1802.03446] Pros and Cons of GAN Evaluation Measures (arxiv.org)</a></li>
</ul>
<h2 id="conditional-generation">Conditional Generation</h2>
<p>前面所提到的Unconditional GAN的输入都是一个随机的分布。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/conditional%20generation.png" style="zoom:50%;" />
<p>例如要做文本转图片，需要给模型一个文本输入$x$。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/text-to-img.png" style="zoom:50%;" />
<h3 id="conditional-gan">Conditional GAN</h3>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/conditional%20GAN.png" style="zoom:50%;" />
<p>在Unconditional GAN中，Discriminator接受一个图片$y$作为输入，输出一个数值，代表图片是真实的或是生成的，但这样的方法无法解Conditional GAN的问题，Generator可以产生非常接近真实的图片，但是忽略了输入的条件。</p>
<p>Conditional GAN中，需要成对的训练数据。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-3/conditional%20GAN2.png" style="zoom:50%;" />
<p>Conditional GAN也可以用图像来生成图像，例如图像去雾，黑白转彩色，白天转黑夜，素描转实物。也叫<strong>Image translation</strong>或<strong>pix2pix</strong>。</p>
<p>通常可以将GAN和有监督学习结合，得到更好的结果。</p>
<h3 id="其他应用">其他应用</h3>
<ul>
<li>Sound-to-image</li>
<li>Talking Head Generation
<ul>
<li>[<a href="https://arxiv.org/abs/1905.08233">1905.08233] Few-Shot Adversarial Learning of Realistic Neural Talking Head Models (arxiv.org)</a></li>
</ul>
</li>
</ul>
<h2 id="learning-from-unpaired-data">Learning from Unpaired Data</h2>
<p>有一堆$x$和一堆$y$，但$x$和$y$不成对（未标注）。pseudo labeling（伪标签）和back translation（反向翻译）都需要一些成对的数据。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-4/unpaired%20data.png" style="zoom:50%;" />
<p>例如在影像风格转换，将定义域$\mathcal{X}$真人头像转为定义域$\mathcal{Y}$二次元头像：</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-4/image%20style%20transfer.png" style="zoom:50%;" />
<h3 id="cycle-gan">Cycle GAN</h3>
<p>输入一个Domain $\mathcal{X}$，输出Domain $\mathcal{Y}$。但如果仍然按照之前的方法学习，GAN无法判断生成的二次元图像是否与输入的真人图像是相似的，可能会将输入当作为高斯噪声，忽略输入的内容。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-4/cycle%20gan.png" style="zoom:50%;" />
<p>Cycle GAN中会训练两个Generator，第一个Generator $G_{\mathcal{X}\rightarrow \mathcal{Y}}$将$\mathcal{X}$ domain的图变成$\mathcal{Y}$ domain的图，第二个Generator $G_{\mathcal{Y}\rightarrow \mathcal{X}}$将$\mathcal{Y}$ domain的图还原为$\mathcal{X}$ domain的图。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-4/cycle%20gan2.png" style="zoom:50%;" />
<p>Cycle GAN能保证真实图片和生成图片有一些关系，但如何保证这种关系是我们想要的呢？例如输入一个戴眼镜的人，$G_{\mathcal{X}\rightarrow \mathcal{Y}}$将眼镜转成痣，但$G_{\mathcal{Y}\rightarrow \mathcal{X}}$又会把痣转成眼镜。理论上可能会出现这样的情况，不过在实际中这种情况往往不会出现。</p>
<p>类似地还有Disco GAN和Dual GAN，思想与Cycle GAN基本相同。</p>
<ul>
<li>[<a href="https://arxiv.org/abs/1703.05192">1703.05192] Learning to Discover Cross-Domain Relations with Generative Adversarial Networks (arxiv.org)</a></li>
<li>[<a href="https://arxiv.org/abs/1704.02510">1704.02510] DualGAN: Unsupervised Dual Learning for Image-to-Image Translation (arxiv.org)</a></li>
</ul>
<p>此外还有能够在多种风格之间转换的Star GAN：</p>
<ul>
<li>[<a href="https://arxiv.org/abs/1704.02510">1704.02510] DualGAN: Unsupervised Dual Learning for Image-to-Image Translation (arxiv.org)</a></li>
</ul>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-4/starGAN.png" style="zoom:50%;" />
<h3 id="selfie2anime">SELFIE2ANIME</h3>
<ul>
<li>
<p><a href="https://selfie2anime.com/">Selfie2Anime</a></p>
</li>
<li>
<p>[<a href="https://arxiv.org/abs/1907.10830">1907.10830] U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation (arxiv.org)</a></p>
</li>
</ul>
<h3 id="text-style-transfer">Text Style Transfer</h3>
<p>文字风格转换，例如将负面的句子转为正面的句子。和Cycle GAN的做法类似。</p>
<img src="https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B2021%E6%98%A5/6/6-4/text%20style%20transfer.png" style="zoom:50%;" />
<h3 id="more">More</h3>
<ul>
<li>Unsupervised Abstractive Summarization
<ul>
<li>[<a href="https://arxiv.org/abs/1810.02851">1810.02851] Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks (arxiv.org)</a></li>
</ul>
</li>
<li>Unsupervised Translation
<ul>
<li>[<a href="https://arxiv.org/abs/1710.04087">1710.04087] Word Translation Without Parallel Data (arxiv.org)</a></li>
<li>[<a href="https://arxiv.org/abs/1710.11041">1710.11041] Unsupervised Neural Machine Translation (arxiv.org)</a></li>
</ul>
</li>
<li>Unsupervised ASR
<ul>
<li>[<a href="https://arxiv.org/abs/1804.00316">1804.00316] Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings (arxiv.org)</a></li>
<li>[<a href="https://arxiv.org/abs/1812.09323">1812.09323] Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching (arxiv.org)</a></li>
<li>[<a href="https://arxiv.org/abs/1904.04100">1904.04100] Completely Unsupervised Speech Recognition By A Generative Adversarial Network Harmonized With Iteratively Refined Hidden Markov Models (arxiv.org)</a></li>
</ul>
</li>
</ul>
    </article>


    





    
    
    
        
    




<section id="articleNext" class="section nartrow">
    <h3 class="footer-next-heading">More articles from yzhn&#39;s Notes</h3>
    <div class="footer-spacer"></div>
    <div class="next-articles-grid" numberOfArticles={numberOfArticles}>
        <div class="post-row">
            
                <a href="/post/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%84%9F%E7%9F%A5%E6%9C%BA/" class="article-link"
                 id="article-link-bigger">
                    <div>
                        <div class="image-container">
                            <img src="" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                统计学习——感知机
                            </h2>
                            <p class="article-excerpt">
                                
                            </p>
                            <div class="article-metadata">
                                May 12, 2022 · 7 min read
                            </div>
                        </div>
                    </div>
                </a>
            
                <a href="/post/%E6%9D%8E%E5%AE%8F%E6%AF%85ml%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%90%84%E5%BC%8F%E5%90%84%E6%A0%B7%E7%9A%84attention/" class="article-link"
                >
                    <div>
                        <div class="image-container">
                            <img src="" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                李宏毅ML课程笔记——各式各样的Attention
                            </h2>
                            <p class="article-excerpt">
                                
                            </p>
                            <div class="article-metadata">
                                April 30, 2022 · 4 min read
                            </div>
                        </div>
                    </div>
                </a>
            
        </div>
    </div>
</section>

</section>


 <script src="/js/progressBar.js"></script>

        
        <div class="footer-gradient"></div>
    <div class="section narrow">
      <div class="footer-hr"></div>
      <div class="footer-container">
        <div class="footer-text">
          © 2022 yzhn&#39;s Notes
        </div>
        <div class="social-icon-outer">
    <div class="social-icon-container">
        
            
                
                <a href="https://github.com/yzhn16/"><svg
class="social-icon-image"
width="14"
height="14"
viewBox="0 0 14 14"
fill="none"
xmlns="http://www.w3.org/2000/svg"
>
<path
  fillRule="evenodd"
  clipRule="evenodd"
  d="M7 0C3.1325 0 0 3.21173 0 7.17706C0 10.3529 2.00375 13.0353 4.78625 13.9863C5.13625 14.0491 5.2675 13.8338 5.2675 13.6454C5.2675 13.4749 5.25875 12.9097 5.25875 12.3087C3.5 12.6406 3.045 11.8691 2.905 11.4653C2.82625 11.259 2.485 10.622 2.1875 10.4516C1.9425 10.317 1.5925 9.98508 2.17875 9.97611C2.73 9.96714 3.12375 10.4964 3.255 10.7118C3.885 11.7973 4.89125 11.4923 5.29375 11.3039C5.355 10.8374 5.53875 10.5234 5.74 10.3439C4.1825 10.1645 2.555 9.54549 2.555 6.80026C2.555 6.01976 2.82625 5.37382 3.2725 4.87143C3.2025 4.692 2.9575 3.95635 3.3425 2.96951C3.3425 2.96951 3.92875 2.78111 5.2675 3.70516C5.8275 3.54367 6.4225 3.46293 7.0175 3.46293C7.6125 3.46293 8.2075 3.54367 8.7675 3.70516C10.1063 2.77214 10.6925 2.96951 10.6925 2.96951C11.0775 3.95635 10.8325 4.692 10.7625 4.87143C11.2087 5.37382 11.48 6.01079 11.48 6.80026C11.48 9.55446 9.84375 10.1645 8.28625 10.3439C8.54 10.5682 8.75875 10.9988 8.75875 11.6717C8.75875 12.6316 8.75 13.4032 8.75 13.6454C8.75 13.8338 8.88125 14.0581 9.23125 13.9863C11.9963 13.0353 14 10.3439 14 7.17706C14 3.21173 10.8675 0 7 0Z"
  fill="#73737D"
/>
</svg></a>
                <span class="hidden">https://github.com/yzhn16/</span>
            
        
    </div>
</div>
    </div>
</div>

    </div>

    
    <script src="/js/prism.js"></script>
</body>

</html>